{"posts":[{"title":"IDEA Community 如何创建SpringBoot项目","text":"使用IDEA插件解决社区版无法自动创建Spring项目的问题。 背景介绍以前电脑上存的IDEA专业版的激活包失效了，搞了两天没效果，只能将就用一下IDEA的社区版，但是又想学习后端技术。 就想着总有人会用社区版来写后端吧，搜一下还真有。 软件版本需要IDEA社区版必须是2022.1.4之前的版本。 插件安装 在Plugins的marketplace中搜索：Sping Boot Helper。 不要install！ 点击进入这个插件的homepage 点击进入Version中，翻到最下面选择FreeVersions的版本，下载到你的电脑中（自己决定路径）。 下载后无需解压。4. 在加入插件中，选择从电脑中加入插件： 选择刚才下载好的压缩包即可。 若IDEA提示，则一路选择同意。 效果 出现了创建Spring项目的选项。 现在电脑还没有配置好，暂时不展示项目创建。 参考教程：如何使用社区版IDEA创建Spring项目","link":"/2023/07/14/IDEA-Community-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BASpringBoot%E9%A1%B9%E7%9B%AE/"},{"title":"Markdown语法基础","text":"现在很多的平台都支持使用markdown语法，包括在写hexo博客的时候，文件也是markdown格式（.md）。还有CSDN、石墨文档、Github的README文件、什么印象笔记有道笔记等等都可以使用这个语言。 可以写书、写幻灯片、写邮件、写日记、写便签、记笔记、写博客，让你专注于敲键盘搞内容，顺便用键盘搞定排版和图片啥的。Markdown就被理所当然地称为了“写作语言”。总之很爽。 我是在使用石墨文档的时候第一次接触到这个语法，第一感觉是：真麻烦啊，跟学写代码一样。现在就被打脸了：什么，不能用markdown做笔记？！我还是换一个软件吧:unamused:。 md看起来麻烦，实际掌握十分简单，因为常用的需要的语法就那几个，熟练之后没什么感觉了，完全不用担心。 本文直接开始介绍基本语法。 先推荐一个学习markdown的超详尽书《了不起的markdown》毕小鹏著。这本书对md语言进行了非常详尽的介绍，甚至根据使用平台推荐了不同的编辑器，如何配置这些编辑器。甚至有博客Hexo的搭建方法。看了本文还想深入学高级技巧的可以看看这本书。不过就我日常使用而言，我下面介绍的语法应该足以应付90%的文字写作情况了。我个人喜欢在石墨文档写东西，最棒的就是全平台，手机写了电脑、平板立刻同步，很方便。md的适配做得还不错，要有的都有，而且随时在更新自己的功能，现在甚至有了思维导图的功能（还在优化，值得期待），甚至可以多人编辑文档。免费版够用，一下即用，我很喜欢。 一、写作必备语法1.1 标题一般可以设置六级标题，使用#与空格 + 题目 1234# 一级标题## 二级标题### 三级标题…… 效果： 1.2 引用使用&gt;+内容 123&gt; 这是引用&gt; &gt; 这是引用的引用&gt; &gt; &gt; 这是三层 效果： 这是引用 这是引用的引用 这是三层 1.3 列表都是可以相互嵌套的。我懒得写了 （1）有序列表1231. aaaa2. bbb3. ccc aaaa bbb ccc (2)无序列表123- aa- bb- cc aa bb cc (3)todo list1234- [x] 第一件事情- [x] 第二件事情- [ ] 第三件事情- [ ] 第四件事情 第一件事情 第二件事情 第三件事情 第四件事情 1.4 代码块英文的三个反引号```，在一行内就是段内嵌入，提行则是代码块。头部的单引号最后加入编程语言的名字，可以根据语言高亮。这个单引号，在键盘数字1的左边，记得是英文的。 C语言 123456int main(){ int a = 14; char c = 'a'; printf(&quot;Hello World!&quot;);} Python 123456789a = 13s = &quot;Hello&quot;print(str(a) + s)def print_num(a): for i in range(a): print(i) return 1.5 数学公式用四个美元符号包裹内容，是latex的数学公式，在网上可以查到。看了教程还不知道怎么手写的话，可以先用在线编译器，图像选择需要的公式，再生成latex公式。这里给一个latex在线编译器吧 1\\frac{\\partial f}{\\partial x} = a\\sqrt{a}x $$\\frac{\\partial f}{\\partial x} = a\\sqrt{a}x$$ 1.6 表格 姓名（左对齐） 年龄（右对齐） 成绩（居中） 周大猛 22 80 周不猛 10 75 1.7 脚注就像是论文的参考文献，给上标1、2、3，然后可以在文章末尾查到对应的参考文献那样。 首先在正文需要脚注的地方： 1这个内容参考了很多资料[^视频资料] 在文章末尾： 1[^视频资料]:https://www.bilibili.com/video/BV1JA411h7Gw/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=69a3eecb8fce5149ffe1597cbbfc9364 效果：这个内容参考了很多资料^视频资料 1.8 分割线使用三根短横线，就是减号那个短横线。--- 就是这样↑↓ 另外，上面说到的脚注，是会自动生成一个分割线以区分正文和脚注的。 1.9 链接(1)简单链接1[百度了你一也不一定知道](baidu.com) 百度了你一也不一定知道 添加提示 1[百度了你一也不一定知道](baidu.com &quot;提示&quot;) 百度了你一也不一定知道 鼠标悬停查看效果 (2)引用链接文章多次使用同一个链接 123我有一个引擎，叫做[百度][baidu]，可以用[百度][baidu]来搜索很多的东西，我很喜欢[百度][baidu]。[baidu]:https://www.baidu.com/ 我有一个引擎，叫做百度，可以用百度来搜索很多的东西，我很喜欢百度。 (3)页面内跳转1我要去[表格](###6.表格) 我要去6.表格 似乎不行:cold_sweat: (4)带协议的url前面带有http或者https的url，会被自动识别为超链接。https://www.baidu.com/ 1.10 字体123456789101112*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___==文字高亮==:smile:H~2~Ox^2^ 斜体文本斜体文本粗体文本粗体文本粗斜体文本粗斜体文本 ==文字高亮== :smile:H2Ox^2^ 这里的表情是使用的shortcodes，没搜到官网呢，但是csdn上有人总结了。Emoji 1.11 嵌入视频如：b站播放器，在分享那里选择嵌入代码，粘贴html格式的播放器代码 1.12 嵌入图片1![百度首页](图片路径 &quot;This is a picutre&quot;) 1.13 很高级的功能这些的语法还挺复杂，这写都是用语法写出来的，不是图片。 直接搬运了菜鸟教程高级部分的评论区。 12345678910111213$$\\begin{Bmatrix} a &amp; b \\\\ c &amp; d\\end{Bmatrix}$$$$\\begin{CD} A @&gt;a&gt;&gt; B \\\\@VbVV @AAcA \\\\ C @= D\\end{CD}$$ 转换图一样的东西 $$\\begin{Bmatrix} a &amp; b \\ c &amp; d\\end{Bmatrix}$$$$\\begin{CD} A @&gt;a&gt;&gt; B \\@VbVV @AAcA \\ C @= D\\end{CD}$$ 流程图一样的东西 1234567三个代码点 mermaidgraph LRA[方形] --&gt;B(圆角) B --&gt; C{条件a} C --&gt;|a=1| D[结果1] C --&gt;|a=2| E[结果2] F[横向流程图] 1、横向流程图源码格式： 123456graph LRA[方形] --&gt;B(圆角) B --&gt; C{条件a} C --&gt;|a=1| D[结果1] C --&gt;|a=2| E[结果2] F[横向流程图] 2、竖向流程图源码格式：把meraid放在代码框的代码语言那里 1234567mermaidgraph TDA[方形] --&gt; B(圆角) B --&gt; C{条件a} C --&gt; |a=1| D[结果1] C --&gt; |a=2| E[结果2] F[竖向流程图] 123456graph TDA[方形] --&gt; B(圆角) B --&gt; C{条件a} C --&gt; |a=1| D[结果1] C --&gt; |a=2| E[结果2] F[竖向流程图] 3、标准流程图源码格式： 12345678910flowst=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st-&gt;op-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op 123456789st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st-&gt;op-&gt;condcond(yes)-&gt;io-&gt;econd(no)-&gt;sub1(right)-&gt;op 4、标准流程图源码格式（横向）： 12345678910flowst=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st(right)-&gt;op(right)-&gt;condcond(yes)-&gt;io(bottom)-&gt;econd(no)-&gt;sub1(right)-&gt;op 123456789st=&gt;start: 开始框op=&gt;operation: 处理框cond=&gt;condition: 判断框(是或否?)sub1=&gt;subroutine: 子流程io=&gt;inputoutput: 输入输出框e=&gt;end: 结束框st(right)-&gt;op(right)-&gt;condcond(yes)-&gt;io(bottom)-&gt;econd(no)-&gt;sub1(right)-&gt;op 5、UML时序图源码样例： 123456sequence对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象A-&gt;对象B: 你真的好吗？ 12345对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象A-&gt;对象B: 你真的好吗？ 6、UML时序图源码复杂样例： 123456789101112sequenceTitle: 标题：复杂使用对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象B-&gt;小三: 你好吗小三--&gt;&gt;对象A: 对象B找我了对象A-&gt;对象B: 你真的好吗？Note over 小三,对象B: 我们是朋友participant CNote right of C: 没人陪我玩 1234567891011Title: 标题：复杂使用对象A-&gt;对象B: 对象B你好吗?（请求）Note right of 对象B: 对象B的描述Note left of 对象A: 对象A的描述(提示)对象B--&gt;对象A: 我很好(响应)对象B-&gt;小三: 你好吗小三--&gt;&gt;对象A: 对象B找我了对象A-&gt;对象B: 你真的好吗？Note over 小三,对象B: 我们是朋友participant CNote right of C: 没人陪我玩 7、UML标准时序图样例： 12345678910111213mermaid%% 时序图例子,-&gt; 直线，--&gt;虚线，-&gt;&gt;实线箭头 sequenceDiagram participant 张三 participant 李四 张三-&gt;王五: 王五你好吗？ loop 健康检查 王五-&gt;王五: 与疾病战斗 end Note right of 王五: 合理 食物 &lt;br/&gt;看医生... 李四--&gt;&gt;张三: 很好! 王五-&gt;李四: 你怎么样? 李四--&gt;王五: 很好! 123456789101112%% 时序图例子,-&gt; 直线，--&gt;虚线，-&gt;&gt;实线箭头 sequenceDiagram participant 张三 participant 李四 张三-&gt;王五: 王五你好吗？ loop 健康检查 王五-&gt;王五: 与疾病战斗 end Note right of 王五: 合理 食物 &lt;br/&gt;看医生... 李四--&gt;&gt;张三: 很好! 王五-&gt;李四: 你怎么样? 李四--&gt;王五: 很好! 1.14 正常显示那些符号比如星号（被用来加粗了） ，可以使用转义字符反斜杠来正常输出* 1\\*","link":"/2023/04/18/Markdown%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"title":"Python项目与别人分享","text":"当有一个项目，想打包给自己的朋友的时候，需要做什么呢？献给小白的你我他。 必做的事情通常一个项目，你配置python、numpy啥的版本不一样，也会影响到在别人电脑上的运行情况。 为了避免这个问题，我们可以生成一个项目的依赖文件，帮助别人在导入我们的项目后快捷的搭建好需要的环境。 打开终端 进入项目目录（其实在pycharm下面的终端直接就可以，或者在文件夹中右键打开终端） 输入命令pip freeze &gt; requirements.txt 就可以了！ 你的朋友只需要： install -r requirements.txt1 就可以在他们的环境中安装和你一样的依赖了。 打包方法1：传到github上看我的另一个博客_post/git与github使用方法.md 方法2：压缩文件使用win的命令：tar -cvzf project.tar.gz --exclude='./data/aa' --exclude='./data/bb' . 运行地方与生成依赖的目录一样 其中--exclude=是该项目下不打包的文件。","link":"/2023/11/18/Python%E9%A1%B9%E7%9B%AE%E4%B8%8E%E5%88%AB%E4%BA%BA%E5%88%86%E4%BA%AB/"},{"title":"git与github使用方法","text":"学习一下如何使用git与github对代码进行管理 git与github的关系Git是一种分布式版本控制系统，由Linus Torvalds于2005年创建。它用于跟踪文件和代码的变化，使团队成员能够在不干扰其他人工作的情况下协同开发项目。每个开发人员都可以在自己的本地计算机上创建、修改和提交代码的版本，然后将这些变更推送到共享的代码仓库。 而GitHub是一个基于Git的代码托管平台。它提供了一个在线的服务，使开发者能够轻松地将他们的Git代码仓库托管在云端。GitHub除了支持基本的代码托管功能外，还提供了诸如协作、问题追踪、代码审核、持续集成等功能，使得团队合作更加高效。 简而言之，Git是一种版本控制系统，而GitHub是基于Git的代码托管平台，为开发者提供了更便捷的协作和管理代码的方式。 描述来自chatGPT。 写在前面：如果想要在本地创建了git仓库并且和github连接到一起，先用git init在本地初始化，再在github上创建自己对应的仓库。按照本文一步一步走即可。 Git使用步骤以及介绍。 提交 设置个人信息 这里设置全局的不是每次创建一个git仓库都需要设置。设置一次就可以了。 12git config --global user.name&quot;你的昵称&quot;git config --global user.email&quot;你的邮箱&quot; 这是为了记录提交者的信息，不需要一定和github的用户名与电子邮件对应。但是设置成一样的github才能将这次提交记录为自己的贡献。 初始化 在你的对应文件夹或者文件所在位置进行初始化。 git init在当前目录下初始化你的git管理，会生成一个隐藏.git文件夹，文件夹中保存每个git版本记录和变化。 此时文件还没有被记录 存到暂存区 git add 文件名 若是该文件路径下的所有文件，则为git add . 将所有的更改添加到暂存区，存储到暂存区后，commit会把暂存区的东西提交到仓库。 提交到仓库 git commit 将暂存的修改提交为一个固定的版本。 提交后会打开一个vim的终端编辑器，这里要求写你的提交说明。 vim操作详见vim的教程。 简单说明：进入这个步骤的时候还不能直接输入，按下（二选一）： a ： 光标之后开始插入文本 i ： 光标之前开始插入文本 编辑完成后，按下esc推出拜年祭模式。 然后输入:wq保存文件并退出。 本次提交就算完成了。 简化版： git commit -m &quot;提交的说明&quot;跳过vim编辑。 提交信息的书写规范，遵守Converntional Commits规范，按照&lt;type&gt;(&lt;scope&gt;):&lt;description&gt; &lt;type&gt; 提交类型，常见的有：fix修复了bug，feat新增功能，docs文档更新，style代码格式化，refactor重构代码，test测试代码。 &lt;scope&gt;提交的影响范围 &lt;description&gt;对本次提交的简单描述 vscode也自带了这些git的提交流程，可以研究一下。 查看提交信息 git log - 本次提交的随机aid - 提交的人 - Date：日期 - 提交的说明 回退（重置）到某个版本状态 git log查看版本信息 找到对应的随机编号 git rest --hard 版本编号 reset会把回到的这个版本之后的版本也清空(撤销这个版本之后的所有记录)。 如果不想清空记录，我还不会。 分支branch用于团队开发。 创建分支 git branch &lt;branchName&gt; 进入分支 git checkout 合并分支在主分支进行操作： git merge &lt;合进来的分支名称&gt; Github首先，自己创建一个repository在github上面。 进入这个页面，下面的是叫你如何在自己的代码处创建git仓库和与github该仓库链接的简单教程。 git branch -M main 是一个 Git 命令，用于将当前分支重命名为 main。github现在默认创建的主要分支叫做main了，以前叫master。 这里建议设置一下。因为之前下载git的你可能不记得自己设置的git默认主分支是master还是main了。 当前项目的git分支可以通过git branch -a查看。 其实就是上图中，仓库初始化后的网站上提示的操作。 git remote add origin XXXXX ：添加一个远程仓库地址。 git push -u origin main 推送上传到这个github的远程仓库。 可能需要输入github的邮箱和密码 补充技巧在一次推送项目的时候忘记加入.gitignore 了，导致我的png数据集全部被列入了推送list，好多个G，严重影响了我的上传速度。这里介绍：在git push 后如何终止并重新上传。 首先使用 ctrl+C 停止当前的进度。 从Git中移除所有文件：git rm -r --cached . 重新添加所有文件git add . 提交git commit -m &quot;Add .gitignore&quot; 推送到Githubgit push -u origin main 如果还不得行，就删除项目文件夹中.git ，然后重新开始init…… 遇事不决删历史。 一些规范在commit代码的时候，备注应该怎么写呢？ Git commit的注解规范可以参考以下内容： 每个提交应该有一个简短的标题，不超过50个字符，使用大写字母和祈使语气。 标题和正文之间应该有一个空行。 正文应该简要描述本次提交的目的和具体做了什么操作。 如果需要，可以在正文中添加备注或说明。 提交信息应该尽可能准确地描述本次提交内容。 可以使用以下标识来说明提交的类别： feat：新功能（feature）。 fix：修复bug。 docs：文档（documentation）。 style：格式（不影响代码运行的变动）。 refactor：重构（即不是新增功能，也不是修改bug的代码变动）。 perf：优化相关，比如提升性能、体验。 test：增加测试。 chore：构建过程或辅助工具的变动。 revert：回滚到上一个版本。 merge：代码合并。 sync：同步主线或分支的Bug。 总结操作完毕之后，每次提交代码的流程都是： 123git add .git commit -m &quot;NXXXXX&quot;git push 就行了 下面这个视频教学非常好，参考这个来的。 B站的教学视频:git、github 保姆级教程入门 有一个闯关形式的git练习，很有创意，但是我没学会：git游戏","link":"/2023/07/23/git%E4%B8%8Egithub%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/06/26/hello-world/"},{"title":"1.为什么我要写这个博客","text":"其实这个想法存在了很久了，只是恰好拖到了现在，又恰好虽然现在忙得不行，但是就是不想干正事，这个Hexo又恰好不是很难搭建，就着手干了起来。有想法，没计划，全靠热情和冲动，以及一点点逃避现实的懒惰和恐惧。 先说说起因吧……那其实是我还没有转到计算机的时候。我喜欢的一个油管主，他除了分享自己的学习方法、学习日常以及做推广（笑）之外，他还会分享自己读的书以及自己的读后感。一个很厉害很厉害的油管主，我很佩服他，他的学习那么忙，还剪视频、做博客，我一直都很好奇，到底是什么在推动他如此持久地记录自己的生活，分享自己的经验？For money？哈哈哈，这个理由肯定不会没有。但是除此之外，我更多的是感受到他分享的时候，面对镜头的那种喜悦。总而言之，他对我的影响很大。 恰好又是那段时间，我正苦于英语的学习，抱着学习要从兴趣出发 的想法，要不找一本有意思的全英文的不是那么难的书来读一读吧？然后又是恰好这个时候，这个对我影响颇深的油管主，分享了一本书 《Show Your Work》。不难、纯英文，我到现在都没读完（笑）。他说，就是这本书让他开始了自己的油管主之旅。恰好也是这个时间段吧，我开始了我的计算机之旅。 进入了这个领域之后，真的会接触到很多博客或者类似的个人发表自己的“作品”的平台：CSDN、知乎或者是公众号…… 这中最多的title就是：“手把手教你如何安装XXX”（笑）。 很感谢各位大佬的倾囊相授，很感激的同时，让我多少有些痛苦的就是：“啊，这个界面怎么来的？”，“这是啥？”，“我配对了吗？我怎么知道？”，“噫？怎么【中国脏话】报错了？怎么搞的？”。多少会有这种地方，大佬们就不会细致地讲解了，默认大家都会（悲）。 那个时期的我，还只是个office都用不熟练，下载只会默认C盘，最厉害的就是右键新建文档……的我需要在一两个月内，下载好编译器、配置好环境、学会C语言、补修大一计算机的课程、插班并跟上大二计算机的课程。第一步搞坏了我的电脑、第二步搞坏了我的脑子、第三步搞坏了我的身心健康。与此同时我还要继续我的英语学习（悲）。 稀里糊涂、慌里慌张地终于正式成为了计算机专业的大冤种的一员，学会了不要什么事情都问学长学姐和同学，要先自己百度一下，CSDN搜一搜，再不行谷歌里面StackOverFlow里面一字一句翻译的自学的“初有成效”阶段，我终于有时间看看大大推荐的书，那些为我们写下那么多“手把手带你XXX”教程的大佬们，是不是和书里面有同样的想法呢？ 我当时看了些什么不记得了，记得的就只有，为什么要展示你的工作？（基本都由我的记忆瞎编了一点，不代表书中的意思） 因为可以看到你自己的成长足迹 因为大佬们已经忘记了自己是小白的日子，忘记了什么都不会的人该怎么起步，所以他们分享的东西是不完整的，需要有人来补充，而你恰好是初学者。 学习如何把自己的工作用最简单的话展示给别人，是提升自己能力的一种。 更集中在“过程”而不是“成果” 好像还提到可以变现？没事反正我变不了现，所以无所畏了。其中，第二条对我的影响很深：我就是小白啊，我就是什么都不会，但是我还是配置好了环境，学会了写代码！大概就是这个这段时间，开始出现：我也想搞一个东西，展示我的学习生活。这种幼稚的想法。 但是我不知道自己可以写什么，在哪个平台发布，从零到有往往是最难的一步。知乎吧，人均年入百万，各个出口成章、引经据典，我这个文盲还是别凑热闹了。CSDN吧…… 自从我看到一个网友比我年级小，问了个我看不懂的问题，还被大家清一色地嘲笑：“都这个年龄了这都不会！”，让我敬而远之。或者自己搞个公众号？但是我自己关注的好几个公众号都没做下去，下来了解了一下公众号的搭建流程，嫌麻烦就放弃了。搜索“如何搭建自己的公众号10次，放弃10次（笑）。 某一天，又是写不动代码的时候，看到了有的人的网站怎么既不是CSDN，又不是什么知乎，又看起来不像是什么平台上的文章，简陋的只有作者介绍和干货？哦~原来还有个叫个人博客的东西。 搭不来，百度“怎么搭建个人博客？”，推荐Hexo，XXX，XXX。这是我第一次接触到Hexo。如何搭建Hexo？oh天哪，要github、要node.js，不会，遂放弃。再有一次在翻找各种大大写的网文，有个大大分享了个WordPress中的文章。想着顺着摸摸看能不能找到更多好文，居然是个博客！而且是大家都可以用它搭建自己的博客！ 百度：怎么搭建WordPress？ 你需要巴拉巴啦啦……需要自己的服务器…… 好的放弃了。 是的，我就是这么容易放弃的人。所以好多想法没有实现，好多事情没能做完，好多地方没有去，好多东西没有吃。就是这么一事无成、平平无奇。 但就算是这样的我，也最终还是搭建了这个博客。 或许是因为，看到身边有同学在做着同样的事情，在CSDN发布自己的学习笔记，B站发布自己的复习视频，讲解所学的课程，自己当个小老师，或许是每一次出现Erro的时候看到大佬们的文章“临帖涕零”的时候，一次又一次想起那个书里面说的那些话，让我不知道多少次又开始想：我也要整一个！ 还在化工的时候，我就在试着用思维导图做一些复习整理，这个习惯在现在愈演愈烈，我的石墨文档、幕布或者我青涩愚蠢粗暴的代码里面穿插详尽的批注（我为我的批注感到骄傲，我到现在都看得懂我的代码）。这些年，虽然不曾发表，但是积累了不少的东西，感谢这些便利的平台让我养成了写东西的习惯。 单纯因为这些平台的笔记方便手机复习。期末的时候我习惯性的会把我认为好的东西分享给我的朋友们，包括这些我自己整理的笔记。 就是有一次吧，忘了啥时候了，我朋友突然说：你搞了这么多，都可以发个CSDN的博客了。我的心突然咯噔一下，我这粗糙的东西，也配？但是转念一想，也不是不行，毕竟CSDN很有好了……不提问的话……但是就是这么一句话，让第一次分享了自己的东西。 幕布社区里面或许搜得到，一个粗糙的计算机网络的笔记。 题目和内容都不是很好，没几个人看，但是还是很开心，哪怕一个节点对那个陌生人有用，也是有价值的。没价值也没事，他们知道了这种做笔记的方法很失败也行（我没有难过，嘤） 而且每次打开那个两万字的笔记，就不由得感叹，这门课真他喵的折磨。 然后，就是现在这个博客了。B站？哦，我不会剪视频，好麻烦，没设备，没时间（剪视频可比写文章麻烦多了！），而且那里现在也变得可怕起来了。（我曾录视频给室友讲过一个算法，反馈还不错，但是吧……实在是太麻烦了！！！要保证看得清、听得清、废话不多、有条理巴拉巴拉，目前的我，太难） 呵呵，回到现在。这几年，没学会Node.js(会过，忘了)，但是电脑里却配置了这个东西，不会用github，但是有了自己的账号、下载了Git，创建了demo仓库n个（这几天学会删掉了），当时看不懂的各种npm，在哪里输入这个命令，现在也知道了。 那还差什么？就差npm install了呀！Android Studio都安装过的我，区区一个Hexo怕神马！（嗷呜！） 反正毕设卡住了，修考复习也一筹莫展，这个Hexo也不是很难的样子，整一个！ 然后我一个下午、又一个晚上、又一个下午，都搭在了这上面。写博客真是上头。 好吧，主要还是智商不够，这么简单的博客搭了这么久（悲）。但是确实很简单，真的，或许是我只差Hexo了，反正，比那个WordPress简单（吧）。 之前不是没想过纯手工做一个博客，我可是计算机学生，那样更自由，更有成就感，但是我真的到大四了还不会搞开发……我就是这么废物呵呵，之前做网站开发是小组作业，我一直分的是搞后端的，前端就知道个皮毛，现在后端技术也忘光光了（大悲）。这种技术流程，自己做笔记就不是很方便了，所以也没记下来，但是学习资料都保存了，后面需要的时候，再整理成笔记吧。 但是最主要的原因还是：搭建成本太高。需要自学前后端开发（很麻烦的！）、设计UI（这是很困难的！）、搭建（很麻烦的！）、部署上线（还要花钱！），一套下来不知道几个月要投入进去（纯搞这个），对我而言，做这个事情还没有重要到值得我做到这一步。 但是Hexo+Github很好的解决了这些问题。 现成的框架，不想改主题，直接写就行，简单的几行命令轻松搭建好自己的博客。Github直接让你的主页可以被人看到，要被搜到还需要别的方法，不过与我而言目前已经足够。写博客也很简单，本地保存、md格式，使用多年石墨文档的我很快可以上手。 嗯，真好~ 最后，感谢你看到了这里。我不善言辞，更不善写作，看我废话了这么久，辛苦辛苦。 这一切开始也就这么回事儿，看起来是一次冲动，但是追本溯源好像又不是那么回事儿。我不知道这个博客我会坚持多久，但是它存在的这一刻起就是我“记录”的全部意义。这篇文章只是为了稍微记录一下我的初心，它是怎么出现的，现在我把自己的小小的初心放在这里，也不知道能不能茁壮成长，总之先长吧。 如果看了到这个文章的你，也有了一个：“要不我也整一个？”的想法，我的博客里面，Hexo下面有个可以参考的搭建教程，我参考过的博客链接也在里面，希望对你有帮助，也是我的愿望之一。 谢谢。","link":"/2023/04/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E8%A6%81%E5%86%99%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/"},{"title":"恢复SD卡被格式化数据","text":"今天又不小心把SD卡搞得出问题了，提示不格式化不能进行任何操作……记录一下恢复的过程。 误删相机中的照片可以尝试用同样的方法恢复数据。 事故发生在准备把SD卡中拍摄的照片转移到我的U盘里面的时候，看到我的读卡器有点点松，就碰了一下，然后就无法转移数据了，所有的相片、视频都显示数据受损。 电脑提示：驱动损坏，需要格式化该硬盘。 插回相机：内存卡未格式化 原因分析在SD卡的读写过程中不可以进行任何的热插拔操作，不然就会造成内存卡数据出错，可能会导致数据损坏。 发生这种提示的原因其实不只是这一中，据网络搜索，读卡器受损、相机受损、电脑系统故障，都有可能出现这种提示。这里做出上述判断纯粹是知道这是自己手贱造成的（哭）。 其实之前也有一次手滑，在相机里面删除了所有的照片。并且在相机上进行了强制格式化后继续拍照。这样很有可能会导致数据无法恢复，请勿模仿，把卡换下来，换备用卡谢谢。 解决方法使用数据恢复软件对格式化后的SD卡进行数据恢复。 使用的软件：Recuva（免费版） 需要知道自己需要恢复的数据的路径。很多别的软件是要收费的，说的是免费，但是其实是免费下载。我当时选了一个软件，扫描完了我的数据，都找到了，点击恢复说要给钱…… 操作步骤 当然是给他权限进去 选择恢复的数据类型 选则恢复路径 知道确切路径的话，就选择 In a specific location. 然后就会开始扫描这个路径下面有些什么残留的文件信息，会出现一个列表，选中自己要恢复的数据，列表回显示数据的时间、是否可恢复的状态等，根据需求恢复即可。 我记得好像是提示了不建议恢复到原位，这次我是选择了恢复到我的目标U盘里面。 之前删除照片的时候，是直接恢复到了原来的位置。倒也没影响我的这张卡的使用。 我的卡是32G的，恢复了34个G的数据……，失去数据前应该是有十多个G的视频和照片，我没有细看多恢复了哪些东西。但是其中有4个G的数据是无法查看的，估计是很久以前的东西，因为我这次要转移的数据都是新拍的，扫了一眼基本都是回来了的。 数据珍贵，操作消息 :cry:","link":"/2023/07/27/%E6%81%A2%E5%A4%8DSD%E5%8D%A1%E8%A2%AB%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%95%B0%E6%8D%AE/"},{"title":"关于这个Hexo博客","text":"这个主题这个博客用的主题是：icarus，当时一眼就相中了：这玩意儿真好看，我也要整一个，所以就有了现在这个样子的主页。 放上这个帅气的主题的github和链接吧： 123https://github.com/ppoffice/hexo-theme-icarushttps://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Donation/ 这个博客这是我第一次创建博客，也是第一次搞这个主题，稀里糊涂的怎么也看不懂这个博客怎么建立、怎么写、怎么删（写这个内容的时候还没学会删除），搞上了这个主题之后，因为各个地方的设置也不是很清楚，目前只切换了我找得到的github的url和删掉了部分我不想要的链接和功能。 删掉评论单纯是因为我不会搞也懒得搞，这些博客都是自娱自乐的东西，记录一个才开始不就自己的代码之旅已经被搞得灰头土脸的人的学习和生活。仅此而已。 在我搞这个复杂（至少在我看来是的）的主题的时候，会陆陆续续贴上自己怎么搞的这个Hexo博客（这个简单），怎么修改主题（略复杂，如果没看懂大佬们的说明的话），以及怎么把这个主题搞得面目全非。 希望自己在魔改这个博客的各种东西的时候，没有冒犯到慷慨的大佬们的权益。博客内容肯定是我这个小白的总结和笔记，参考的东西都会贴上原贴或者视频地址。就先这样吧。 今天搭建这个玩意儿花了我四个小时，问就是我不会。不过是真的很简单，只是因为看了太多的资料有些搞混罢了，后面整理一下吧。 就先这样，如果你看到了这个博客，我会非常开心，说明我将这个blog发表了。或许可以做个点赞的功能（思考）","link":"/2023/04/10/%E5%85%B3%E4%BA%8E%E8%BF%99%E4%B8%AAHexo%E5%8D%9A%E5%AE%A2/"},{"title":"我的小角落","text":"","link":"/2023/07/27/%E6%88%91%E7%9A%84%E5%B0%8F%E8%A7%92%E8%90%BD/"},{"title":"更换Hexo主题","text":"来讲一下怎么更换自己喜欢的主题吧，如何查找喜欢的主题、如何更换，都有写的。 我用的最麻烦的一种方式，因为我还不是很会git的语句。 但是，简单的来说就是以下几个步骤： 找到喜欢的主题 hexo官网theme： https://hexo.io/themes/ 某呼会有人写推荐 任何你想得到的别人会推荐这个博客主题的地方。 把这个主题下载到theme文件夹内，文件名用这个主题的名字 把_config.yml 中的theme改为这个名字 接下来用我使用的这个主题ICARUS进行介绍 1. 下载这个主题 https://github.com/ppoffice/hexo-theme-icarus 作者会分享到github上面，在github上下载到你的themes文件夹中 理论上这一步可以通过git指令完成。等我学会了再说。 非常的easy对吧 2. 设置yml根据大佬github的指示干就行 12$ npm install hexo-theme-icarus$ hexo config theme icarus 第一句不知道是啥，但是看起来是icarus这个主题要做的，什么效果不知道，反正搞就是了。 第二句是属性设置，可以不用进到yml文件里手动修改theme的属性，这行代码就可以搞定。 3. 之后其实下载好之后，你会发现还有很多需要自己去设定的东西，比如你的头像、昵称、你的社交媒体的链接等等，icaus的作者在自己的展示页面是配备了修改的讲解的，可以按照说明来。 据我观察，基本都是修改config文件，或者是主题自带的它的configXX文件。 说了这么多，我自己的主题都没有修改完哈哈。就先这样吧。","link":"/2023/04/11/%E6%9B%B4%E6%8D%A2Hexo%E4%B8%BB%E9%A2%98/"},{"title":"留学日记-1","text":"23年7月4日到达日本，现在已过去4天，简单记录一下。 路还是要亲自走走，才知道难与否。 伴随互联网的发展，入境日本填写纸质申报单已经不是必要的事情了，可以在 Visit Japan Web上提前申请，得到黄色和蓝色的QR码，截图保存，就可以丝滑入境。 到达日本后，成田机场的工作人员非常的耐心，他们大多都是年长的叔叔阿姨，只会说几个简单的英语单词。 不用担心听不懂看不懂的问题，翻译+手势足以。 我走的留学生通道，带上自己的护照、语校录取通知和外出申请书（打工用的申请），交给审查官，就可以办下暂时没有住址的在留卡。在留卡的上面会写明是否能打工的申请。 入境的检查也没有那么严格，扫码（VJW的码）后，询问了几句就放人了。主打一个自觉。 离开机场，非常感谢我的叔叔大老远来接我，还送我去我租的房子，帮我收拾了一下亚马逊下单的床上用品，带我吃了个晚饭，我才能在第一天还有人样，不至于累的要死还不知道咋办也不敢进饭店吃饭在房间里面哭。 叔叔带我吃的拉面，是干拌面那种拉面，我说不上来像国内的哪种，比甜水面细一点的粗面，以及日本的酱油味和他们的叉烧，加上几个鸣人卷和几片海带，味道很独特，就是我到日本的第一顿饭。 为了找到能停车能吃饭的店，叔叔带我在城里绕了好久。 这里并没有给我一种先进或者发达的感觉，仿佛一切都停止在了二十世纪初，倒是哪些霓虹灯、刷卡支付、机器点单让我感受到突兀，与周围的老旧环境格格不入。 还有就是，小、窄、挤、严格和收费真他妈贵。 一切都像是中国的0.75倍：街道、车子、房子、立交桥…… 但是规矩是那么严格，路上不能停车，而且到处没有停车位，因为这边土地实在是太少了。店面也是那么的小，可能就三五十左右平方的用餐区，堆放六七八九个餐桌。那么晚了警察都会在立交桥追着超速的车跑，路边没有停车位，有也会严格设置你可以停放的时间和停放车辆的类型，好多车位是给店铺卸货用的。 路上的行人也大多都是靠左走，男的穿西装，女的穿碎花长裙。 三三两两的行人，偶尔经过的车辆，我好像与这个城市格格不入。 第二天还什么都不会就要去语校报道。 谷歌你能不能优化一下导航 我跟着谷歌map，走错了路…… 错过了车站入口，大着胆子拉了一个路人问了路，那个姐姐很好，一边比划一边跟我说怎么走，只是我只听懂了前面路口要左转…… 神奇的是找到车站了……甚至是对的入口。 但是不知道怎么看车子的方向，坐反了，愚蠢的我坐反了还出站了，痛失180日元。 一路磕磕绊绊到了学校的本馆，被告知我在新馆上课，感谢中国兄弟带路。 迟到了，但是跟老师说明后被原谅了。 那天是大家第一次上课，我虽然错过了开学会，但是还好没有错过我们班的第一节课。 有的人是中级班升上来的，有的则是和我一样，刚入学。 我们班全是中国人，不愧是优秀的大家。 做自我介绍的时候，我彻底懵了，都是中国人，干嘛把自己的名字日语化？？？下来愣是一个人没记住，就记住了大家的志愿。 后来我懂了，老师不会念我们的名字，为了方便老师，也或许为了以后给本地人做自我介绍的时候方便吧。 课程很简单，进度很慢，甚至比不上我在国内为了备考的时候自学的效率，但是老师全程日语讲课，给了我很多机会学习他们的表达。 而且，语法稀烂的我，在这个龟速教学下多少开始学着怎么去理解不同的语境下的表达了。 下课后，办了学生证，结识了另外两个班的也是刚到日本的同学，加了好友。她们住在学校宿舍。 宿舍就是好啊，可以一下子交到朋友，家具什么的也都配齐了。我现在孤身一人，一无所有。 学校的事情办完了之后，不敢去吃饭，不敢上街，在大厅里面呆呆地等中介带我办手续。 我不知道他会不会坑我，但是我除此之外无依无靠，毕竟不可能麻烦在工作的叔叔大老远的带我办这些事情。 理论上说，这些一个人也该能办的。 但是我就是怕。 怕说不好，怕做错事，怕被骗，怕自己问的太多被人嫌弃。 我没有那么强大的内心，也没有那么多的试错成本。 这天办事情没那么顺利，说最近来的中国人太多了，处理不过来，窗口关了许多。 中介说他这么久，从来没遇到过这种情况，问我飞机上是不是很多留学生。 我说：具体不太清楚，但是据说我这班机是因为来日本的人太多了，加的航班。 最近的国际形势并不和谐，日本排放核废水就是在这个夏天。 我问中介，你在日本生活这么久，对这个怎么看。 他说：你看看来日本的是变多了还是变少了呢？ 我不知道具体的数据，但是看登记所的情况，这个夏天人肯定是不少的，我们只是七月生。 认识了很有趣的朋友。 今日宜交友 首先是班上的同学，奇迹的是我们住在一个街区，相隔5min路程。 她带我知道了好多百元店，我之前只知道大创，带我吃饭，带我找路。 下午自己去办理手机卡，又结识了一个来自都匀的朋友，也是相聊甚欢。 晚上班上的同学和她对象带我在街区走了好久，认识了一下周围的情况，听了好多故事和生活技巧，很是感谢。相约第二天一起去上学。 一个人的生活好像没有那么孤单了。 七月七日是日本的七夕，老师介绍了他们这边的七夕的来源，中国。 他们对于来自中国的文化和习惯都是大大方方的承认，也对自己文化中特有的部分感到自豪。 说起这个，我们学习汉字的时候，老师们的态度真的很有趣。经常会说：“哎，你们都是中国人，这个应该很简单吧。“ 然后开始讲一些特殊意义和读法。 老师，我们写确实是会写的，但是读是读不准的，你们一个汉字根据不同的情况有不同的读音，不是一两个是三四个，我们很懵逼。 所以还是能学到不少东西，虽然是汉字。 下午，我终于在各种犹豫+询问+大胆与大爷店员交流，通过翻译软件+蹩脚的日语+手舞足蹈买到了我的窗帘。 真好，我也是有窗帘的人了。 这几天一直都是纸板贴墙+叔叔的猫猫的毯子保护我的隐私。 谢谢纸板，谢谢猫猫。 这里的设计还真是好啊，很多都是统一的或者兼容性很高的尺寸和配件，让我的shopping没有那么难过。 记得家里的窗帘每次安装我都生不如死筋疲力尽，这边安装窗帘真的丝滑，小房子真好。 晚上叔叔来帮我把床板搭了起来，申请了邮局的银行卡，带了吃的给我，我好像又可以活几天了~真开心 (●’◡’●) 床++ ， 垃圾++。 现在还是乱七八糟，还有好多事情没做，虽然不知道赶不赶得上考试……但是一切都在慢慢走向正轨。 一个人生活还真是不容易。 这几天生活下来我算是知道了为什么日本人安静、喜欢整洁，做事规矩。 鄙人浅薄的见解 小，太小了。 房间稍微有一点点杂乱，就会非常明显。 声音稍微大一点，自己都觉得吵闹。 稍微走快一点，就很容易撞到别人。 所以要靠左行，自己急着前走挤着路上慢慢走的人要稍微表示歉意。 所以要小声说话，别影响到别人，说话声音刚刚好能交流就行。 所以东西都不便宜，地小人多。 以前只是网上看到，但是来了之后，切实生活在其中，才真正领会到这些东西。","link":"/2023/07/08/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-1/"},{"title":"留学日记-2","text":"来这边一周多了，再来记录一下自己的生活。 日本真的生活起来很舒服吗？ 我的小家 现在租的这个小房子总算有了点人类居住所的感觉了。 添置了桌椅、冰箱、洗衣机、热水壶和电饭煲。但是我的厨具还没有到，锅碗瓢盆一个没有。 上次去百元店本来想买个刀和菜板的……才反应过来刀需要刀架，菜板得有地方放。我那个狭小的地方，哪里来的空间放这些东西，总不能放在头顶的厨柜里面吧。 做饭啥的还不急，慢慢来吧。 家里的垃圾还是堆在那里，这边的垃圾分类，要说多复杂，到好像也没有，但是有这么个流程，总归是麻烦的。 因为要处理垃圾，我买东西欲望都降低了，全是生存的欲望导致我购买食物和水。 别的则是能不买，就不买了。 在语校 这周的课程依旧不是很难，虽然每次都会涉及到完全陌生的知识点，全程日本老师纯日语上课，用他们的理解为我们讲解哪些词语和文法。 今天做了个小考试，在手机上使用谷歌classroom软件完成。 手机做卷子嘛，都懂的。 不得不说，这种成绩高低无所谓，重要的是自己学会了这个知识点没，无关利益的感觉真好。 虽然，确实这样会导致我的学习非常的敷衍。 我的社交 出了最开始在班上找到的和我住很近的女生，以及某次排队认识的两个别的班的女生，我又认识了几位朋友。 当然都是女生。 在班上又认识了一位本科学习油画的朋友，现在准备攻读这边的插画专业。 然后通过别的班的那两位同学，又认识了她们宿舍的同学。 大家都是来这边考大学院的，文科或艺术专业。（目前遇到的艺术最多，其次社科，最后是理工科。数据仅参考我的身边。） 理工科我现在只知道我们班上有一个学机器人的，和一个学电气的。 我现在经常和那群宿舍的同学们一起出去吃饭，我们都冲着好吃且便宜的餐馆去。虽然这几次我们去的餐厅都不便宜。 这边我知道的最便宜的是松屋，最便宜的套餐，肥牛盖饭+生菜沙拉和一碗味增汤是420日元左右（21RMB），贵的当然也有八九百日元的套餐。还有个SAIZERIYA，西式的餐厅，最便宜的焗饭320日元。 这几天，跟着这几位同学去了书店，去了文具店。唯有书店的漫画书的价格还较为亲民，我看到《暗杀教室》的漫画单行本110日元（5RMB），有的是220日元。但是文具店也是一支笔好几十。 不得不说，从国内带文具是多么的明智，自动铅笔成了我不得不用的选择。因为笔芯便宜，还可以修改。 同样的斑马、百乐，甚至是我喜欢的白金钢笔，都比国内的价格高上一些，谢谢国内的商家没有涨价，谢谢晨光得力的一路护航，不然这书我是真的读不起。 现在认识了这么些朋友，虽然我们每天只有短暂的交流时间，但是让我孤独的学校生活好上了不少，非常感谢。 我的生活 现在基本上开始了两点一线的生活。 早上八点过一点出发去车站，到学校上课，上了课后和同学吃个饭，再去采买一些东西，回家。晚上大部分是靠着便利店的食物过活。 下午这两天主要是收拾东西，学习什么的，甚是惭愧，还没有起步。 就是这样简单的生活，或许也有最近几日的高温天气影响，回到家后就已经筋疲力尽。 不过现在要开始了，一边收拾屋子，一边看论文，一边复习我的课程。 好像我的生活很无聊，没有那些留学生的精彩灿烂。 说实话，这边物价这么贵，大学院也还没有考上，生活还是一团乱麻。 我第一次自己一个人handle所有的一切，在照顾自己好好生活上好像也没有什么经验和才能，唯一能松一口气的也就是经济还是靠着家里的支持（感谢我的爸爸妈妈）。 很多时候我回到家，打开门看到乱糟糟空荡荡的房间，心里面都沉沉的，我好像很难过，但是又没有难过到想哭，放下书包打开空调，也就这样了。 我好像有什么事情想说给什么人听，但是又好像没什么说的必要，也不知道该说给谁。 我也想出去走走，但是家里还那么乱，书还没有打开，出去妈的坐一趟地铁起步价9RMB，太阳仿佛要把人晒穿，算了算了。 打车？记得昨天准备去一个比较远的地方看看台灯（结果并没有买到，还走了一个多小时的路），做地铁就190左右的日元，如果打车大概是10倍的价格（数据来自谷歌打车价格计算） 虽然家里吹空调也贵。 这边，感觉做啥都束手束脚。 走路必须要随大流靠左，路太窄了稍微走随意一点就可能撞到人。 吃个饭都安安静静（大部分的店），然后店里面也窄得很。 吃饭贵，买东西贵，东西还买不到。 我不熟悉这边该去那里买需要的东西，只知道自己认识的那几个小店。大点的店，东西就不是一两倍的贵了。 网购，东西少，还贵，还撇。国内更好的配置，更低的价钱，这边的电商……好吧，有总比没有好，不然现在我还在奔波于买生活用品。 我点名表扬：淘宝、京东、拼多多。亚马逊你是什么品种的垃圾。（可能有些粗暴了，但是是真情实感） 我知道这有点那种，端起碗吃饭放下碗骂娘。 来说说使用体验吧： 首先是东西的丰富度：亚马逊完败。然后是页面的展示，网页版：亚马逊很简陋且，产品信息混乱，每次看一个新的东西，详细信息要用放大镜看才看得清，手机版：有一种怼在我脸上的美。功能上：送货要想免费就用时间换，无法跟踪详细物流信息，只能知道非常粗糙的信息。 要说好处，听说亚马逊买东西，评分的信任度很高，不用担心刷分，还有就是下单的时候说几号到就真的是几号到，京东或许可以达到这个效果，但是淘宝和拼多多，菜鸟驿站的时间不一定可以如此准时。 还有什么可以聊聊呢…… 说一些网上流传的对日本的印象，以及我经历的亲身体验吧。 首先是日本街道、河道真的那么干净么？路上看不到垃圾桶？ 说不上一尘不染，但是真的干净。走在路上给人一种干净整洁的感觉。之前去秋叶原路上路过了一条河，确实是没有垃圾漂浮。 也确实，很难找到垃圾桶。但是通常可以在贩卖机、便利店、超市和餐馆的背后找到垃圾桶，请注意也是需要分类的。别丢错了。 日本人讲规矩，什么红绿灯没人都是按规矩走。 不守规矩的人哪里都有。守规矩的肯定是大多数。 办事效率低 真。刚来日本需要办理在留卡的居住证明，由于这个月前来居住的外国人过多所以不少地方窗口都限时了，只能上午办理（我不理解）。我好不容易找到一个能办理这个手续的分局一样的地方。那个人叫我填了一张纸，也就是一些简单的个人信息。顺便办了普通的国民健康保险。从到我，等了半个多小时，到办完，花了一个半小时……俺也不明白就几行字，他在那个玻璃墙后面到底在干嘛搞了那么久。 地铁安静 真。我都不敢打电话，和朋友说话都是把声音压倒极低。 这里的地铁没有安检，前几天和大学同学聊到这个问题。这确实提高了通勤效率，但是也确实导致了几次大型恶性事件犯人行凶时的一路畅通。 服务好 我不知道日本人心里在想什么，但是作为客人，我很的感受到了他们的贴心和温柔，这就足够了。 目前差不多是这些。 接下来就不是我亲自经历的事情了，说一下我的朋友们分享在朋友圈的或是讲给我听的他们的故事吧。 我在手机店认识的那个很漂亮的女生，遇到了搭讪的大爷，邀请她去喝茶；遇到了一些大叔上下盯着她打量，说她可爱。走过了一条全是牛郎的街道。 我一个朋友，去了一家中餐厅，那里的老板对日本人点头哈腰，对中国人爱答不理，甚至优先给日本人上菜。 这个朋友的老师，买东西的时候，租房的时候，办手机卡的时候，被中国人坑，导致银行卡信用卡无法正常使用，签证可能都会受到影响。 希望大家都能远离这些不愉快。还有就是中国人别骗中国人。 嗯，虽然还有很多麻烦的事情没有处理好、等着做，但是好歹是一步步开始走上正轨（也真的花了很多的钱）。算不上高效，也有很多时候在摆烂，在emo，在睡觉，往前总是好的。 现在开始看书了，又会遇到很多的困难吧，害，除了努力好像也做不了别的什么，加油咯。 放几个图吧，导都导进来了： 拉面哦，720日元 一条街","link":"/2023/07/13/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-2/"},{"title":"留学日记-3","text":"来了日本一个多月了，简单记录一下自己的生活 说来惭愧，一个月了，也是保证了基本生活条件而已。 如同当时所担心的那样，确实是学习没有学多少，厨艺是突飞猛进。 语言学校的课零零散散，刚上了不到一个月的课程就迎来了暑假，本想着暑假弯道超车，现在看来是弯道翻车了。 不过多多少少还是学习了一点东西，虽然脑子里面大部分还是空荡荡的。 先说一些生活上的事情吧。 每个周末会集中采购一些蔬菜和肉类，放在冰箱里面作为一周的伙食，尽量价格控制在200rmb以下，但是并没有那么容易。 这边的蔬菜种类不是很多，而且价格大概是国内蔬菜的两到三倍。肉的价格反而更显得亲民了些。 每次去超市，选打折的蔬菜，降价的鸡肉、猪肉，一把意大利面和一包速成调料，就可以解决很多顿饭了，但是种类还是太过贫瘠，现在一想到吃饭的事情，就觉得疲惫。 数学题怎么做不知道，但是我学会了货比三家。 我记住了哪里的蔬菜便宜，那里的肉更丰富，哪里的牛奶、果汁物美价廉。 牛奶买最便宜的低脂牛奶，果汁每次买两盒，每次三餐喝一到两杯的话，一盒可以喝两天。 日本有一个很折腾人的地方，就是，哪怕是一模一样的牛奶、鸡蛋、蔬菜、饮料，在不同地段的超市里，价格可以相差10~50日元不等。这几个超市都在一个街区。 而其中便利店是最便利最贵的地方。最开始不知道，当了好多天的怨种。 所以只要能通过走路省哪怕10日元，20min以内我都能接受。 一个人生活的好处就是，每次买东西不需要买很多。但是弊端也随之明显，我也买不了很多。 虽然变着法子做菜了，但是翻来覆去也就那么几个菜能做。要考虑到蔬菜的处理时间、肉类的解冻时间等等等等。很多时候一边看着教程，一遍手里炒菜。 现在已经是习惯了火烧眉毛的场景了，基本上五次做饭，四次锅里面要着火。还好没有触发警报。 小小的屋子里是一点懒都偷不得，稍微没收拾，整个房子会一团乱。 要吃的蔬菜、肉，切好了就得把剩下的赶紧收到冰箱里，不然炒菜后装的盘子都没地方放。 炒完菜得立刻把菜板、锅、铲洗干净，不然一会儿吃完饭都没有干净地儿洗自己的饭碗…… 从没有想过自己会如此勤快。 简单展示一些自己这个月的厨艺吧（尽可能每次做饭都有绿色的东西出现是我最后的倔强）： 哈哈。 按时间顺序介绍这一个月我的娱乐生活。 最先和老乡去了足下烟花大会，第一次感受到日本烟花大会的魅力。 那天是晚上七点半开始放烟花，我们二人六点半临时决定前往。 五点过发消息，走不走，走！ 收拾好相机、水，就上路了。 一遍穿鞋子一边看着手里的导航，路上不断刷着小红书看看有没有现场的信息。 从距离目的地还有两站路远的地方就已经是人满为患了。 到车站，已经算是一脚跨入了烟花大会的会场。 我只在国内五一或者国庆的景区见到过这么多人 日本政府封锁了已烟花大会为中心的好几公里的路，为游客提供步行的通道。 不需要知道会场在什么方向，顺着人流走就行了。 路上隔一段距离就会看到指引的交警和路牌。 路边也会有很多小吃，最常见的就是焼きそば（炒面，但与国内的味道很不一样）。 这次的烟花大会大概七十多万人。 下一周又去了隅田川烟花大会。100万人。 烟花很好看。 虽然每次都非常担心，这么多人会不会赶不上回家的班车，车站估计会非常混乱吧。 但是非常意外，这些事情都没有发生。 即使整个道路水泄不通，但是得益于为了烟花大会而交通管制的道路范围极广，周围有好几个可以乘坐的电车或地铁站，人在一次又一次分流的过程中逐渐减少。 即使在车站口仍然有非常多的游客，但是大家都有序从闸机那里开始排队，一个一个刷卡进入车站。 即使有的人一时间拿不出卡，或者不小心排错了闸口（分id卡和车票），后面的人也是礼貌等待，前面的人要么快速换道要么到一边收拾。 没有因为人太多挤来挤去而导致大家难以进入车站。 关于日本人收拾垃圾的事情。 离开的时候，绝大部分的人都是自己把垃圾裹好之后带走，现场也会有专门情节场地的工作人员。 不是完全没有人乱丢，但是整体离开之后场地是十分干净的。 也有不少人在烟花结束后继续和朋友饮酒聊天，对他们来说，赏烟花是一部分，更多的是和朋友们的聚会。 这个暑假，去了东京国立博物馆（1000日元）、浅草寺（抽签100日元）和横滨（新宿出发30min）。 先说说东国立博物馆吧。这个让我心情复杂的地方。 说是博物馆，更准确的说是一个博物馆园区，里面有两到三个可参观的展馆。 最先去的是东洋馆。 里面陈列的大多数是来着东亚的文物。 整个一楼，几乎都是来自中国的。各种佛像、菩萨。或是断臂，或是只有一个头，来自中国的各个地方。 这些东西，都不是赠与给这个博物馆的。来源虽未曾调查，但是心里多少知道些。 能如此笃定地说是因为，赠与的展品是会明确标注的。 除了中国之外，还有东南亚国家的很多雕像、布制品。 …… 还有值得一提的就是，这个博物馆的介绍非常粗糙。 日语可能会详细的描述这个文物是什么干啥的，中文（或者没有中文）就会说一句：碗、杯…… 包括墙上的各种介绍也是如此。 先发布吧，这是几个月前写的了，现在十一月了我才想起来还有一篇没发。","link":"/2023/11/18/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-3/"},{"title":"搭建自己的Hexo","text":"下面来讲讲怎么创建自己的Hexo博客，难度不是很大，顺利的话问题也不会怎么有，不顺利当我没说。 你需要准备的东西或者配置： Git Node.js Hexo 你的宝贝github账号 Git和Node.js的教程太多了，我也是很久以前安装的这个东西，大家随便在CSDN找个教程安装一下就行。 安装步骤 安装Git 安装Node.js 安装Hexo并配置 和你的Github链接 粗糙分就是这么几个步骤。 安装Gitwindows：到git官网上下载,Download git,下载后会有一个Git Bash的命令行工具，以后就用这个工具来使用git。 问就是别的系统我不会 安装Node请自行搜索 检查node安装和版本，在cmd或者git bush（安装git后右键会有） 1node -v github注册和建库github注册是我见过的最友好的注册了相信不需要细讲。实在不会b站有手把手的视频教学…… 建立用于hexo博客的专用Repositories 进入自己的主页 Repositories列表 看到一个绿色的按钮，写的New New一个 怎么New ！！ （注意） 这里的名字一定要和你的账号名字一样Repository name：onername的那个name.github.io 别的不需要设置，跳过是可以的。我反正跳过了。 最后就是create。 这一步就结束了。 需要注意的地方 记得将SSH添加到Github 在git bash 中 12git config --global user.name &quot;yourname&quot;git config --global user.email &quot;youremail&quot; 然后创建SSH,一路回车 1ssh-keygen -t rsa -C &quot;youremail&quot; 在你的C盘的某个文件下面能找到一个.ssh的文件夹。C:/User/.ssh 这个文件夹中的.pub用记事本打开，之后到github中： 鼠标放在头像，进入settings 点击左边导航栏：SSH and GPG keys SSH 那里 New SSH key 把pub的秘钥粘进去。 在github上面差不多就这了。 安装Hexo这是官网：https://hexo.io/zh-cn/ 首先你需要准备一个空空荡荡的文件夹，名字无所谓，之后你的博客所有的配置都会下载到里面，包括你要发表的东西、主题等等。同样的，你瞎搞搞坏了博客，直接删掉这个文件夹，重新搭建Hexo就行。 假设你创建好了一个在D盘的博客文件夹 Blog 在这里，右键，打开 git bash输入： 123456npm install -g hexo-clihexo init myblogcd myblog //进入这个myblog文件夹npm install 就安装好了，这个时候文件夹应该啪的一下有很多东西。我现在知道的： theme：放你下载的主题的地方 source：用来存放你的文章 别的还不会用，以后更新。不过先贴出来： node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 _config：非常重要的配置文件 检查版本命令： 1hexo -v 在本地运行： 1hexo -s 就可以从localhost的那个地址看到自己的本地博客了。 将你的博客和github链接起来前面已经创建了的那个仓库，就派上用场了。和github结合起来之后，大家就可以通过 username.github.io访问到你的博客了！ 下面介绍咋个搞： 在创建的这个Blog 文件夹里，找到_config 这个文件，打开。 在deploy的部分修改： 1234deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: main 记得对应好你的用户名 你需要先执行： 1npm install hexo-deployer-git --save 让你用命令部署到GitHub。下载成功就可以，之后不会用到。 然后就是推送到你的github的那个io的仓库： 12hexo generatehexo deploy 成功之后就可以从https://YourgithubName.github.io.git找到你的博客了。每次写完或者修改了什么之后，记得 12hexo ghexo d (前面的缩写)才会刷新，相当于保存一下。不是非常的及时，差不多等个几分钟就行。 可能会搜到有的人在保存之前都先hexo c了一下，我不知道这是做什么，知道的话以后更新。不做好像问题不大。 每次写文章的步骤 hexo new &quot;Article Name&quot; hexo clean hexo g -d 如果要先写草稿： hexo draft &quot;Article Name&quot; hexo publish &quot;Article Name&quot; hexo clean hexo g -d 参考的博客： https://blog.csdn.net/sinat_37781304/article/details/82729029","link":"/2023/04/10/%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84Hexo/"},{"title":"迁移Hexok博客","text":"尝试迁移Hexo文件，因为换了新的电脑。 是Windows10 换到 Windows11。 一套做下来，其实和系统版本关系不大。 原来的Hexo是链接了Github和配置了新的主题的。 迁移背景 原来电脑的Node.js 和 Git版本都和新电脑不一样 原来的电脑Hexo博客已经和Github链接，且更新了一些文章 原Hexo主题不是默认主题，且修改了这个主题的配置 因为很早就打算换电脑了，也知道Hexo迁移没那么简单，所以很久没有更新了。 简单来说，我之前的Hexo博客已经基本上什么都设置了一遍了（主题、Github），所以迁移的时候我希望能尽可能地保存我之前的配置。 这段时间看了很多的迁移博客，看不懂，后来就直接勇敢向前冲了，目前看来迁移成功。所以记录一下。 1. 拷贝原来的博客文件网上看了很多的说法，但是我选择了保留的东西最多的一种。 除了node_models 全部拷贝！ 也有说public、deploy_git、.github什么的也可以不带的，但是好像也是在后面上传新的文章的时候，这些文件会自动更新，目前看来我拷贝过来也没有受到什么新的影响。 2. 环境配置 安装git并配置 安装Node.js 在CSDN上有非常多的教程，我就不献丑了。或许以后补充 我在安装新的环境的时候并没有按照之前版本安装，都是官网上最新的版本，目前使用正常。 建议： git 的user.name 和 user.email 都一样 新的SSH的title是为了表示你的电脑来自哪里，可以换成新的电脑的名字。 剩下的后面补充。 推荐的安装博客(感谢大佬们的分享）：安装Git，并与Github链接 Node.js安装与环境配置 3. 配置Hexo因为之前复制的时候没有带 node_models 文件所以需要创建一下。 在博客的文件夹下右键，点击 Git Bash Here 在命令行中依次键入： 1. 安装Node.js相关的包。npm install是一个命令行命令，它用于安装 Node.js 包。 Hexo 博客目录中运行 npm install 时，它会安装 package.json 文件中列出的所有依赖项。这些依赖项是 Hexo 博客正常运行所必需的。 也会创建node_models 这个文件夹了。 2. 创建Hexo环境npm install -g hexo-cli为电脑全局安装Hexo，没事全局就全局，自己用嘛。 3.安装 hexo-deployer-git 模块 npm install hexo-deployer-git --save 这是一个用于安装 hexo-deployer-git 模块的命令。 npm install 是用来安装 Node.js 模块的命令。 hexo-deployer-git 是一个用于将 Hexo 博客部署到 Git 仓库的模块。 --save 选项表示将模块保存到项目的 package.json 文件中，以便在其他电脑上重新安装时能够自动安装这个模块。 运行这个命令后，它会在当前目录下安装 hexo-deployer-git 模块，并将其添加到 package.json 文件中。您可以在 Hexo 博客的配置文件中配置相关选项，然后使用 hexo deploy 命令将博客部署到 Git 仓库。 补充说明好像这个过程中都没有看到自己迁移后的博客怎么和自己的GitHub连接到一起？其实在转移过来的_config.yml的最下面（我的是最下面），deploy的部分，已经设置了与Github对应仓库的配置，所以会自动绑定啦。 4. 检查 尝试发布新的文章： hexo new &quot;迁移Hexo博客&quot; 然后编辑一波 清除缓存 hexo clean可以写也可以不写的命令，用于清除缓存文件（db.json）和已生成的静态文件（public）。在某些情况下（尤其是更换主题后），如果发现对站点的更改无论如何也不生效，可能需要运行该命令。 生成静态文章 hexo g 本地预览效果 hexo s可以不这么做。 推送到远程服务器 hexo d 部署到远程服务器，会根据Hexo博客中的配置文件指定的部署选项进行推送。若已经在配置文件中制定了使用hexo-deployer-git并配置了Git仓库的地址，就会推送到Github仓库啦。 因为同步需要时间，过一两分钟之后打开自己的github博客主页，就可以看到自己的Hexo博客更新啦！ 而且之前的发布时间没有受到影响。 参考博客知乎：更换新电脑后，hexo无损方式重新部署CSDN：hexo史上最全搭建教程CSDN：换电脑后怎么迁移Hexo博客？","link":"/2023/06/26/%E8%BF%81%E7%A7%BBHexok%E5%8D%9A%E5%AE%A2/"},{"title":"hexo博客加密","text":"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 Hey, password is required here.","link":"/2024/02/12/hexo%E5%8D%9A%E5%AE%A2%E5%8A%A0%E5%AF%86/"},{"title":"留学日记-4","text":"2024年3月6日，东北大医工发表，考试合格。 仅以此篇记录我留学的哪些事情。虽然现在才算得上是刚刚走上旅途． 故事要从哪里开始说起呢？好像要从很久以前开始…… 我从小就不是一个有目标,有理想的人。脑子里也没有什么奇奇怪怪的欲望，按部就班的学着学校里面教的东西。 还好，脑子还算不错，运气也算得上极好，一路磕磕碰碰但是也顺风顺水。 我就读于一个非常厉害的高中，原本对学习无感的我，一下子跌落了谷底，这一触底，就是三年。 我是一个没有目标的人，没有目标，我也没有努力的理由。看着身边的人，抠破脑袋去做那些看都看不懂的题，读那些我理解不了的文章。我很佩服他们有这样的毅力和智力。 我从小就觉得，学的差不多就得了。但是我的差不多，好像在这个学校里面过于的烂了一点，这让我非常郁闷。 我觉得自己好像没那么烂，但是我的成绩和排名却告诉我不是这样。但是，要去提升成绩真的很麻烦。我不希望自己为了成绩读书，变成身边那些人那样。 差不多高二下，高三的时候。 “既然没什么梦想，就当个医生吧。” 我突然这么想到。 我没有绝顶的智慧，也没有对生活、物质的欲望。什么时候死了，也没有什么后悔的。如果不在乎家人的想法的话。 这样的人生，实在是太无聊了。 不如做一个好人死掉吧。 医生，只要在工作，就是在做好事。 我或许不会成为一个任何病症都能妙手回春的神医，但是我可以保证我开的每一个药都问心无愧。 而且，说不定涉及到帮助别人的事情上，我也能多一些干劲吧。 开一个自己的小诊所，帮街道的人解决一些小问题。 也能帮家里人治治病。 加上，自己对一些玄而又玄的东西有点兴趣，家里人也接触针灸推拿比较多。 那我去考个中医大学吧。 抱着这样的想法，我开始有了目标。 我调查了国内中医大学的排名，专业能力，高考分数线。 当时以我的能力，能考上成中医就不错了。 但是只有北中医是211大学。有211的牌子，或许能学到的东西能多一些呢？ 那就定北中医吧！ 从来觉得学习无所谓的我，开始钻研自己的不足，开始问同学要笔记…… 开始在每一节自习计算自己哪门课还得进步多少分才能考上北中医。 北中医好遥远啊……我记得我算了很多次，把我拿手的科目再提高一些，不拿手的科目再补上一些，怎么补都补不上北中医的分数线。 （当时甚至没算能进中医学，只是学校的分数线） …… 高考出分，成中医成了我的保底校。 但是，那天晚上，爸爸妈妈突然把我叫到卧室，他们坐在床上，床上摊着的是各种学校的资料和电话…… “中医这条路并不好走……刚刚问了一个学校的教授……宝贝，我们还是换条路吧。”“好。” 我一下子就失去了方向。 六个志愿，我一个都填不出来。 那去学地质吧，去科考队。 哥哥说别去。 去机械吧。 姐姐建议我三思。 我还能做什么呢？ 医生，总要开药吧。 …… 然后被录取了化工。 我就要这样过完我的一生么？ “我要出国留学。”“好。” 我们找到新东方，开始为去美国留学做准备。 化工的课并不轻松。都是大一，我们的课表远比别的专业满。 美国留学，为了减轻学费，我必须拿到最高一档的奖学金。 从来不知道努力为何物的我，陷入了无尽的痛苦。 我不知道打了多少次电话，抱怨他们让我走上这条路。 我不知道多少次埋怨自己，那天晚上为什么就答应了他们的话。 我发现，化工并没有像大人们说的那样，可以轻轻松松转到药学或者制药。 越查，越发现这条路的黑。 我得离开这个专业…… 大二，我以化工专业第一转到计算机。 在众多大佬云集的地方，我又找到了高中被碾压的感觉。 计算机是充满无限可能的领域，一定有和医学结合的方向吧？ 确实。 但是是真的难。 大二进去，我找到一个做医学影像处理的实验室。 因为实力太差被拒。 转NLP。被放养。 …… 英语这个的东西，我真的学不明白。 我背单词，做精听…… 我也不知道我学了些什么。成绩稳如老狗。 至少四六级可以划过。 TOFEL是真的不行。2000一次的报名费更是让我压力倍增。 为了它，我人生第二次报英语补习班。 我还是不懂，语言要怎么学。 后来…… 疫情彻底爆发。 中美再次紧张。 换个国家吧……反正英语没成绩、项目也没有。 “要不去日本吧？总觉得和日本还是有些缘分的。也便宜很多。也有人照应，听说那边做交叉的很多，日本医学也很厉害，说不定能有你喜欢的实验室。”“好。” 确实有缘分极了。 10年没正儿八经学过日语，自己买了一打N2的卷子，一做就是140分左右。 或许从我初中踏入那个日语教室起，有的齿轮就开始转动了。 22年，N2 166.小时候的我，一定觉得我帅极了吧。 我在寝室里上蹿下跳。 那时跟着塾断断续续的复习日语专业课。还没有找好学校，没有确定研究方向，没有写研究计划书，一切还很迷茫。 现在的我来告诉她：这种迷茫将持续很久很久很久…… 最开始选择京大的医疗情报、早大的生物情报、筑波随便。 前两个都不需要学数学。数学就搁置了。 当时一对一的老师，根本没有帮我研究这两个学校的考题，唬我说考的都一样，实际上并不是。 但是也只好跟着上课。 后来发现，京大的专门考试不知所云，早大要考计网。 筑波找不到web page，日常迷路。 再后来，开始做毕设了，修考复习暂停。 毕业没几天，就飞到日本。 我没能参加夏季考试，冬季的希望又非常渺茫。刚来日本的我适应不了这里的物价和什么都要自己来的生活…… 痛苦、迷茫。 只要一停下来，我就被这两种情绪吞噬。 无法呼吸…… 语校每天无意义的上午反而成了我能抓住的木板，得到短暂的呼吸。 我认识了很多朋友。 很多很好的朋友。 大家和我有一样的痛苦，但是有不一样的应对手段。 我第一次真正开始思考：“我想要怎样生活下去？” 每天吃什么饭？ 和什么人吃饭？ 交什么朋友？ 下个周末怎么过？ 家里要不要再添置点东西？ 要不要去哪里玩？一个人，还是和朋友？和哪个朋友？ 我去了说走就走的烟花大会，爬了手脚并用才能上的山…… 认识了一些萍水相逢的人，交到了志同道合的朋友…… 我似乎开始真正成长为一个人。 开始重新找冬季能考的学校。 看了不知道多少篇文献，修修改改的计划书，最终还是进入了废弃箱。 已经记不得自己陷入过多少次自我怀疑……在深夜辗转反侧，难以入睡。 塾的老师劝我放弃吧，医疗+情报太少了，你又不愿意去做图像处理。 塾的老师问我，到底是考上重要，还是这个方向重要…… 那么多人来日本都是混个学历，我又在执着什么？ 可是我好不容易来到这里…… 可是你做了这个研究，又不会做这个工作。 我都没法做这个工作了，至少让我研究的时候做这个研究吧…… 我到底……为什么来这里来着？ 我在城市角落的出租屋里，痛苦地翻找着一个又一个的研究科页面。 那是一个平平无奇的下午。 我打开了东北大的界面。 其实之前打开过好几次了，没有找到合适的实验室。 有生物方向的，有NLP的，都很厉害，但是都差那么一点。 我打开了过去问，看了看范围，倒还好。 突然，在顶部，“医工研究科”几个字映入眼帘。 不会吧？ 我几乎是颤抖着打开学院官网。 我翻找着一个又一个的实验室。 直到看到几个字：“使用深度学习技术，为医学……” 找到了，真的有！ 我兴奋地从椅子上起来，手在头上拨弄我的头发，把自己的短发弄得一团糟。 阳光，从对面两栋楼的夹缝里，打到我的身上…… 或许上天在告诉我是这里。 但是东北大……日本数一数二的学校。 即使是这样而也要试试—— 和日本朋友面基的时候，忍不住还是透露了这个消息。她送我了一个学业的目出しダルマ，让我许愿后点上左眼，如果愿望实现了，就点上右眼。 我回到家，捏着目出しダルマ许愿：希望合格东北大。 但是自嘲地想到：会不会太为难他了，不会单眼一辈子吧…… 补充上岸就好，但心里还是期望着东北大。 我做不了一点东北大的题…… 我拿给私塾的老师，他不提前做，而是上课才看题，才思考…… 但是一节课，他才能思考一个题。 还没做完，也不一定对。 他让我放弃。 我不甘心…… 又发生了很多难过的事情，最终换了老师。 新的老师问我：非医学不可么？ 我：医学优先，数据分析类的都行。 …… 总之先把别的课学了吧。 先发个邮件问问教授，看看冬季有没有机会呢，说必须要准备面试。 我发了邮件，做好了毫无相关研究经验和成绩的自己会被拒绝。 但是教授还是给了我机会，只是…… 硬着头皮答应了。 开始写计划书。 教授说我写的很好。 开始读论文。 教授问我能不能写英语……（呵呵，不行也得行） 开始复现实验。 感谢我的琪琪和bro。 面试，20min汇报，40分钟battle。 拿到内诺。 开始备考。 加了实验室的学长学姐好友，心情++。 然后是暗无天日的备考。但是有了学长的助力，顺利了很多。 谢谢学长学姐的一路支持与陪伴。 他们给我讲了很多实验室和备考的事情。 虽然感觉有不少的隐患（嘤），但是感觉氛围很好，好想加入他们啊。 感觉私塾帮不了我什么了，开始完全一个人奋斗。 一月初，完成一轮刷题。 网上认识了一个也要考东北大的兄弟，开始结伴学习。他逆天的社交能力为我们套到不少的资料，有的题豁然开朗。 二月初，完成二轮刷题，发现很多问题。 二月底考试前：完成三轮刷题。 27号，到达仙台。风巨大，感冒了。 28号，考试第一天，内容和往年完全不同，能做，但是身体欠佳。 29号，考试第二天，考题完全变了，没复习到。但是能写的都写了。 下午面试，教授们被我流利且幽默的性格逗笑。 晚上我就速回东京，去第二天一个很好的语校老师的最后一节课。 等待结果的焦虑的一周…… 3月6号，哄邱兄陪我逛街，等待合格的发表。 从来没觉得逛街那么漫长……之前和他一起逛街的时候明明一下子就天黑了。 17：00 秋叶原某个不知名的小店里，我颤抖地打开医工的主页……好几次没找到名单。最后在主页找到了位置…… 修士录取……只有三个人的编号。 “我记得面试有六个人……” “我是多少号来着……” WMP3002…… “卧槽啊啊啊我合格了啊啊啊啊啊啊！！！！！” 我挥拳不停击打我兄弟的手臂，不敢叫太大声，会影响别的顾客。 截图，发到父母群。 爸妈立刻打来电话。 他们在国内比我还紧张…… 非常感谢一路上父母给我的支持，无数次给他们宣泄自己的压力，他们无法体会，但还是努力安抚我……很抱歉让他们担心了。 感谢安琪，陪我游戏，听我抱怨，和我一起骂东北大的出题老师，帮我改代码，陪我面试准备，改ppt…… 感谢邱兄，带我玩，带我吃饭，一起拍照，被我暴击…… 感谢金姐，带着我这个小屁孩，真是给姐姐添麻烦了，还被迫回忆了好多哈哈哈哈的回忆。 感谢语校的朋友们……，语校生活短暂，但因为你们而充满美好回忆。 感谢目出しダルマ，一直提醒我最初找到这个实验室的心情，让我坚持了下来，多亏了你呢~ 眼睛能点上真是太好了呢！ 感谢有点用但不多的塾……学到很多……的东西。 考学之路，算是告一段落了。 后面的生活才是重头戏。 学长学姐在我备考痛苦的时候和我说，进实验室之后的痛苦只会更甚。 我还能保持初心，走好这条路吗？ 我不知道，只能一遍又一遍的警醒自己…… “不忘初心，方得始终。 初心易得，始终难守。” 请佛祖保佑弟子，坚守初心，得有始终。 大医精诚 初记于：2024年3月18日","link":"/2024/03/18/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-4/"},{"title":"文件或目录损坏且无法读取","text":"在导照片的时候……出现了这个提示。 这是GPT给的答案。 遇到U盘提示“文件或目录损坏且无法读取”的问题时，可以尝试以下几种方法来解决： 使用Windows磁盘检查工具： 打开“运行”窗口（可以按Windows+R），输入cmd打开命令提示符。 输入chkdsk X: /f（其中X是U盘的盘符）并回车，这将修复磁盘上的错误。 更改驱动器号和路径： 在“计算机管理”中选择“存储”-&gt;“磁盘管理”，找到U盘对应的“可移动磁盘”。 右键点击并选择“更改驱动器号和路径”，然后选择一个未被占用的盘符。 卸载并重新连接U盘： 在“设备管理器”中找到“通用串行总线控制器”，下的“USB大容量存储设备”。 右键点击并选择“卸载设备”，然后重新插入U盘。 如果上述方法都不能解决问题，可能需要使用专业的数据恢复软件来尝试恢复数据，或者联系专业的数据恢复服务。在尝试修复之前，建议不要对U盘进行写入操作，以免数据丢失。 希望这些方法能帮助您解决问题。如果还有其他问题，欢迎继续咨询。🛠️ 源: 与必应的对话， 2024/3/21(1) U盘出现文件目录损坏或无法识别和读取，这该怎么办？ - 知乎. https://www.zhihu.com/question/22170790.(2) U盘出现文件目录损坏或无法识别和读取，这该怎么办？ - 知乎. https://www.zhihu.com/question/22170790/answers/updated.(3) U盘无法访问 “文件或目录损坏且无法读取” 的解决方法 - 搜狐. https://www.sohu.com/a/752395656_121271335.(4) U盘文件或目录损坏且无法读取的正确解决方法 - 百家号. https://baijiahao.baidu.com/s?id=1787759357483741041.(5) 关于u盘文件或目录损坏且无法读取的解决方法 - CSDN博客. https://blog.csdn.net/lmq1993/article/details/123241687.","link":"/2024/03/21/%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96/"},{"title":"计算机会议及期刊总结","text":"【权威】CCF(中国计算机协会) A会/刊 B会/刊 C会/刊 全部会议汇总 计算机图形学会议A类","link":"/2024/05/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BC%9A%E8%AE%AE%E5%8F%8A%E6%9C%9F%E5%88%8A%E6%80%BB%E7%BB%93/"},{"title":"PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆","text":"1 环境配置检查显卡： 在命令行底部右键打开任务管理器 也可以查看到GPU的型号![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/显卡检查.png]] conda#conda 配置一个特定的环境 1conda create -n [env name] python=[python version] 激活环境 1conda activate [env name] 查看创建过的环境 1conda info -e 技巧pip 查看工具包1pip list 安装Pytorch 检查电脑的GPU是否支持pytorch打开命令行，输入nvidia-smi![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/检查GPU.png]] 查看驱动版本 Driver Version 需要保持版本号大于coda的需求的 如果不满足，可以去英伟达的官网更新驱动 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240502215043.png]]选好后，输入conda命令即可 检验安装123&gt;&gt;python&gt;&gt;import torch # 没有报错就是安装成功&gt;&gt;torch.cuda.is_available() # 检查是否可以使用GPU ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/检查torch是否可以使用GPU.png]] torch.cuda.is_available()返回False进行以下步骤进行排除： 进入https://www.nvidia.cn/geforce/technologies/cuda/supported-gpus/ 检查是否支持cuda 检查驱动版本nvidia-smi 不够高就去更新 在正常使用一段时间后，安装各种包突然又返回False或者各种冲突。解决方案： 卸载torch全部重来：conda remove pytorch torchvision 2 编辑器的选择PyCharm![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/安装PyCharm配置.png]] 配置PyCharm![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/创建项目的配置.png]] 一些技巧python的console，可以检查一些变量或者一些命令、方法，简便直观。![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/python console.png]] Jupyterjupyter 配置在安装cuda的时候，这个默认安装在base的环境中。但是base中没有安装torch。可以再在base里面安装一次torch，但是还是在之前安装的torch环境中安装一下jupyter吧~ 安装一个个包nb_conda 是一个用于 Jupyter Notebook 的插件，它可以让你在 Notebook 中使用 Conda 环境。通过运行 conda install nb_conda，你可以将这个插件安装到你的 Conda 环境中，然后在 Jupyter Notebook 中使用。这样你就可以方便地在 Notebook 中管理和切换不同的 Conda 环境了。 1conda install nb_conda 在命令行中切换到对应的项目目录最开始在C盘![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/命令行切换目录.png]] 创建项目![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240502221306.png]] 3 Python的两大法宝函数 dir(): 打开，看见 help(): 说明书 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/dir和help.png]] 4 浅对比PyCharm，python控制台和Jupyter rerun的区别 PyCharm会全部重新运行。 控制台：从错误的地方开始运行 notebook：任意行为块，每一块重运行。 5 PyTorch加载数据 Dataset Dataaloader Dataset: 获取的数据是混乱的，但是可以进行编号 可以获取数据和label 如何获取每一个数据和label 总共有多少个数据 Dataloader： 对Dataset进行打包 提供不同的数据形式 #os的用法 os.path.join(dir1,dir2)：可以根据系统自动拼接地址 1234567891011121314151617181920212223242526272829303132333435363738''' @Project ：pythonProject @File ：read_data.py @IDE ：PyCharm @Author ：周大猛 @Date ：2024/05/02 23:50 ''' from torch.utils.data import Dataset from PIL import Image import os class MyDataset(Dataset): def __init__(self, root_dir, label_dir): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(root_dir, label_dir) self.img_path = os.listdir(self.path) def __getitem__(self, index): &quot;&quot;&quot; 读取每一个图片 :param index: :return: &quot;&quot;&quot; img_name = self.img_path[index] img_item_path = os.path.join(self.path, img_name) img = Image.open(img_item_path) label = self.label_dir return img, label def __len__(self): &quot;&quot;&quot;获得数据集的长度&quot;&quot;&quot; return len(self.img_path) if __name__ == '__main__': root_dir = &quot;dataset/train&quot; ants_label_dir = &quot;ants&quot; bees_label_dir = &quot;bees&quot; ants_dataset = MyDataset(root_dir,ants_label_dir) bees_dataset = MyDataset(root_dir,bees_label_dir) # 拼接数据集，按顺序拼接。 train_loader = ants_dataset + bees_dataset 5.1 TensorBoard的使用 对图像进行变化：统一尺寸等 对图像进行展示 SummaryWriter原文部分介绍： 12345678910111213141516171819202122class SummaryWriter: &quot;&quot;&quot;Writes entries directly to event files in the log_dir to be consumed by TensorBoard. The `SummaryWriter` class provides a high-level API to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training. &quot;&quot;&quot; def __init__( self, log_dir=None, comment=&quot;&quot;, purge_step=None, max_queue=10, flush_secs=120, filename_suffix=&quot;&quot;, ): &quot;&quot;&quot;Create a `SummaryWriter` that will write out events and summaries to the event file. Args: log_dir (str): Save directory location. Default is runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run. Use hierarchical folder structure to compare between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc. for each new experiment to compare across them. comment (str): Comment log_dir suffix appended to the default ``log_dir``. If ``log_dir`` is assigned, this argument has no effect. purge_step (int): When logging crashes at step :math:`T+X` and restarts at step :math:`T`, any events whose global_step larger or equal to :math:`T` will be purged and hidden from TensorBoard. Note that crashed and resumed experiments should have the same ``log_dir``. max_queue (int): Size of the queue for pending events and summaries before one of the 'add' calls forces a flush to disk. Default is ten items. flush_secs (int): How often, in seconds, to flush the pending events and summaries to disk. Default is every two minutes. filename_suffix (str): Suffix added to all event filenames in the log_dir directory. More details on filename construction in tensorboard.summary.writer.event_file_writer.EventFileWriter. Examples:: from torch.utils.tensorboard import SummaryWriter # create a summary writer with automatically generated folder name. writer = SummaryWriter() # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ # create a summary writer using the specified folder name. writer = SummaryWriter(&quot;my_experiment&quot;) # folder location: my_experiment # create a summary writer with comment appended. writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;) # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ &quot;&quot;&quot; 三种用法 默认保存到一个路径 writer = SummaryWriter() # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ 自定义保存到的文件夹 writer = SummaryWriter(&quot;my_experiment&quot;) # folder location: my_experiment 可以对文件名加入一些comments writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;) # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ writer.add_scalar()![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/scalar的参数.png]] 效果打开方法： 指定路径 –logdir 指定端口 –port 1tensorboard --logdir=[logs] --port=[6007] ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/tensorboard效果.png]] 但是运行多次之后可能显示图像会出bug，可以选择删掉之前的log writer.add_image() 读取图片 识别类型： numpy tensor string 但是我们常用的PIL的Image是JpegImageFile类型，所以不符合，需要转换，或者直接用别的方法读取图片，如OpenCV 在使用numpy读取图片的时候，每个通道的顺序可能与add_image默认的顺序不一样，可以ctrl进入add_image查看手册，手动设定通道顺序 1234567891011from PIL import Image from torch.utils.tensorboard import SummaryWriter import numpy as np writer = SummaryWriter('logs') image_path = &quot;dataset/train/ants/5650366_e22b7e1065.jpg&quot; iamge_PIL = Image.open(image_path) img_array = np.array(iamge_PIL) # 但是这里形状不对,np读出来之后，通道在最后：(375, 500, 3) print(img_array.shape) writer.add_image(&quot;image&quot;, img_array, 1,dataformats='HWC') # 根据官方文档里面，指定type的顺序 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/add_image效果.png]] 修改add_image的第二个参数step，可以在进度条处出现拉出新的图![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/add_image_step2.png]] writer.add_graph(net,input)可以查看网络的结构 1234# 查看网络结构的方法 writer = SummaryWriter(&quot;./logs&quot;) writer.add_graph(net,input) writer.close() ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/tensorboard查看网络结构.png]] 5.2 Transform指的是：transforms.py文件，里面又很多的“工具”： toTensor resize 拿特定格式的图片，丢进去，得到需要的图片结果。 引入的方式 1from torchvision import transforms ToTensor12tensor_trans = transforms.ToTensor() # 实例化这个工具 tensor_img = tensor_trans(image) # 使用这个工具，输出一个结果 为什么需要Tensor这个数据类型？ tensor包含了神经网络中使用的一些参数 另一种读取方式：nparray使用OpenCV. 导入opencv的方法： 1pip install opencv-python 归一化Normalizationoutput[channel] = (input[channel] - mean[channel]) / std[channel] ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/归一化的公式.png]] 均值和标准差都是0.5 1234trans_norm = transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]) img_norm = trans_norm(img_tensor) writer.add_image('Normal_img', img_norm) Resize()![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Resize说明.png]] 12345678910# Resize print(img.size) trans_resize = transforms.Resize((512,512)) # img PIL --&gt; resize --&gt; img_resize PIL img_resize = trans_resize(img) # img_resize PIL --》to_tensor --&gt; img_resize tensor img_resize = trans_totensor(img_resize) writer.add_image('Resize_img', img_resize,0) print(img_resize) writer.close() Compose()![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Compose 的说明.png]] 123456# Compose - resize -2 trans_resize_2 = transforms.Resize(64) # 这里列表的顺序需要保证前一个的输出类型是后一个的输入类型。 trans_compose = transforms.Compose([trans_resize_2,trans_totensor,]) img_resize_2 = trans_compose(img) RandomCrop()随机裁剪按照设定的尺寸随机在图片内裁剪规定尺寸大小的图片。 123456# RandomCrop trans_random = transforms.RandomCrop(64) trans_compose_2 = transforms.Compose([trans_random,trans_totensor,]) for i in range(10): img_crop = trans_compose_2(img) writer.add_image('Random_img', img_crop,i) 总结 关注输入和输出的类型 多看官方文档 看初始化的参数 输出类型可以print查看，或者debug 6 Torchvision的数据集使用官网链接 如果下载速度太慢，可以将下载路径粘贴到迅雷中进行下载。 数据集的参数设置很多都是相同的，教程中以CIFAR10为例：![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/CIFAR10参数.png]] 设置数据集路径 设置训练or测试集合 transform要做的操作 download：是否要网络下载（准备好了就False，没准备就True） 1234import torchvision train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True) test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True) 可以在transform参数，设置对数据集的操作，也是可以打包送进去的。 123456789101112131415161718192021import torchvision from torch.utils.tensorboard import SummaryWriter dataset_transform = torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=dataset_transform) test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=dataset_transform) print(test_set[0]) writer = SummaryWriter(log_dir='./logs') for i in range(10): img, label = test_set[i] writer.add_image('test_img', img, i) 7 Dataloader的使用将数据加载到神经网络中。 如何取数据可以由Dataloader进行设置。 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Dataloader文档.png]] 常用参数设置： batch_size shuffle:洗牌 num_workers:多少个进行进行加载（但是win上有时候出现错误） drop_last:分组除不尽的时是否舍去一些数据。 DataLoader会分别把数据集的数据和label，按照batch_size的大小，进行打包。 如果设置了shuffle，一个epoch打乱一次。 12345678910111213141516171819202122232425262728import torchvision from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter from torchvision import transforms data_transforms = transforms.Compose([transforms.ToTensor(),]) test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=data_transforms) test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True,num_workers=0, drop_last=False) img, label = test_data[0] print(img.shape) print(label) writer = SummaryWriter('./logs') # 多次让dataloader取数据，shuffle就会在每次的epoch影响取值，True会打乱数据集 for epoch in range(10): step = 0 for data in test_loader: imgs, labels = data # 注意这里用的是images writer.add_images('Epoch:{}'.format(epoch), imgs,step) step += 1 writer.close() ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Epoch和dataloader.png]] 8 网络搭建https://pytorch.org/docs/stable/nn.html 8.1 Containers最常用的模块，提供神经网络的最基本的框架 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240510001631.png]] nn.Module》 https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module 123456789101112131415import torch.nn as nnimport torch.nn.functional as Fclass Model(nn.Module): def __init__(self): # 调用父类的初始化 super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): # 神经网络的前向传播 x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) # 这个demo进行了两次非线性卷积 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240510002025.png]] 8.2 卷积层操作与卷积层（1）卷积操作基本原理在全连接（Affine）层中存在忽略了数据形状，它直接将整个图片拉成一维数据输入到了神经网络。 因此导致了，形状中含有的空间信息被忽略。 卷积层的优点就是，可以保持形状的不变，或许能更好的理解图片的形状信息。 卷积层的输入输出被称为特征图，。!PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240513161728.png]]主要用torch.nn 的部分，对functional封装更好 卷积核：（类似图像处理的滤波器）一个小矩阵，对图像矩阵进行一坨一坨的计算 stride = 滤波器每次移动的举例 会影响最后得到的卷积输出的形状 越大，输出的矩阵越小（？） 官网参数介绍：conv2d input – input tensor of shape (minibatch,in_channels,𝑖𝐻,𝑖𝑊)(minibatch,in_channels,iH,iW) 要设置batch的带线啊哦 weight – filters of shape (out_channels,in_channelsgroups,𝑘𝐻,𝑘𝑊)(out_channels,groupsin_channels​,kH,kW) bias – optional bias tensor of shape (out_channels)(out_channels). Default: None stride – the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1 padding （在图像左右两边对图像进行填充）– implicit paddings on both sides of the input. Can be a string {‘valid’, ‘same’}, single number or a tuple (padH, padW). Default: 0 padding='valid' is the same as no padding. padding='same' pads the input so the output has the same shape as the input. However, this mode doesn’t support any stride values other than 1. 填充的内容默认为0 也会对输出结构造成影响 1234567891011121314151617181920212223242526272829303132333435363738import torch import torch.nn.functional as F input = torch.tensor([[1,2,0,3,1], [0,1,2,3,1], [1,2,1,0,0], [5,2,3,1,1], [2,1,0,1,1]]) kernel = torch.tensor([[1,2,1], [0,1,0], [2,1,0]]) # print(input) # print(kernel) # # print(input.shape) # print(kernel.shape) # 转换成nn.conv需要的形状 input = torch.reshape(input,(1,1,5,5)) # shape:batch，通道，长，宽 kernel = torch.reshape(kernel,(1,1,3,3)) # print(input) # print(kernel) # # print(input.shape) # print(kernel.shape) output1 = F.conv2d(input,kernel,stride=1) print(output1) output2 = F.conv2d(input,kernel,stride=2) print(output2) output3 = F.conv2d(input,kernel,stride=1,padding=1) print(output3) （2）卷积层![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240513143027.png]] https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d Parameters in_channels (int) – Number of channels in the input image out_channels (int) – Number of channels produced by the convolution 》 有几个卷积核，就会导致输出有几个维度，也就是channels ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240513143637.png]] kernel_size (int or tuple) – Size of the convolving kernel 个 stride (int or tuple, optional) – Stride of the convolution. Default: 1 padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0 padding_mode (str, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros' dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1 groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240513151144.png]]根据这两个公式，推到论文中的padding和stride #padding计算 #stride计算如果卷积前后尺寸不变，padding = （卷积核尺寸-1）/2 ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240513152311.png]] #批处理批处理：这里将多个图像打包成一个batch，让图像变成了四维数据（batch_num, channel,height,width)进行计算，加快运算效率 8.3 池化#池化 特征 无需学习参数（与卷积的不同） 只是从目标区域获得最大值或者平均值 通道数不发生变化 计算按照通道独立进行 对微笑的数据位置变化具有鲁棒性（健壮） Parameters kernel_size (Union[_int,_ Tuple[_int,_ int]__]) – the size of the window to take a max over stride (Union[_int,_ Tuple[_int,_ int]__]) – the stride of the window. Default value is kernel_size padding (Union[_int,_ Tuple[_int,_ int]__]) – Implicit negative infinity padding to be added on both sides dilation (Union[_int,_ Tuple[_int,_ int]__]) – a parameter that controls the stride of elements in the window return_indices (bool) – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later ceil_mode (bool) – when True, will use ceil instead of floor to compute the output shape 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torch import torch.nn as nn import torch.nn.functional as F import torchvision.datasets as datasets from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter from torchvision import transforms dataset = datasets.CIFAR10(root='./data', train=False, download=True,transform=transforms.ToTensor()) dataloader = DataLoader(dataset, batch_size=64, shuffle=True) # input = torch.tensor([ # [1,2,0,3,1], # [0,1,2,3,1], # [1,2,1,0,0], # [5,2,3,1,1], # [2,1,0,1,1] # ],dtype=torch.float32) # # input = torch.reshape(input,(-1,1,5,5)) # print(input.shape) class T(nn.Module): def __init__(self): super(T, self).__init__() self.pool = nn.MaxPool2d(3,ceil_mode=False) def forward(self, x): output = self.pool(x) return output tt = T() # result = tt(input) # print(result.shape) # print(result) writer = SummaryWriter('./maxpool_logs') step = 0 for data in dataloader: imgs, labels = data writer.add_image('Input', imgs,step,dataformats='NCHW') outputs = tt(imgs) &quot;&quot;&quot; 最大池化不会改变形状， 所以不用像卷积那样还要将得到的图片进行reshape &quot;&quot;&quot; writer.add_image(&quot;Output&quot;, outputs,step,dataformats='NCHW') step += 1 writer.close() 8.4 非线性激活（1） ReLu（Rectified Linear Unit）$$y =\\begin{cases}x &amp; \\text{if } x &gt; 0 \\0 &amp; \\text{if } x \\leq 0\\end{cases}\\tag{1}$$$$\\frac{\\partial y}{\\partial x} =\\begin{cases}1 &amp; \\text{if } x &gt; 0 \\0 &amp; \\text{if } x \\leq 0\\end{cases}\\tag{2}$$ ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240514104621.png]]![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240514110338.png]]这个inplace（替换）： True：直接把变换后的值，放到input的那个变量里面 False：把变换后的值，需要一个新的变量来接收 12345678910111213141516import torch i = torch.tensor([[-1, 2, 3], [4, -5, 6], [7, 8, -9]]) i = torch.reshape(i,(-1,1,3,3)) class DemoModule(torch.nn.Module): def __init__(self): super(DemoModule, self).__init__() self.relu1 = torch.nn.ReLU(inplace=False) def forward(self, x): return self.relu1(x) mod = DemoModule() output = mod(i) print(output) (2)Sigmoid$$\\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)}$$ 8.5 Linear modelnn.LinearParameters in_features (int) – size of each input sample out_features (int) – size of each output sample（下一层要输出的个数） bias (bool) – If set to False, the layer will not learn an additive bias. Default: True ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240514142823.png]] 就是全连接层。把数据摊平之后，进行kx+bias的变化，再输出到指定数目的节点去。 #torchflattentorch.flatten：把数据展开到一维 9 损失函数与反向传播损失函数神经网络通过学习损失函数（Loss Function）寻找最优权重参数。 计算实际输出和目标之间的差距 为更新输出提供依据（反向传播），grad（梯度） #损失函数常用的损失函数： 均方误差（mean squared erro）![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240514151828.png]] 交叉熵误差![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240514151848.png]] 只计算对应正确解标签的输出的自然对数。 1234567891011121314import torch.nn as nn import torch loss = nn.L1Loss() input = torch.randn(3, 5, requires_grad=True) target = torch.randn(3, 5) print(input) print(target) output = loss(input, target) print(output) loss_mes = nn.MSELoss() result_mse = loss_mes(input, target) print(result_mse) 反向传播![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240519105814.png]] 10 优化器#优化器用backward进行反向传播，计算出每一个节点的参数，有了参数梯度之后，就可以选择合适的优化器进行优化，对loss达到一个降低的目的。 https://pytorch.org/docs/stable/optim.html SGD随机梯度下降#SGD 初始化 1234optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)optimizer = optim.Adam([var1, var2], lr=0.0001) 初始化参数![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240520002324.png]] 1234optim.SGD([ {'params': model.base.parameters(), 'lr': 1e-2}, {'params': model.classifier.parameters()} ], lr=1e-3, momentum=0.9) [!NOTE]这里的代码使用了PyTorch中的optim.SGD优化器来训练模型。这个优化器采用了随机梯度下降（Stochastic Gradient Descent，SGD）的方法，并添加了动量（momentum）来加速训练过程。 具体解释如下： optim.SGD: 这是一个优化器，它实现了随机梯度下降算法。SGD是一种常用的优化算法，用于调整模型参数以最小化损失函数。 params: 这里指定了要优化的参数集合。代码中将模型的参数分成了两组，分别设置了不同的学习率（learning rate，lr）。 {'params': model.base.parameters(), 'lr': 1e-2}：这表示模型的基础层（base）参数使用一个学习率为0.01（1e-2）的值进行优化。 {'params': model.classifier.parameters()}：这表示模型的分类器（classifier）层的参数。没有指定单独的学习率，因此这些参数将使用外层的学习率1e-3。 lr: 学习率是一个超参数，控制每次参数更新的步长。这里有两个学习率： 1e-2（0.01）用于基础层参数。 1e-3（0.001）用于分类器层参数（外层指定的学习率）。 momentum: 动量是一个超参数，用于加速SGD在相关方向上的收敛，并抑制震荡。动量项在参数更新时引入了历史梯度的累积，使得优化过程更稳定。这里设置的动量值为0.9。 综上所述，这段代码的含义是使用带有动量的随机梯度下降算法来优化模型的参数，其中基础层参数的学习率设置为0.01，分类器层参数的学习率设置为0.001。动量参数设置为0.9。这样可以在训练过程中更好地控制模型的更新步长和收敛速度。 使用demo1234567891011for input, target in dataset:# - 在进行反向传播和梯度计算之前，先将优化器中的所有参数的梯度缓存清零。 optimizer.zero_grad() output = model(input) # 计算模型输出 `output` 和目标标签 `target` 之间的损失（误差） loss = loss_fn(output, target) # 进行反向传播，计算损失相对于模型参数的梯度 loss.backward() # - 使用计算得到的梯度，按照优化算法更新模型的参数。 # - 这里的 `optimizer` 是前面定义的优化器（如 `optim.SGD`），它根据参数的梯度和学习率来调整参数的值，使损失函数逐渐减小，从而优化模型。 optimizer.step() 训练部分代码： 123456789101112131415161718192021loss = nn.CrossEntropyLoss()# 交叉熵 net = NeuralNetwork() optimizer = torch.optim.SGD(net.parameters(), lr=0.01) for epoch in range(20): running_loss = 0.0 # 每次开始前，把loss设置为0 for data in test_loader: &quot;&quot;&quot; 这个for相当于只对data进行了一轮的学习， 通常需要好几轮的学习，才能有所改善。 所以需要外层的epoch &quot;&quot;&quot; imgs, labels = data outputs = net(imgs) result_loss = loss(outputs, labels) optimizer.zero_grad() # 对之前的记录清零 result_loss.backward() optimizer.step() # print(result_loss) running_loss = running_loss + result_loss # 整体误差总和 print(&quot;epoch:{}, loss:{}&quot;.format(epoch, running_loss)) 11 现有网络模型的使用和修改在pytorch的官方文档中，torchvision或torchtext等文件中，包含了相关领域中的经典网络模型。 11.1 VGG简介常用的版本： vgg16 pretrained：在ImageNet中与训练(这个数据集130G+，而且不能torchvision直接下载，需要自己寻找资源) progress：下载进度条 vgg19 初始化的时候，True会下载参数（很大） VGG16常被用来作为迁移学习等模型的前半部分，用于提取一些图像的特殊特征，在后续的模型中对这些特征进行一个进一步的学习。 利用现有的网络，套到自己的数据集上VGG使用了ImageNet进行训练，输出的最后一层与ImageNet的类别数量相同，都是1000，如何把这个现有的模型改成我需要的模型？ 之前的数据集为例 方法一：把最后一个输出层后追加一层input为10000，output为10的线性层。1vgg16_false.add_module('add_linear', nn.Linear(1000, 10)) ![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240520135525.png]] 如果要加到上面那个括号（classifier）里面： 1vgg16_false.classifier.add_module('add_linear', nn.Linear(1000, 10)) 方法二：直接修改模型最后一层![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240520135809.png]] 12 网络模型的保存与读取12.1 保存模型与参数这种方法可以保存模型的结构和模型的参数。缺点： 若模型较大，则保存文件也会很大 Save model 12vgg16 = torchvision.models.vgg16(pretrained=False)torch.save(vgg16, 'vgg16_method.pth') 第一个参数：模型第二个参数：保存的文件名，通常用.pth作为文件类型 load model12# Load Method 1: model_1 = torch.load(&quot;vgg16_method.pth&quot;) 这个方式是存在陷阱的：如果是自己定义了一个模型，对这个模型进行保存。则加载的时候会产生报错。 为了解决这个问题，则需要自己重新定义一次自定义的模型结构： 比如我在model文件创建并保存了数据，在load文件里面需要重新定义（无需new）一次这个模型，才能继续正常使用![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240520145856.png]] 12.2 保存模型参数这个方法将模型的参数作为字典进行保存，所以加载的时候，要用字典加载的方式，放入新的模型中。 官方推荐的方法 Save model 1torch.save(vgg16.state_dict(), 'vgg16_state_dict.pth') load model 12345678910# Specify a pathPATH = &quot;state_dict_model.pt&quot;# Savetorch.save(net.state_dict(), PATH)# Loadmodel = Net()model.load_state_dict(torch.load(PATH))model.eval() [!NOTE]两种方式一定要对应。※不知道为什么，在下个章节代码实现的时候，我无法用方法二的步骤正常创建模型 12 完整模型训练套路 以CIFAR10 为例 步骤说明： 初始化训练集、测试集，转换为Dataloader 初始化自己的模型 定义损失函数和优化器 定义训练次数 epoch 进行迭代epoch 从dataloader中每次取数据进行训练 得到output 得到output与labels的loss 优化器置零 反传播 优化器优化参数 在测试集中检测——取消grad 在流程中合适的地方对结果进行输出或者保存。 定义模型 123456789101112131415161718192021222324252627282930313233343536''' @Project ：pythonProject @File ：MyModel.py @IDE ：PyCharm @Author ：周大猛 @Date ：2024/05/20 15:21 ''' import torch from torch import nn class TongModel(nn.Module): def __init__(self): super(TongModel, self).__init__() self.model = nn.Sequential( nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2), nn.MaxPool2d(2), nn.Conv2d(32, 32, 5, 1, 2), nn.MaxPool2d(2), nn.Conv2d(32, 64, 5, 1, 2), nn.MaxPool2d(2), nn.Flatten(), nn.Linear(64 * 4 * 4, 64), nn.Linear(64, 10), ) def forward(self, x): x = self.model(x) return x if __name__ == '__main__': # 测试网络模型的正确性 model = TongModel() # 64个图片，3个通道，尺寸32*32 input = torch.ones((64, 3, 32, 32)) output = model(input) #torch.Size([64, 10]) 64个图片，10个数据表示每个类别的可能性 print(output.shape) [!NOTE]通常在专门的模型py文件中对模型进行定义，方便管理，修改、检查模型每层的正确性。 数据集123456789101112131415# 准备训练数据 train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,transform=transforms.ToTensor()) # 准备测试数据 test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=transforms.ToTensor()) # 查看数据集信息 train_data_size = len(train_data) test_data_size = len(test_data) print(&quot;Train data size: {}&quot;.format(train_data_size) ) print(&quot;Test data size: %d&quot; % test_data_size) # 使用dataloader加载数据集 train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True) test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) [!NOTE]下载好数据集后，用dataloader进行封装。 导入神经网络，初始化模型 模型初始化 损失函数 优化器 学习率 训练进度 测试进度 迭代次数 保存数据位置1234567891011121314151617from MyModel import * # 创建网络模型 model = TongModel() # 损失函数和优化器 loss_fn = nn.CrossEntropyLoss() learning_rate = 1e-2 optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4) # 设置训练参数 total_train_step = 0 # 记录训练次数 total_test_step = 0 # 记录测试次数 epoch = 100 # 训练的轮数 # 使用tensorboard记录数据 writer = SummaryWriter('./logs_train') 训练与测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647for i in range(epoch): print('Epoch {}/{}'.format(i, epoch)) # 训练开始 model.train() # 当模型有dropout等特殊层的时候，起作用 for data in train_dataloader: imgs, labels = data output = model(imgs) # 计算输出和真实的损失 loss = loss_fn(output, labels) # 优化器优化模型 optimizer.zero_grad() # 准备优化，先梯度清零 loss.backward() #得到每个参数的梯度 optimizer.step() # 对参数进行优化 total_train_step += 1 if total_train_step % 100 == 0: print('Total train step:{}, Loss:{}' .format(total_train_step, loss.item())) writer.add_scalar('Loss/train', loss.item(), total_train_step) &quot;&quot;&quot; 每次训练一轮之后，需要知道本次训练之后在测试集上模型表现是否有进步。 在第一层的for中，对此进行检测。 这里不需要对模型进行调优。 需要知道在整个数据集上的loss &quot;&quot;&quot; model.eval() # 与train（）一个情况 total_test_loss = 0.0 # 计算ACC total_accuracy = 0 with torch.no_grad(): # 没有梯度了 # 测试开始 for data in test_dataloader: imgs, labels = data output = model(imgs) loss = loss_fn(output, labels) total_test_step += 1 total_test_loss += loss.item() accuracy = (output.argmax(dim=1)==labels).sum() total_accuracy += accuracy.item() print('Total test Loss:{}' .format(total_test_loss)) writer.add_scalar('Loss/test', total_test_loss, total_test_step) print(&quot;整体测试集的正确率:{}&quot;.format(total_accuracy/test_data_size)) writer.add_scalar('Accuracy/test', total_accuracy/test_data_size, total_test_step) torch.save(model.state_dict(), './modelData/model_{}.pt'.format(i)) writer.close() 13 使用GPU训练有两种使用GPU的方式 13.1.cuda 网络模型 123# 创建网络模型 model = TongModel() model = model.cuda() 数据的输入和标注 在训练和测试的部分 123imgs, labels = data imgs = imgs.cuda() labels = labels.cuda() 损失函数 123# 损失函数和优化器 loss_fn = nn.CrossEntropyLoss() loss_fn = loss_fn.cuda() 良好的写法：![[PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240521003749.png]] 13.2方法二：.to(device) 定义训练的设备12 # 定义训练的设备 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') 然后之前该国的地方都改成 1model.to(device) 14 完整模型验证套路给训练好的模型提供输入。 与测试部分类似，大概流程如下： 准备数据（自己准备的，非数据集的测试部分或训练部分） 导入模型 模型初始化 模型参数初始化 在测试模式下，输入准备的数据 获得结果，并进行对比 15 Github开源代码只说说注意事项： 仔细阅读README 参数部分可以在代码中找到描述","link":"/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/"}],"tags":[{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"写作","slug":"写作","link":"/tags/%E5%86%99%E4%BD%9C/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"项目管理","slug":"项目管理","link":"/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"闲话","slug":"闲话","link":"/tags/%E9%97%B2%E8%AF%9D/"},{"name":"硬件","slug":"硬件","link":"/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"数据恢复","slug":"数据恢复","link":"/tags/%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"随拍","slug":"随拍","link":"/tags/%E9%9A%8F%E6%8B%8D/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"科研","slug":"科研","link":"/tags/%E7%A7%91%E7%A0%94/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"deep learning","slug":"deep-learning","link":"/tags/deep-learning/"}],"categories":[{"name":"技术学习","slug":"技术学习","link":"/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"技能学习","slug":"技能学习","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/"},{"name":"Java","slug":"技能学习/Java","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Java/"},{"name":"markdown","slug":"技能学习/markdown","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/markdown/"},{"name":"代码管理","slug":"技能学习/代码管理","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"硬件","slug":"技能学习/硬件","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E7%A1%AC%E4%BB%B6/"},{"name":"环境","slug":"技能学习/Java/环境","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Java/%E7%8E%AF%E5%A2%83/"},{"name":"Hexo","slug":"技能学习/Hexo","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Hexo/"},{"name":"闲话","slug":"生活/闲话","link":"/categories/%E7%94%9F%E6%B4%BB/%E9%97%B2%E8%AF%9D/"},{"name":"留学","slug":"生活/留学","link":"/categories/%E7%94%9F%E6%B4%BB/%E7%95%99%E5%AD%A6/"},{"name":"知识科普","slug":"知识科普","link":"/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/"},{"name":"计算机","slug":"知识科普/计算机","link":"/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA/"},{"name":"深度学习","slug":"技术学习/深度学习","link":"/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}],"pages":[]}