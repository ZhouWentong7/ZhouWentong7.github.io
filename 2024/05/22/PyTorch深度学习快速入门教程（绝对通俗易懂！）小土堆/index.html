<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆 - 在代码中遨游</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="在代码中遨游"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="在代码中遨游"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="根据B站视频整理的笔记，看完基本可以入门Pytorch。"><meta property="og:type" content="blog"><meta property="og:title" content="PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆"><meta property="og:url" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/"><meta property="og:site_name" content="在代码中遨游"><meta property="og:description" content="根据B站视频整理的笔记，看完基本可以入门Pytorch。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%98%BE%E5%8D%A1%E6%A3%80%E6%9F%A5.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%A3%80%E6%9F%A5GPU.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240502215043.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%A3%80%E6%9F%A5torch%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8GPU.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%AE%89%E8%A3%85PyCharm%E9%85%8D%E7%BD%AE.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E7%9A%84%E9%85%8D%E7%BD%AE.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/python%20console.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%87%E6%8D%A2%E7%9B%AE%E5%BD%95.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240502221306.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/dir%E5%92%8Chelp.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/scalar%E7%9A%84%E5%8F%82%E6%95%B0.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/tensorboard%E6%95%88%E6%9E%9C.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/add_image%E6%95%88%E6%9E%9C.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/add_image_step2.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/tensorboard%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E5%85%AC%E5%BC%8F.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Resize%E8%AF%B4%E6%98%8E.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Compose%20%E7%9A%84%E8%AF%B4%E6%98%8E.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/CIFAR10%E5%8F%82%E6%95%B0.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Dataloader%E6%96%87%E6%A1%A3.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Epoch%E5%92%8Cdataloader.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240510001631.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240510002025.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513143027.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513143637.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513151144.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513152311.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514104621.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514110338.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514142823.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514151828.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514151848.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240519105814.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520002324.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520135525.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520135809.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520145856.png"><meta property="og:image" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240521003749.png"><meta property="article:published_time" content="2024-05-21T15:23:07.000Z"><meta property="article:modified_time" content="2024-05-21T15:39:16.856Z"><meta property="article:author" content="Zhou"><meta property="article:tag" content="pytorch"><meta property="article:tag" content="deep learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%98%BE%E5%8D%A1%E6%A3%80%E6%9F%A5.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/"},"headline":"PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆","image":["https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%98%BE%E5%8D%A1%E6%A3%80%E6%9F%A5.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%A3%80%E6%9F%A5GPU.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240502215043.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%A3%80%E6%9F%A5torch%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8GPU.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%AE%89%E8%A3%85PyCharm%E9%85%8D%E7%BD%AE.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E7%9A%84%E9%85%8D%E7%BD%AE.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/python%20console.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%87%E6%8D%A2%E7%9B%AE%E5%BD%95.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240502221306.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/dir%E5%92%8Chelp.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/scalar%E7%9A%84%E5%8F%82%E6%95%B0.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/tensorboard%E6%95%88%E6%9E%9C.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/add_image%E6%95%88%E6%9E%9C.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/add_image_step2.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/tensorboard%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E5%85%AC%E5%BC%8F.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Resize%E8%AF%B4%E6%98%8E.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Compose%20%E7%9A%84%E8%AF%B4%E6%98%8E.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/CIFAR10%E5%8F%82%E6%95%B0.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Dataloader%E6%96%87%E6%A1%A3.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Epoch%E5%92%8Cdataloader.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240510001631.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240510002025.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513143027.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513143637.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513151144.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513152311.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514104621.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514110338.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514142823.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514151828.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514151848.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240519105814.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520002324.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520135525.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520135809.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520145856.png","https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240521003749.png"],"datePublished":"2024-05-21T15:23:07.000Z","dateModified":"2024-05-21T15:39:16.856Z","author":{"@type":"Person","name":"Zhou"},"publisher":{"@type":"Organization","name":"在代码中遨游","logo":{"@type":"ImageObject","url":{"text":"一个小角落"}}},"description":"根据B站视频整理的笔记，看完基本可以入门Pytorch。"}</script><link rel="canonical" href="https://zhouwentong7.github.io/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/">一个小角落</a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="My Github" href="https://github.com/ZhouWentong7"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-05-21T15:23:07.000Z" title="2024/5/22 0:23:07">2024-05-22</time>发表</span><span class="level-item"><time dateTime="2024-05-21T15:39:16.856Z" title="2024/5/22 0:39:16">2024-05-22</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a><span> / </span><a class="link-muted" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><span class="level-item">1 小时读完 (大约8468个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆</h1><div class="content"><p>根据B站视频整理的笔记，看完基本可以入门Pytorch。</p>
<span id="more"></span>

<h1 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="1 环境配置"></a>1 环境配置</h1><p>检查显卡：</p>
<ul>
<li>在命令行底部右键打开任务管理器<ul>
<li>也可以查看到GPU的型号<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%98%BE%E5%8D%A1%E6%A3%80%E6%9F%A5.png" class=""></li>
</ul>
</li>
</ul>
<h2 id="conda"><a href="#conda" class="headerlink" title="conda"></a>conda</h2><p>#conda</p>
<ul>
<li><p>配置一个特定的环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n [env name] python=[python version]</span><br></pre></td></tr></table></figure>
</li>
<li><p>激活环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate [env name]</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看创建过的环境</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda info -e</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="技巧pip"><a href="#技巧pip" class="headerlink" title="技巧pip"></a>技巧pip</h2><ul>
<li>查看工具包<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip list</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="安装Pytorch"><a href="#安装Pytorch" class="headerlink" title="安装Pytorch"></a>安装Pytorch</h2><ul>
<li>检查电脑的GPU是否支持pytorch<br>打开命令行，输入<code>nvidia-smi</code><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%A3%80%E6%9F%A5GPU.png" class=""></li>
<li>查看驱动版本 Driver Version<ul>
<li>需要保持版本号大于coda的需求的</li>
<li>如果不满足，可以去英伟达的<a target="_blank" rel="noopener" href="https://www.nvidia.cn/Download/index.aspx?lang=cn">官网</a>更新驱动</li>
</ul>
</li>
</ul>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240502215043.png" class="">
<p>选好后，输入conda命令即可</p>
<h2 id="检验安装"><a href="#检验安装" class="headerlink" title="检验安装"></a>检验安装</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;python</span><br><span class="line">&gt;&gt;import torch # 没有报错就是安装成功</span><br><span class="line">&gt;&gt;torch.cuda.is_available() # 检查是否可以使用GPU</span><br></pre></td></tr></table></figure>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E6%A3%80%E6%9F%A5torch%E6%98%AF%E5%90%A6%E5%8F%AF%E4%BB%A5%E4%BD%BF%E7%94%A8GPU.png" class="">

<ul>
<li>torch.cuda.is_available()返回False<br>进行以下步骤进行排除：</li>
</ul>
<ol>
<li><p>进入<a target="_blank" rel="noopener" href="https://www.nvidia.cn/geforce/technologies/cuda/supported-gpus/">https://www.nvidia.cn/geforce/technologies/cuda/supported-gpus/</a></p>
<ol>
<li>检查是否支持cuda</li>
</ol>
</li>
<li><p>检查驱动版本<code>nvidia-smi</code></p>
<ol>
<li>不够高就去更新</li>
</ol>
</li>
<li></li>
</ol>
<p>在正常使用一段时间后，安装各种包突然又返回False或者各种冲突。<br>解决方案：</p>
<ul>
<li>卸载torch全部重来：<code>conda remove pytorch torchvision</code></li>
</ul>
<h1 id="2-编辑器的选择"><a href="#2-编辑器的选择" class="headerlink" title="2 编辑器的选择"></a>2 编辑器的选择</h1><h2 id="PyCharm"><a href="#PyCharm" class="headerlink" title="PyCharm"></a>PyCharm</h2><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%AE%89%E8%A3%85PyCharm%E9%85%8D%E7%BD%AE.png" class="">

<h3 id="配置PyCharm"><a href="#配置PyCharm" class="headerlink" title="配置PyCharm"></a>配置PyCharm</h3><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE%E7%9A%84%E9%85%8D%E7%BD%AE.png" class="">

<h2 id="一些技巧"><a href="#一些技巧" class="headerlink" title="一些技巧"></a>一些技巧</h2><p>python的console，可以检查一些变量或者一些命令、方法，简便直观。</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/python%20console.png" class="">

<h2 id="Jupyter"><a href="#Jupyter" class="headerlink" title="Jupyter"></a>Jupyter</h2><h2 id="jupyter-配置"><a href="#jupyter-配置" class="headerlink" title="jupyter 配置"></a>jupyter 配置</h2><p>在安装cuda的时候，这个默认安装在base的环境中。但是base中没有安装torch。可以再在base里面安装一次torch，但是还是在之前安装的torch环境中安装一下jupyter吧~</p>
<ol>
<li><p>安装一个个包<br><code>nb_conda</code> 是一个用于 Jupyter Notebook 的插件，它可以让你在 Notebook 中使用 Conda 环境。通过运行 <code>conda install nb_conda</code>，你可以将这个插件安装到你的 Conda 环境中，然后在 Jupyter Notebook 中使用。这样你就可以方便地在 Notebook 中管理和切换不同的 Conda 环境了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda install nb_conda</span><br></pre></td></tr></table></figure>
</li>
<li><p>在命令行中切换到对应的项目目录<br>最开始在C盘</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%88%87%E6%8D%A2%E7%9B%AE%E5%BD%95.png" class="">
</li>
<li><p>创建项目</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240502221306.png" class=""></li>
</ol>
<h1 id="3-Python的两大法宝函数"><a href="#3-Python的两大法宝函数" class="headerlink" title="3 Python的两大法宝函数"></a>3 Python的两大法宝函数</h1><ul>
<li>dir(): 打开，看见</li>
<li>help(): 说明书</li>
</ul>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/dir%E5%92%8Chelp.png" class="">


<h1 id="4-浅对比PyCharm，python控制台和Jupyter"><a href="#4-浅对比PyCharm，python控制台和Jupyter" class="headerlink" title="4 浅对比PyCharm，python控制台和Jupyter"></a>4 浅对比PyCharm，python控制台和Jupyter</h1><ol>
<li>rerun的区别</li>
</ol>
<ul>
<li>PyCharm会全部重新运行。</li>
<li>控制台：从错误的地方开始运行</li>
<li>notebook：任意行为块，每一块重运行。</li>
</ul>
<h1 id="5-PyTorch加载数据"><a href="#5-PyTorch加载数据" class="headerlink" title="5 PyTorch加载数据"></a>5 PyTorch加载数据</h1><blockquote>
<ul>
<li>Dataset</li>
<li>Dataaloader</li>
</ul>
</blockquote>
<p>Dataset:</p>
<ul>
<li>获取的数据是混乱的，但是可以进行编号</li>
<li>可以获取数据和label<ul>
<li><strong>如何获取每一个数据和label</strong></li>
<li><strong>总共有多少个数据</strong></li>
</ul>
</li>
</ul>
<p>Dataloader：</p>
<ul>
<li>对Dataset进行打包</li>
<li><h2 id="提供不同的数据形式"><a href="#提供不同的数据形式" class="headerlink" title="提供不同的数据形式"></a>提供不同的数据形式</h2></li>
</ul>
<p>#os的用法</p>
<ul>
<li><code>os.path.join(dir1,dir2)</code>：可以根据系统自动拼接地址</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;  </span></span><br><span class="line"><span class="string">@Project ：pythonProject @File    ：read_data.py  </span></span><br><span class="line"><span class="string">@IDE     ：PyCharm @Author  ：周大猛  </span></span><br><span class="line"><span class="string">@Date    ：2024/05/02 23:50 &#x27;&#x27;&#x27;</span>  </span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset  </span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"><span class="keyword">import</span> os  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDataset</span>(<span class="title class_ inherited__">Dataset</span>):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, root_dir, label_dir</span>):  </span><br><span class="line">        self.root_dir = root_dir  </span><br><span class="line">        self.label_dir = label_dir  </span><br><span class="line">        self.path = os.path.join(root_dir, label_dir)  </span><br><span class="line">        self.img_path = os.listdir(self.path)  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">        读取每一个图片  </span></span><br><span class="line"><span class="string">        :param index:        :return:  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>        img_name = self.img_path[index]  </span><br><span class="line">        img_item_path = os.path.join(self.path, img_name)  </span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_item_path)  </span><br><span class="line">        label = self.label_dir  </span><br><span class="line">        <span class="keyword">return</span> img, label  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;获得数据集的长度&quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_path)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    root_dir = <span class="string">&quot;dataset/train&quot;</span>  </span><br><span class="line">    ants_label_dir = <span class="string">&quot;ants&quot;</span>  </span><br><span class="line">    bees_label_dir = <span class="string">&quot;bees&quot;</span>  </span><br><span class="line">    ants_dataset = MyDataset(root_dir,ants_label_dir)  </span><br><span class="line">    bees_dataset = MyDataset(root_dir,bees_label_dir)  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 拼接数据集，按顺序拼接。  </span></span><br><span class="line">    train_loader = ants_dataset + bees_dataset</span><br></pre></td></tr></table></figure>

<h2 id="5-1-TensorBoard的使用"><a href="#5-1-TensorBoard的使用" class="headerlink" title="5.1 TensorBoard的使用"></a>5.1 TensorBoard的使用</h2><ul>
<li>对图像进行变化：统一尺寸等</li>
<li>对图像进行展示</li>
</ul>
<h3 id="SummaryWriter"><a href="#SummaryWriter" class="headerlink" title="SummaryWriter"></a>SummaryWriter</h3><p>原文部分介绍：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SummaryWriter</span>:  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;Writes entries directly to event files in the log_dir to be consumed by TensorBoard.  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">    The `SummaryWriter` class provides a high-level API to create an event file    in a given directory and add summaries and events to it. The class updates the    file contents asynchronously. This allows a training program to call methods    to add data to the file directly from the training loop, without slowing down    training.    &quot;&quot;&quot;</span>  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">  </span></span><br><span class="line"><span class="params">        self,  </span></span><br><span class="line"><span class="params">        log_dir=<span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">        comment=<span class="string">&quot;&quot;</span>,  </span></span><br><span class="line"><span class="params">        purge_step=<span class="literal">None</span>,  </span></span><br><span class="line"><span class="params">        max_queue=<span class="number">10</span>,  </span></span><br><span class="line"><span class="params">        flush_secs=<span class="number">120</span>,  </span></span><br><span class="line"><span class="params">        filename_suffix=<span class="string">&quot;&quot;</span>,  </span></span><br><span class="line"><span class="params">    </span>):  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create a `SummaryWriter` that will write out events and summaries to the event file.  </span></span><br><span class="line"><span class="string">  </span></span><br><span class="line"><span class="string">        Args:            log_dir (str): Save directory location. Default is              runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.              Use hierarchical folder structure to compare              between runs easily. e.g. pass in &#x27;runs/exp1&#x27;, &#x27;runs/exp2&#x27;, etc.              for each new experiment to compare across them.            comment (str): Comment log_dir suffix appended to the default              ``log_dir``. If ``log_dir`` is assigned, this argument has no effect.            purge_step (int):              When logging crashes at step :math:`T+X` and restarts at step :math:`T`,              any events whose global_step larger or equal to :math:`T` will be              purged and hidden from TensorBoard.              Note that crashed and resumed experiments should have the same ``log_dir``.            max_queue (int): Size of the queue for pending events and              summaries before one of the &#x27;add&#x27; calls forces a flush to disk.              Default is ten items.            flush_secs (int): How often, in seconds, to flush the              pending events and summaries to disk. Default is every two minutes.            filename_suffix (str): Suffix added to all event filenames in              the log_dir directory. More details on filename construction in              tensorboard.summary.writer.event_file_writer.EventFileWriter.  </span></span><br><span class="line"><span class="string">        Examples::  </span></span><br><span class="line"><span class="string">            from torch.utils.tensorboard import SummaryWriter  </span></span><br><span class="line"><span class="string">            # create a summary writer with automatically generated folder name.            writer = SummaryWriter()            # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/  </span></span><br><span class="line"><span class="string">            # create a summary writer using the specified folder name.            writer = SummaryWriter(&quot;my_experiment&quot;)            # folder location: my_experiment  </span></span><br><span class="line"><span class="string">            # create a summary writer with comment appended.            writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;)            # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>三种用法</p>
<ol>
<li>默认保存到一个路径 <code>writer = SummaryWriter()            # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ </code> </li>
<li>自定义保存到的文件夹 <code>writer = SummaryWriter(&quot;my_experiment&quot;)            # folder location: my_experiment  </code></li>
<li>可以对文件名加入一些comments <code>writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;)            # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ </code></li>
</ol>
<h3 id="writer-add-scalar"><a href="#writer-add-scalar" class="headerlink" title="writer.add_scalar()"></a>writer.add_scalar()</h3><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/scalar%E7%9A%84%E5%8F%82%E6%95%B0.png" class="">

<h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><p>打开方法：</p>
<ul>
<li>指定路径 –logdir</li>
<li>指定端口 –port</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=[logs] --port=[6007]</span><br></pre></td></tr></table></figure>

<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/tensorboard%E6%95%88%E6%9E%9C.png" class="">

<p>但是运行多次之后可能显示图像会出bug，可以选择删掉之前的log</p>
<h3 id="writer-add-image"><a href="#writer-add-image" class="headerlink" title="writer.add_image()"></a>writer.add_image()</h3><ul>
<li>读取图片</li>
<li>识别类型：<ul>
<li>numpy</li>
<li>tensor</li>
<li>string</li>
</ul>
</li>
</ul>
<p>但是我们常用的PIL的Image是JpegImageFile类型，所以不符合，需要转换，或者直接用别的方法读取图片，如OpenCV</p>
<p>在使用numpy读取图片的时候，每个通道的顺序可能与add_image默认的顺序不一样，可以ctrl进入add_image查看手册，手动设定通道顺序</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image  </span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np  </span><br><span class="line">  </span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;logs&#x27;</span>)  </span><br><span class="line">image_path = <span class="string">&quot;dataset/train/ants/5650366_e22b7e1065.jpg&quot;</span>  </span><br><span class="line">iamge_PIL = Image.<span class="built_in">open</span>(image_path)  </span><br><span class="line">img_array = np.array(iamge_PIL) <span class="comment"># 但是这里形状不对,np读出来之后，通道在最后：(375, 500, 3)  </span></span><br><span class="line"><span class="built_in">print</span>(img_array.shape)  </span><br><span class="line">  </span><br><span class="line">writer.add_image(<span class="string">&quot;image&quot;</span>, img_array, <span class="number">1</span>,dataformats=<span class="string">&#x27;HWC&#x27;</span>) <span class="comment"># 根据官方文档里面，指定type的顺序</span></span><br></pre></td></tr></table></figure>

<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/add_image%E6%95%88%E6%9E%9C.png" class="">

<p>修改add_image的第二个参数step，可以在进度条处出现拉出新的图</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/add_image_step2.png" class="">

<h3 id="writer-add-graph-net-input"><a href="#writer-add-graph-net-input" class="headerlink" title="writer.add_graph(net,input)"></a>writer.add_graph(net,input)</h3><p>可以查看网络的结构</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网络结构的方法  </span></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;./logs&quot;</span>)  </span><br><span class="line">writer.add_graph(net,<span class="built_in">input</span>)  </span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/tensorboard%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84.png" class="">
<h2 id="5-2-Transform"><a href="#5-2-Transform" class="headerlink" title="5.2 Transform"></a>5.2 Transform</h2><p>指的是：transforms.py文件，里面又很多的“工具”：</p>
<ul>
<li>toTensor</li>
<li>resize</li>
</ul>
<p>拿特定格式的图片，丢进去，得到需要的图片结果。</p>
<p>引入的方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br></pre></td></tr></table></figure>
<h3 id="ToTensor"><a href="#ToTensor" class="headerlink" title="ToTensor"></a>ToTensor</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor_trans = transforms.ToTensor() <span class="comment"># 实例化这个工具  </span></span><br><span class="line">tensor_img = tensor_trans(image)  <span class="comment"># 使用这个工具，输出一个结果</span></span><br></pre></td></tr></table></figure>


<p>为什么需要Tensor这个数据类型？</p>
<ul>
<li>tensor包含了神经网络中使用的一些参数</li>
</ul>
<p>另一种读取方式：nparray<br>使用OpenCV.</p>
<p>导入opencv的方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install opencv-python</span><br></pre></td></tr></table></figure>

<h3 id="归一化Normalization"><a href="#归一化Normalization" class="headerlink" title="归一化Normalization"></a>归一化Normalization</h3><p><code>output[channel] = (input[channel] - mean[channel]) / std[channel]</code></p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/%E5%BD%92%E4%B8%80%E5%8C%96%E7%9A%84%E5%85%AC%E5%BC%8F.png" class="">

<p>均值和标准差都是0.5</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">trans_norm = transforms.Normalize([<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>], [<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>])  </span><br><span class="line">img_norm = trans_norm(img_tensor)  </span><br><span class="line">  </span><br><span class="line">writer.add_image(<span class="string">&#x27;Normal_img&#x27;</span>, img_norm)</span><br></pre></td></tr></table></figure>

<h3 id="Resize"><a href="#Resize" class="headerlink" title="Resize()"></a>Resize()</h3><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Resize%E8%AF%B4%E6%98%8E.png" class="">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Resize  </span></span><br><span class="line"><span class="built_in">print</span>(img.size)  </span><br><span class="line">trans_resize = transforms.Resize((<span class="number">512</span>,<span class="number">512</span>))  </span><br><span class="line"><span class="comment"># img PIL --&gt; resize --&gt; img_resize PIL  </span></span><br><span class="line">img_resize = trans_resize(img)  </span><br><span class="line"><span class="comment"># img_resize PIL --》to_tensor --&gt; img_resize tensor  </span></span><br><span class="line">img_resize = trans_totensor(img_resize)  </span><br><span class="line">writer.add_image(<span class="string">&#x27;Resize_img&#x27;</span>, img_resize,<span class="number">0</span>)  </span><br><span class="line"><span class="built_in">print</span>(img_resize)  </span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<h3 id="Compose"><a href="#Compose" class="headerlink" title="Compose()"></a>Compose()</h3><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Compose%20%E7%9A%84%E8%AF%B4%E6%98%8E.png" class="">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Compose - resize -2  </span></span><br><span class="line">trans_resize_2 = transforms.Resize(<span class="number">64</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 这里列表的顺序需要保证前一个的输出类型是后一个的输入类型。  </span></span><br><span class="line">trans_compose = transforms.Compose([trans_resize_2,trans_totensor,])  </span><br><span class="line">img_resize_2 = trans_compose(img)</span><br></pre></td></tr></table></figure>

<h3 id="RandomCrop-随机裁剪"><a href="#RandomCrop-随机裁剪" class="headerlink" title="RandomCrop()随机裁剪"></a>RandomCrop()随机裁剪</h3><p>按照设定的尺寸随机在图片内裁剪规定尺寸大小的图片。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RandomCrop  </span></span><br><span class="line">trans_random = transforms.RandomCrop(<span class="number">64</span>)  </span><br><span class="line">trans_compose_2 = transforms.Compose([trans_random,trans_totensor,])  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  </span><br><span class="line">    img_crop = trans_compose_2(img)  </span><br><span class="line">    writer.add_image(<span class="string">&#x27;Random_img&#x27;</span>, img_crop,i)</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>关注输入和输出的类型</li>
<li>多看官方文档</li>
<li>看初始化的参数</li>
<li>输出类型可以print查看，或者debug</li>
</ul>
<h1 id="6-Torchvision的数据集使用"><a href="#6-Torchvision的数据集使用" class="headerlink" title="6 Torchvision的数据集使用"></a>6 Torchvision的数据集使用</h1><p><a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/datasets.html">官网链接</a></p>
<blockquote>
<p>如果下载速度太慢，可以将下载路径粘贴到迅雷中进行下载。</p>
</blockquote>
<p>数据集的参数设置很多都是相同的，教程中以CIFAR10为例：</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/CIFAR10%E5%8F%82%E6%95%B0.png" class="">
<ul>
<li>设置数据集路径</li>
<li>设置训练or测试集合</li>
<li>transform要做的操作</li>
<li>download：是否要网络下载（准备好了就False，没准备就True）</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision  </span><br><span class="line">  </span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>)  </span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>可以在transform参数，设置对数据集的操作，也是可以打包送进去的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchvision  </span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  </span><br><span class="line">  </span><br><span class="line">dataset_transform = torchvision.transforms.Compose([  </span><br><span class="line">  </span><br><span class="line">    torchvision.transforms.ToTensor(),  </span><br><span class="line">    torchvision.transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),  </span><br><span class="line">  </span><br><span class="line">])  </span><br><span class="line">  </span><br><span class="line">train_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>, transform=dataset_transform)  </span><br><span class="line">test_set = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=dataset_transform)  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">print</span>(test_set[<span class="number">0</span>])  </span><br><span class="line">  </span><br><span class="line">writer = SummaryWriter(log_dir=<span class="string">&#x27;./logs&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  </span><br><span class="line">    img, label = test_set[i]  </span><br><span class="line">    writer.add_image(<span class="string">&#x27;test_img&#x27;</span>, img, i)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h1 id="7-Dataloader的使用"><a href="#7-Dataloader的使用" class="headerlink" title="7 Dataloader的使用"></a>7 Dataloader的使用</h1><p>将数据加载到神经网络中。</p>
<p><strong>如何取</strong>数据可以由Dataloader进行设置。</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Dataloader%E6%96%87%E6%A1%A3.png" class="">


<p>常用参数设置：</p>
<ul>
<li>batch_size</li>
<li>shuffle:洗牌</li>
<li>num_workers:多少个进行进行加载（但是win上有时候出现错误）</li>
<li>drop_last:分组除不尽的时是否舍去一些数据。</li>
</ul>
<p>DataLoader会分别把数据集的数据和label，按照batch_size的大小，进行打包。</p>
<p>如果设置了shuffle，一个epoch打乱一次。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision  </span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader  </span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  </span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms  </span><br><span class="line">  </span><br><span class="line">data_transforms = transforms.Compose([transforms.ToTensor(),])  </span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,transform=data_transforms)  </span><br><span class="line">  </span><br><span class="line">test_loader = DataLoader(dataset=test_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span>, drop_last=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">img, label = test_data[<span class="number">0</span>]  </span><br><span class="line"><span class="built_in">print</span>(img.shape)  </span><br><span class="line"><span class="built_in">print</span>(label)  </span><br><span class="line">  </span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./logs&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 多次让dataloader取数据，shuffle就会在每次的epoch影响取值，True会打乱数据集  </span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  </span><br><span class="line">    step = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:  </span><br><span class="line">        imgs, labels = data  </span><br><span class="line">        <span class="comment"># 注意这里用的是images  </span></span><br><span class="line">        writer.add_images(<span class="string">&#x27;Epoch:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(epoch), imgs,step)  </span><br><span class="line">        step += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Epoch%E5%92%8Cdataloader.png" class="">


<h1 id="8-网络搭建"><a href="#8-网络搭建" class="headerlink" title="8 网络搭建"></a>8 网络搭建</h1><p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/nn.html">https://pytorch.org/docs/stable/nn.html</a></p>
<h2 id="8-1-Containers"><a href="#8-1-Containers" class="headerlink" title="8.1 Containers"></a>8.1 Containers</h2><p>最常用的模块，提供神经网络的最基本的框架</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240510001631.png" class="">

<h3 id="nn-Module"><a href="#nn-Module" class="headerlink" title="nn.Module"></a>nn.Module</h3><p>》 <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 调用父类的初始化</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># 神经网络的前向传播</span></span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="keyword">return</span> F.relu(self.conv2(x))  <span class="comment"># 这个demo进行了两次非线性卷积</span></span><br></pre></td></tr></table></figure>

<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240510002025.png" class="">

<h2 id="8-2-卷积层操作与卷积层"><a href="#8-2-卷积层操作与卷积层" class="headerlink" title="8.2 卷积层操作与卷积层"></a>8.2 卷积层操作与卷积层</h2><h3 id="（1）卷积操作"><a href="#（1）卷积操作" class="headerlink" title="（1）卷积操作"></a>（1）卷积操作</h3><h4 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h4><p>在全连接（Affine）层中存在忽略了数据形状，它直接将整个图片拉成一维数据输入到了神经网络。</p>
<p>因此导致了，形状中含有的空间信息被忽略。</p>
<p>卷积层的优点就是，可以保持形状的不变，或许能更好的理解图片的形状信息。</p>
<p>卷积层的输入输出被称为<font color="#f79646">特征图</font>，。<br>!PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆&#x2F;Pasted image 20240513161728.png]]<br>主要用torch.nn 的部分，对functional封装更好</p>
<p>卷积核：（类似图像处理的滤波器）一个小矩阵，对图像矩阵进行一坨一坨的计算</p>
<ul>
<li>stride &#x3D; 滤波器每次移动的举例<ul>
<li>会影响最后得到的卷积输出的形状</li>
<li>越大，输出的矩阵越小（？）</li>
</ul>
</li>
</ul>
<p>官网参数介绍：conv2d</p>
<ul>
<li><p><strong>input</strong> – input tensor of shape (minibatch,in_channels,𝑖𝐻,𝑖𝑊)(minibatch,in_channels,iH,iW)</p>
<blockquote>
<p>要设置batch的带线啊哦</p>
</blockquote>
</li>
<li><p><strong>weight</strong> – filters of shape (out_channels,in_channelsgroups,𝑘𝐻,𝑘𝑊)(out_channels,groupsin_channels​,kH,kW)</p>
</li>
<li><p><strong>bias</strong> – optional bias tensor of shape (out_channels)(out_channels). Default: <code>None</code></p>
</li>
<li><p><strong>stride</strong> – the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1</p>
</li>
<li><p><strong>padding</strong> （在图像左右两边对图像进行填充）–</p>
<p>  implicit paddings on both sides of the input. Can be a string {‘valid’, ‘same’}, single number or a tuple (padH, padW). Default: 0 <code>padding=&#39;valid&#39;</code> is the same as no padding. <code>padding=&#39;same&#39;</code> pads the input so the output has the same shape as the input. However, this mode doesn’t support any stride values other than 1.<br>  填充的内容默认为0<br>  也会对输出结构造成影响</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  </span><br><span class="line">  </span><br><span class="line"><span class="built_in">input</span> = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">0</span>,<span class="number">3</span>,<span class="number">1</span>],  </span><br><span class="line">                      [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],  </span><br><span class="line">                      [<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],  </span><br><span class="line">                      [<span class="number">5</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>],  </span><br><span class="line">                      [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>]])  </span><br><span class="line">  </span><br><span class="line">kernel = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>],  </span><br><span class="line">                       [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],  </span><br><span class="line">                       [<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>]])  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># print(input)  </span></span><br><span class="line"><span class="comment"># print(kernel)  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># print(input.shape)  </span></span><br><span class="line"><span class="comment"># print(kernel.shape)  </span></span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 转换成nn.conv需要的形状  </span></span><br><span class="line"><span class="built_in">input</span> = torch.reshape(<span class="built_in">input</span>,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">5</span>,<span class="number">5</span>)) <span class="comment"># shape:batch，通道，长，宽  </span></span><br><span class="line">kernel = torch.reshape(kernel,(<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># print(input)  </span></span><br><span class="line"><span class="comment"># print(kernel)  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># print(input.shape)  </span></span><br><span class="line"><span class="comment"># print(kernel.shape)  </span></span><br><span class="line">  </span><br><span class="line">output1 = F.conv2d(<span class="built_in">input</span>,kernel,stride=<span class="number">1</span>)  </span><br><span class="line"><span class="built_in">print</span>(output1)  </span><br><span class="line">  </span><br><span class="line">output2 = F.conv2d(<span class="built_in">input</span>,kernel,stride=<span class="number">2</span>)  </span><br><span class="line"><span class="built_in">print</span>(output2)  </span><br><span class="line">  </span><br><span class="line">output3 = F.conv2d(<span class="built_in">input</span>,kernel,stride=<span class="number">1</span>,padding=<span class="number">1</span>)  </span><br><span class="line"><span class="built_in">print</span>(output3)</span><br></pre></td></tr></table></figure>


<h3 id="（2）卷积层"><a href="#（2）卷积层" class="headerlink" title="（2）卷积层"></a>（2）卷积层</h3><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513143027.png" class="">

<blockquote>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d">https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d</a></p>
</blockquote>
<p>Parameters</p>
<ul>
<li><p><strong>in_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of channels in the input image</p>
</li>
<li><p><strong>out_channels</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – Number of channels produced by the convolution<br>  》 有几个卷积核，就会导致输出有几个维度，也就是channels</p>
  <img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513143637.png" class=""></li>
<li><p><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a>) – Size of the convolving kernel<br>  个</p>
</li>
<li><p><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>,</em> <em>optional</em>) – Stride of the convolution. Default: 1</p>
</li>
<li><p><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>,</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>,</em> <em>optional</em>) – Padding added to all four sides of the input. Default: 0</p>
</li>
<li><p><strong>padding_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.12)"><em>str</em></a><em>,</em> <em>optional</em>) – <code>&#39;zeros&#39;</code>, <code>&#39;reflect&#39;</code>, <code>&#39;replicate&#39;</code> or <code>&#39;circular&#39;</code>. Default: <code>&#39;zeros&#39;</code></p>
</li>
<li><p><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a> <em>or</em> <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.12)"><em>tuple</em></a><em>,</em> <em>optional</em>) – Spacing between kernel elements. Default: 1</p>
</li>
<li><p><strong>groups</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>,</em> <em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</p>
</li>
<li><p><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a><em>,</em> <em>optional</em>) – If <code>True</code>, adds a learnable bias to the output. Default: <code>True</code></p>
</li>
</ul>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513151144.png" class="">
<p>根据这两个公式，推到论文中的padding和stride</p>
<p>#padding计算 #stride计算<br>如果卷积前后尺寸不变，padding &#x3D; （卷积核尺寸-1）&#x2F;2</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240513152311.png" class="">
<blockquote>
<p>#批处理<br>批处理：这里将多个图像打包成一个batch，让图像变成了四维数据（batch_num, channel,height,width)进行计算，加快运算效率</p>
</blockquote>
<h2 id="8-3-池化"><a href="#8-3-池化" class="headerlink" title="8.3 池化"></a>8.3 池化</h2><p>#池化</p>
<h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><ul>
<li>无需学习参数（与卷积的不同）<ul>
<li>只是从目标区域获得最大值或者平均值</li>
</ul>
</li>
<li>通道数不发生变化<ul>
<li>计算按照通道独立进行</li>
</ul>
</li>
<li>对微笑的数据位置变化具有鲁棒性（健壮）</li>
</ul>
<p>Parameters</p>
<ul>
<li><p><strong>kernel_size</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)"><em>Union</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]__]</em>) – the size of the window to take a max over</p>
</li>
<li><p><strong>stride</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)"><em>Union</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]__]</em>) – the stride of the window. Default value is <code>kernel_size</code></p>
</li>
<li><p><strong>padding</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)"><em>Union</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]__]</em>) – Implicit negative infinity padding to be added on both sides</p>
</li>
<li><p><strong>dilation</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.12)"><em>Union</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.12)"><em>Tuple</em></a><em>[_<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a></em>,_ <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a><em>]__]</em>) – a parameter that controls the stride of elements in the window</p>
</li>
<li><p><strong>return_indices</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – if <code>True</code>, will return the max indices along with the outputs. Useful for <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d" title="torch.nn.MaxUnpool2d"><code>torch.nn.MaxUnpool2d</code></a> later</p>
</li>
<li><p><strong>ceil_mode</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – when True, will use ceil instead of floor to compute the output shape</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  </span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F  </span><br><span class="line"><span class="keyword">import</span> torchvision.datasets <span class="keyword">as</span> datasets  </span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader  </span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter  </span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms  </span><br><span class="line">  </span><br><span class="line">dataset = datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,transform=transforms.ToTensor())  </span><br><span class="line">dataloader = DataLoader(dataset, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)  </span><br><span class="line"><span class="comment"># input = torch.tensor([  </span></span><br><span class="line"><span class="comment">#     [1,2,0,3,1],  </span></span><br><span class="line"><span class="comment">#     [0,1,2,3,1],  </span></span><br><span class="line"><span class="comment">#     [1,2,1,0,0],  </span></span><br><span class="line"><span class="comment">#     [5,2,3,1,1],  </span></span><br><span class="line"><span class="comment">#     [2,1,0,1,1]  </span></span><br><span class="line"><span class="comment"># ],dtype=torch.float32)  </span></span><br><span class="line"><span class="comment">#  </span></span><br><span class="line"><span class="comment"># input = torch.reshape(input,(-1,1,5,5))  </span></span><br><span class="line"><span class="comment"># print(input.shape)  </span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">T</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>(T, self).__init__()  </span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">3</span>,ceil_mode=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        output = self.pool(x)  </span><br><span class="line">  </span><br><span class="line">        <span class="keyword">return</span> output  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">tt = T()  </span><br><span class="line"><span class="comment"># result = tt(input)  </span></span><br><span class="line"><span class="comment"># print(result.shape)  </span></span><br><span class="line"><span class="comment"># print(result)  </span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./maxpool_logs&#x27;</span>)  </span><br><span class="line">step = <span class="number">0</span>  </span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> dataloader:  </span><br><span class="line">    imgs, labels = data  </span><br><span class="line">    writer.add_image(<span class="string">&#x27;Input&#x27;</span>, imgs,step,dataformats=<span class="string">&#x27;NCHW&#x27;</span>)  </span><br><span class="line">    outputs = tt(imgs)  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    最大池化不会改变形状，  </span></span><br><span class="line"><span class="string">    所以不用像卷积那样还要将得到的图片进行reshape  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>    writer.add_image(<span class="string">&quot;Output&quot;</span>, outputs,step,dataformats=<span class="string">&#x27;NCHW&#x27;</span>)  </span><br><span class="line">  </span><br><span class="line">    step += <span class="number">1</span>  </span><br><span class="line">  </span><br><span class="line">writer.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<h2 id="8-4-非线性激活"><a href="#8-4-非线性激活" class="headerlink" title="8.4 非线性激活"></a>8.4 非线性激活</h2><h3 id="（1）-ReLu（Rectified-Linear-Unit）"><a href="#（1）-ReLu（Rectified-Linear-Unit）" class="headerlink" title="（1） ReLu（Rectified Linear Unit）"></a>（1） ReLu（Rectified Linear Unit）</h3><p>$$<br>y &#x3D;<br>\begin{cases}<br>x &amp; \text{if } x &gt; 0 \<br>0 &amp; \text{if } x \leq 0<br>\end{cases}<br>\tag{1}<br>$$<br>$$<br>\frac{\partial y}{\partial x} &#x3D;<br>\begin{cases}<br>1 &amp; \text{if } x &gt; 0 \<br>0 &amp; \text{if } x \leq 0<br>\end{cases}<br>\tag{2}<br>$$</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514104621.png" class="">
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514110338.png" class="">
<p>这个inplace（替换）：</p>
<ul>
<li>True：直接把变换后的值，放到input的那个变量里面</li>
<li>False：把变换后的值，需要一个新的变量来接收</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line">  </span><br><span class="line">i = torch.tensor([[-<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, -<span class="number">5</span>, <span class="number">6</span>], [<span class="number">7</span>, <span class="number">8</span>, -<span class="number">9</span>]])  </span><br><span class="line">i = torch.reshape(i,(-<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">3</span>))  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DemoModule</span>(torch.nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>(DemoModule, self).__init__()  </span><br><span class="line">        self.relu1 = torch.nn.ReLU(inplace=<span class="literal">False</span>)  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        <span class="keyword">return</span> self.relu1(x)  </span><br><span class="line">  </span><br><span class="line">mod = DemoModule()  </span><br><span class="line">output = mod(i)  </span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure>

<h3 id="2-Sigmoid"><a href="#2-Sigmoid" class="headerlink" title="(2)Sigmoid"></a>(2)Sigmoid</h3><p>$$<br>\text{Sigmoid}(x) &#x3D; \sigma(x) &#x3D; \frac{1}{1 + \exp(-x)}<br>$$</p>
<h2 id="8-5-Linear-model"><a href="#8-5-Linear-model" class="headerlink" title="8.5 Linear model"></a>8.5 Linear model</h2><p><code>nn.Linear</code><br>Parameters</p>
<ul>
<li><p><strong>in_features</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – size of each input sample</p>
</li>
<li><p><strong>out_features</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.12)"><em>int</em></a>) – size of each output sample（下一层要输出的个数）</p>
</li>
<li><p><strong>bias</strong> (<a target="_blank" rel="noopener" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.12)"><em>bool</em></a>) – If set to <code>False</code>, the layer will not learn an additive bias. Default: <code>True</code></p>
</li>
</ul>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514142823.png" class="">

<p>就是全连接层。把数据<font color="#f79646">摊平</font>之后，进行kx+bias的变化，再输出到指定数目的节点去。</p>
<p>#torchflatten<br><code>torch.flatten</code>：把数据展开到一维</p>
<h1 id="9-损失函数与反向传播"><a href="#9-损失函数与反向传播" class="headerlink" title="9 损失函数与反向传播"></a>9 损失函数与反向传播</h1><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>神经网络通过<font color="#f79646">学习损失函数（Loss Function）</font>寻找最优权重参数。</p>
<ol>
<li>计算实际输出和目标之间的差距</li>
<li>为更新输出提供依据（反向传播），grad（梯度）</li>
</ol>
<p>#损失函数<br>常用的损失函数：</p>
<ul>
<li><p>均方误差（mean squared erro）</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514151828.png" class="">
</li>
<li><p>交叉熵误差</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240514151848.png" class="">
<blockquote>
<p>只计算对应正确解标签的输出的自然对数。</p>
</blockquote>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn  </span><br><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line">loss = nn.L1Loss()  </span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)  </span><br><span class="line">target = torch.randn(<span class="number">3</span>, <span class="number">5</span>)  </span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>)  </span><br><span class="line"><span class="built_in">print</span>(target)  </span><br><span class="line">output = loss(<span class="built_in">input</span>, target)  </span><br><span class="line"><span class="built_in">print</span>(output)  </span><br><span class="line">  </span><br><span class="line">loss_mes = nn.MSELoss()  </span><br><span class="line">  </span><br><span class="line">result_mse = loss_mes(<span class="built_in">input</span>, target)  </span><br><span class="line"><span class="built_in">print</span>(result_mse)</span><br></pre></td></tr></table></figure>

<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240519105814.png" class="">

<h1 id="10-优化器"><a href="#10-优化器" class="headerlink" title="10 优化器"></a>10 优化器</h1><p>#优化器<br>用backward进行反向传播，计算出每一个节点的参数，有了参数梯度之后，就可以选择合适的优化器进行优化，对loss达到一个降低的目的。</p>
<p><a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/optim.html">https://pytorch.org/docs/stable/optim.html</a></p>
<h2 id="SGD随机梯度下降"><a href="#SGD随机梯度下降" class="headerlink" title="SGD随机梯度下降"></a>SGD随机梯度下降</h2><p>#SGD</p>
<ul>
<li><p>初始化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">optimizer = optim.Adam([var1, var2], lr=<span class="number">0.0001</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化参数<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520002324.png" class=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">optim.SGD([</span><br><span class="line">                &#123;<span class="string">&#x27;params&#x27;</span>: model.base.parameters(), <span class="string">&#x27;lr&#x27;</span>: <span class="number">1e-2</span>&#125;,</span><br><span class="line">                &#123;<span class="string">&#x27;params&#x27;</span>: model.classifier.parameters()&#125;</span><br><span class="line">            ], lr=<span class="number">1e-3</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>[!NOTE]<br>这里的代码使用了PyTorch中的<code>optim.SGD</code>优化器来训练模型。这个优化器采用了随机梯度下降（Stochastic Gradient Descent，SGD）的方法，并添加了动量（momentum）来加速训练过程。</p>
<p>具体解释如下：</p>
<ol>
<li><p><strong>optim.SGD</strong>: 这是一个优化器，它实现了随机梯度下降算法。SGD是一种常用的优化算法，用于调整模型参数以最小化损失函数。</p>
</li>
<li><p><strong>params</strong>: 这里指定了要优化的参数集合。代码中将模型的参数分成了两组，分别设置了不同的学习率（learning rate，lr）。</p>
<ul>
<li><code>&#123;&#39;params&#39;: model.base.parameters(), &#39;lr&#39;: 1e-2&#125;</code>：这表示模型的基础层（base）参数使用一个学习率为0.01（1e-2）的值进行优化。</li>
<li><code>&#123;&#39;params&#39;: model.classifier.parameters()&#125;</code>：这表示模型的分类器（classifier）层的参数。没有指定单独的学习率，因此这些参数将使用外层的学习率1e-3。</li>
</ul>
</li>
<li><p><strong>lr</strong>: 学习率是一个超参数，控制每次参数更新的步长。这里有两个学习率：</p>
<ul>
<li><code>1e-2</code>（0.01）用于基础层参数。</li>
<li><code>1e-3</code>（0.001）用于分类器层参数（外层指定的学习率）。</li>
</ul>
</li>
<li><p><strong>momentum</strong>: 动量是一个超参数，用于加速SGD在相关方向上的收敛，并抑制震荡。动量项在参数更新时引入了历史梯度的累积，使得优化过程更稳定。这里设置的动量值为0.9。</p>
</li>
</ol>
<p>综上所述，这段代码的含义是使用带有动量的随机梯度下降算法来优化模型的参数，其中基础层参数的学习率设置为0.01，分类器层参数的学习率设置为0.001。动量参数设置为0.9。这样可以在训练过程中更好地控制模型的更新步长和收敛速度。</p>
</blockquote>
<ul>
<li>使用demo<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> <span class="built_in">input</span>, target <span class="keyword">in</span> dataset:</span><br><span class="line"><span class="comment"># - 在进行反向传播和梯度计算之前，先将优化器中的所有参数的梯度缓存清零。</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    output = model(<span class="built_in">input</span>)</span><br><span class="line">    <span class="comment"># 计算模型输出 `output` 和目标标签 `target` 之间的损失（误差）</span></span><br><span class="line">    loss = loss_fn(output, target)</span><br><span class="line">    <span class="comment"># 进行反向传播，计算损失相对于模型参数的梯度</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="comment"># - 使用计算得到的梯度，按照优化算法更新模型的参数。</span></span><br><span class="line">    <span class="comment"># - 这里的 `optimizer` 是前面定义的优化器（如 `optim.SGD`），它根据参数的梯度和学习率来调整参数的值，使损失函数逐渐减小，从而优化模型。</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure></li>
</ul>
<p>训练部分代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">loss = nn.CrossEntropyLoss()<span class="comment"># 交叉熵  </span></span><br><span class="line">net = NeuralNetwork()  </span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)  </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):  </span><br><span class="line">    running_loss = <span class="number">0.0</span> <span class="comment"># 每次开始前，把loss设置为0  </span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> test_loader:  </span><br><span class="line">        <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">        这个for相当于只对data进行了一轮的学习，  </span></span><br><span class="line"><span class="string">        通常需要好几轮的学习，才能有所改善。        所以需要外层的epoch  </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>        imgs, labels = data  </span><br><span class="line">        outputs = net(imgs)  </span><br><span class="line">  </span><br><span class="line">        result_loss = loss(outputs, labels)  </span><br><span class="line">  </span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 对之前的记录清零  </span></span><br><span class="line">        result_loss.backward()  </span><br><span class="line">        optimizer.step()  </span><br><span class="line">        <span class="comment"># print(result_loss)  </span></span><br><span class="line">        running_loss = running_loss + result_loss  </span><br><span class="line">        <span class="comment"># 整体误差总和  </span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;epoch:&#123;&#125;, loss:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(epoch, running_loss))</span><br></pre></td></tr></table></figure>

<h1 id="11-现有网络模型的使用和修改"><a href="#11-现有网络模型的使用和修改" class="headerlink" title="11 现有网络模型的使用和修改"></a>11 现有网络模型的使用和修改</h1><p>在pytorch的官方文档中，torchvision或torchtext等文件中，包含了相关领域中的经典网络模型。</p>
<h2 id="11-1-VGG简介"><a href="#11-1-VGG简介" class="headerlink" title="11.1 VGG简介"></a>11.1 VGG简介</h2><p>常用的版本：</p>
<ul>
<li>vgg16<ul>
<li>pretrained：在ImageNet中与训练(这个数据集130G+，而且不能torchvision直接下载，需要自己寻找资源)</li>
<li>progress：下载进度条</li>
</ul>
</li>
<li>vgg19</li>
</ul>
<p>初始化的时候，True会下载参数（很大）</p>
<p>VGG16常被用来作为迁移学习等模型的前半部分，用于提取一些图像的特殊特征，在后续的模型中对这些特征进行一个进一步的学习。</p>
<h4 id="利用现有的网络，套到自己的数据集上"><a href="#利用现有的网络，套到自己的数据集上" class="headerlink" title="利用现有的网络，套到自己的数据集上"></a>利用现有的网络，套到自己的数据集上</h4><p>VGG使用了ImageNet进行训练，输出的最后一层与ImageNet的类别数量相同，都是1000，如何把这个现有的模型改成我需要的模型？</p>
<blockquote>
<p>之前的数据集为例</p>
</blockquote>
<ul>
<li>方法一：把最后一个输出层后追加一层input为10000，output为10的线性层。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vgg16_false.add_module(<span class="string">&#x27;add_linear&#x27;</span>, nn.Linear(<span class="number">1000</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520135525.png" class=""></li>
</ul>
<p>如果要加到上面那个括号（classifier）里面：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vgg16_false.classifier.add_module(<span class="string">&#x27;add_linear&#x27;</span>, nn.Linear(<span class="number">1000</span>, <span class="number">10</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li>方法二：直接修改模型最后一层<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520135809.png" class=""></li>
</ul>
<h1 id="12-网络模型的保存与读取"><a href="#12-网络模型的保存与读取" class="headerlink" title="12 网络模型的保存与读取"></a>12 网络模型的保存与读取</h1><h2 id="12-1-保存模型与参数"><a href="#12-1-保存模型与参数" class="headerlink" title="12.1 保存模型与参数"></a>12.1 保存模型与参数</h2><p>这种方法可以保存模型的结构和模型的参数。<br>缺点：</p>
<ul>
<li><p>若模型较大，则保存文件也会很大</p>
</li>
<li><p>Save model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line">torch.save(vgg16, <span class="string">&#x27;vgg16_method.pth&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>第一个参数：模型<br>第二个参数：保存的文件名，通常用.pth作为文件类型</p>
<ul>
<li>load model<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load Method 1:  </span></span><br><span class="line">model_1 = torch.load(<span class="string">&quot;vgg16_method.pth&quot;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><font color="#f79646">这个方式是存在陷阱的：</font><br>如果是自己定义了一个模型，对这个模型进行保存。则加载的时候会产生报错。</p>
<p>为了解决这个问题，则需要自己重新定义一次自定义的模型结构：</p>
<blockquote>
<p>比如我在model文件创建并保存了数据，在load文件里面需要重新定义（无需new）一次这个模型，才能继续正常使用</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240520145856.png" class="">
</blockquote>
<h2 id="12-2-保存模型参数"><a href="#12-2-保存模型参数" class="headerlink" title="12.2 保存模型参数"></a>12.2 保存模型参数</h2><p>这个方法将模型的参数作为字典进行保存，所以加载的时候，要用字典加载的方式，放入新的模型中。</p>
<blockquote>
<p>官方推荐的方法</p>
</blockquote>
<ul>
<li><p>Save model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(vgg16.state_dict(), <span class="string">&#x27;vgg16_state_dict.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>load model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Specify a path</span></span><br><span class="line">PATH = <span class="string">&quot;state_dict_model.pt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Save</span></span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load</span></span><br><span class="line">model = Net()</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br></pre></td></tr></table></figure></li>
</ul>
<blockquote>
<p>[!NOTE]<br>两种方式一定要对应。<br>※不知道为什么，在下个章节代码实现的时候，我无法用方法二的步骤正常创建模型</p>
</blockquote>
<h1 id="12-完整模型训练套路"><a href="#12-完整模型训练套路" class="headerlink" title="12 完整模型训练套路"></a>12 完整模型训练套路</h1><blockquote>
<p>以CIFAR10 为例</p>
</blockquote>
<p>步骤说明：</p>
<ol>
<li>初始化训练集、测试集，转换为Dataloader</li>
<li>初始化自己的模型</li>
<li>定义损失函数和优化器</li>
<li>定义训练次数 epoch</li>
<li>进行迭代epoch<ol>
<li>从dataloader中每次取数据进行训练<ol>
<li>得到output</li>
<li>得到output与labels的loss</li>
<li>优化器置零</li>
<li>反传播</li>
<li>优化器优化参数</li>
</ol>
</li>
<li>在测试集中检测——取消grad</li>
</ol>
</li>
</ol>
<blockquote>
<p>在流程中合适的地方对结果进行输出或者保存。</p>
</blockquote>
<ol>
<li>定义模型</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;  </span></span><br><span class="line"><span class="string">@Project ：pythonProject @File    ：MyModel.py  </span></span><br><span class="line"><span class="string">@IDE     ：PyCharm @Author  ：周大猛  </span></span><br><span class="line"><span class="string">@Date    ：2024/05/20 15:21 &#x27;&#x27;&#x27;</span>  </span><br><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TongModel</span>(nn.Module):  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):  </span><br><span class="line">        <span class="built_in">super</span>(TongModel, self).__init__()  </span><br><span class="line">        self.model = nn.Sequential(  </span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>),  </span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),  </span><br><span class="line">            nn.Flatten(),  </span><br><span class="line">            nn.Linear(<span class="number">64</span> * <span class="number">4</span> * <span class="number">4</span>, <span class="number">64</span>),  </span><br><span class="line">            nn.Linear(<span class="number">64</span>, <span class="number">10</span>),  </span><br><span class="line">        )  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):  </span><br><span class="line">        x = self.model(x)  </span><br><span class="line">        <span class="keyword">return</span> x  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:  </span><br><span class="line">    <span class="comment"># 测试网络模型的正确性  </span></span><br><span class="line">    model = TongModel()  </span><br><span class="line">    <span class="comment"># 64个图片，3个通道，尺寸32*32  </span></span><br><span class="line">    <span class="built_in">input</span> = torch.ones((<span class="number">64</span>, <span class="number">3</span>, <span class="number">32</span>, <span class="number">32</span>))  </span><br><span class="line">    output = model(<span class="built_in">input</span>)  </span><br><span class="line">    <span class="comment">#torch.Size([64, 10]) 64个图片，10个数据表示每个类别的可能性  </span></span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>[!NOTE]<br>通常在专门的模型py文件中对模型进行定义，方便管理，修改、检查模型每层的正确性。</p>
</blockquote>
<ol start="2">
<li>数据集<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 准备训练数据  </span></span><br><span class="line">train_data  = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,transform=transforms.ToTensor())  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 准备测试数据  </span></span><br><span class="line">test_data = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>,transform=transforms.ToTensor())  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 查看数据集信息  </span></span><br><span class="line">train_data_size = <span class="built_in">len</span>(train_data)  </span><br><span class="line">test_data_size = <span class="built_in">len</span>(test_data)  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Train data size: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_data_size) )  </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test data size: %d&quot;</span> % test_data_size)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用dataloader加载数据集  </span></span><br><span class="line">train_dataloader = DataLoader(train_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)  </span><br><span class="line">test_dataloader = DataLoader(test_data, batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<blockquote>
<p>[!NOTE]<br>下载好数据集后，用dataloader进行封装。</p>
</blockquote>
<ol start="3">
<li>导入神经网络，初始化模型</li>
</ol>
<ul>
<li>模型初始化</li>
<li>损失函数</li>
<li>优化器</li>
<li>学习率</li>
<li>训练进度</li>
<li>测试进度</li>
<li>迭代次数</li>
<li>保存数据位置<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> MyModel <span class="keyword">import</span> *  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 创建网络模型  </span></span><br><span class="line">model = TongModel()  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 损失函数和优化器  </span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()  </span><br><span class="line">learning_rate = <span class="number">1e-2</span>  </span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span>)  </span><br><span class="line">  </span><br><span class="line"><span class="comment"># 设置训练参数  </span></span><br><span class="line">total_train_step = <span class="number">0</span> <span class="comment"># 记录训练次数  </span></span><br><span class="line">total_test_step = <span class="number">0</span> <span class="comment"># 记录测试次数  </span></span><br><span class="line">epoch = <span class="number">100</span> <span class="comment"># 训练的轮数  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 使用tensorboard记录数据  </span></span><br><span class="line">writer = SummaryWriter(<span class="string">&#x27;./logs_train&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ul>
<ol start="4">
<li>训练与测试<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):  </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch &#123;&#125;/&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i, epoch))  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 训练开始  </span></span><br><span class="line">    model.train() <span class="comment"># 当模型有dropout等特殊层的时候，起作用  </span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> train_dataloader:  </span><br><span class="line">        imgs, labels = data  </span><br><span class="line">        output = model(imgs)  </span><br><span class="line">        <span class="comment"># 计算输出和真实的损失  </span></span><br><span class="line">        loss = loss_fn(output, labels)  </span><br><span class="line">  </span><br><span class="line">        <span class="comment"># 优化器优化模型  </span></span><br><span class="line">        optimizer.zero_grad() <span class="comment"># 准备优化，先梯度清零  </span></span><br><span class="line">        loss.backward() <span class="comment">#得到每个参数的梯度  </span></span><br><span class="line">        optimizer.step() <span class="comment"># 对参数进行优化  </span></span><br><span class="line">        total_train_step += <span class="number">1</span>  </span><br><span class="line">        <span class="keyword">if</span> total_train_step % <span class="number">100</span> == <span class="number">0</span>:  </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Total train step:&#123;&#125;, Loss:&#123;&#125;&#x27;</span> .<span class="built_in">format</span>(total_train_step, loss.item()))  </span><br><span class="line">            writer.add_scalar(<span class="string">&#x27;Loss/train&#x27;</span>, loss.item(), total_train_step)  </span><br><span class="line">    <span class="string">&quot;&quot;&quot;  </span></span><br><span class="line"><span class="string">    每次训练一轮之后，需要知道本次训练之后在测试集上模型表现是否有进步。  </span></span><br><span class="line"><span class="string">    在第一层的for中，对此进行检测。  </span></span><br><span class="line"><span class="string">    这里不需要对模型进行调优。    需要知道在整个数据集上的loss  </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span>    model.<span class="built_in">eval</span>() <span class="comment"># 与train（）一个情况  </span></span><br><span class="line">    total_test_loss = <span class="number">0.0</span>  </span><br><span class="line">  </span><br><span class="line">    <span class="comment"># 计算ACC  </span></span><br><span class="line">    total_accuracy = <span class="number">0</span>  </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():  </span><br><span class="line">        <span class="comment"># 没有梯度了  </span></span><br><span class="line">        <span class="comment"># 测试开始  </span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> test_dataloader:  </span><br><span class="line">            imgs, labels = data  </span><br><span class="line">            output = model(imgs)  </span><br><span class="line">            loss = loss_fn(output, labels)  </span><br><span class="line">            total_test_step += <span class="number">1</span>  </span><br><span class="line">            total_test_loss += loss.item()  </span><br><span class="line">            accuracy = (output.argmax(dim=<span class="number">1</span>)==labels).<span class="built_in">sum</span>()  </span><br><span class="line">            total_accuracy += accuracy.item()  </span><br><span class="line">  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;Total test  Loss:&#123;&#125;&#x27;</span> .<span class="built_in">format</span>(total_test_loss))  </span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;Loss/test&#x27;</span>, total_test_loss, total_test_step)  </span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;整体测试集的正确率:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(total_accuracy/test_data_size))  </span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;Accuracy/test&#x27;</span>, total_accuracy/test_data_size, total_test_step)  </span><br><span class="line">  </span><br><span class="line">    torch.save(model.state_dict(), <span class="string">&#x27;./modelData/model_&#123;&#125;.pt&#x27;</span>.<span class="built_in">format</span>(i))  </span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="13-使用GPU训练"><a href="#13-使用GPU训练" class="headerlink" title="13 使用GPU训练"></a>13 使用GPU训练</h1><p>有两种使用GPU的方式</p>
<h2 id="13-1"><a href="#13-1" class="headerlink" title="13.1"></a>13.1</h2><p><code>.cuda</code></p>
<ul>
<li><p>网络模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建网络模型  </span></span><br><span class="line">model = TongModel()  </span><br><span class="line">model = model.cuda()</span><br></pre></td></tr></table></figure></li>
<li><p>数据的输入和标注</p>
<blockquote>
<p>在训练和测试的部分</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">imgs, labels = data  </span><br><span class="line">imgs = imgs.cuda()  </span><br><span class="line">labels = labels.cuda()</span><br></pre></td></tr></table></figure>

</li>
<li><p>损失函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 损失函数和优化器  </span></span><br><span class="line">loss_fn = nn.CrossEntropyLoss()  </span><br><span class="line">loss_fn = loss_fn.cuda()</span><br></pre></td></tr></table></figure></li>
</ul>
<p>良好的写法：</p>
<img src="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/Pasted%20image%2020240521003749.png" class="">


<h2 id="13-2"><a href="#13-2" class="headerlink" title="13.2"></a>13.2</h2><p>方法二：<code>.to(device)</code></p>
<ol>
<li>定义训练的设备<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">   <span class="comment"># 定义训练的设备  </span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
</ol>
<p>然后之前该国的地方都改成</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>


<h1 id="14-完整模型验证套路"><a href="#14-完整模型验证套路" class="headerlink" title="14 完整模型验证套路"></a>14 完整模型验证套路</h1><p>给训练好的模型提供输入。</p>
<p>与测试部分类似，大概流程如下：</p>
<ol>
<li>准备数据（自己准备的，非数据集的测试部分或训练部分）</li>
<li>导入模型</li>
<li>模型初始化</li>
<li>模型参数初始化</li>
<li>在测试模式下，输入准备的数据</li>
<li>获得结果，并进行对比</li>
</ol>
<h1 id="15-Github开源代码"><a href="#15-Github开源代码" class="headerlink" title="15 Github开源代码"></a>15 Github开源代码</h1><p>只说说注意事项：</p>
<ol>
<li>仔细阅读README</li>
<li>参数部分可以在代码中找到描述</li>
</ol>
</div><div class="article-licensing box"><div class="licensing-title"><p>PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆</p><p><a href="https://zhouwentong7.github.io/2024/05/22/PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/">https://zhouwentong7.github.io/2024/05/22/PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Zhou</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-05-22</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2024-05-22</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/pytorch/">pytorch</a><a class="link-muted mr-2" rel="tag" href="/tags/deep-learning/">deep learning</a></div><div class="sharethis-inline-share-buttons"></div><script src="None" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" href="/None" target="_blank" rel="noopener" data-type="afdian"><span class="icon is-small"><i class="fas fa-charging-station"></i></span><span>爱发电</span></a><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/None" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechatPay.jpg" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/06/11/%E7%95%99%E5%AD%A6%E8%AE%B0%E5%BD%95-5/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">留学记录-5</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/05/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BC%9A%E8%AE%AE%E5%8F%8A%E6%9C%9F%E5%88%8A%E6%80%BB%E7%BB%93/"><span class="level-item">计算机会议及期刊总结</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/DSCF4111.JPG" alt="周大猛"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">周大猛</p><p class="is-size-6 is-block">擅长写三流的代码,一流的bug</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">22</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">18</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ZhouWentong7" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ZhouWentong7"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#1-环境配置"><span class="level-left"><span class="level-item">1</span><span class="level-item">1 环境配置</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#conda"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">conda</span></span></a></li><li><a class="level is-mobile" href="#技巧pip"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">技巧pip</span></span></a></li><li><a class="level is-mobile" href="#安装Pytorch"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">安装Pytorch</span></span></a></li><li><a class="level is-mobile" href="#检验安装"><span class="level-left"><span class="level-item">1.4</span><span class="level-item">检验安装</span></span></a></li></ul></li><li><a class="level is-mobile" href="#2-编辑器的选择"><span class="level-left"><span class="level-item">2</span><span class="level-item">2 编辑器的选择</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#PyCharm"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">PyCharm</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#配置PyCharm"><span class="level-left"><span class="level-item">2.1.1</span><span class="level-item">配置PyCharm</span></span></a></li></ul></li><li><a class="level is-mobile" href="#一些技巧"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">一些技巧</span></span></a></li><li><a class="level is-mobile" href="#Jupyter"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Jupyter</span></span></a></li><li><a class="level is-mobile" href="#jupyter-配置"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">jupyter 配置</span></span></a></li></ul></li><li><a class="level is-mobile" href="#3-Python的两大法宝函数"><span class="level-left"><span class="level-item">3</span><span class="level-item">3 Python的两大法宝函数</span></span></a></li><li><a class="level is-mobile" href="#4-浅对比PyCharm，python控制台和Jupyter"><span class="level-left"><span class="level-item">4</span><span class="level-item">4 浅对比PyCharm，python控制台和Jupyter</span></span></a></li><li><a class="level is-mobile" href="#5-PyTorch加载数据"><span class="level-left"><span class="level-item">5</span><span class="level-item">5 PyTorch加载数据</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#提供不同的数据形式"><span class="level-left"><span class="level-item">5.1</span><span class="level-item">提供不同的数据形式</span></span></a></li><li><a class="level is-mobile" href="#5-1-TensorBoard的使用"><span class="level-left"><span class="level-item">5.2</span><span class="level-item">5.1 TensorBoard的使用</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#SummaryWriter"><span class="level-left"><span class="level-item">5.2.1</span><span class="level-item">SummaryWriter</span></span></a></li><li><a class="level is-mobile" href="#writer-add-scalar"><span class="level-left"><span class="level-item">5.2.2</span><span class="level-item">writer.add_scalar()</span></span></a></li><li><a class="level is-mobile" href="#writer-add-image"><span class="level-left"><span class="level-item">5.2.3</span><span class="level-item">writer.add_image()</span></span></a></li><li><a class="level is-mobile" href="#writer-add-graph-net-input"><span class="level-left"><span class="level-item">5.2.4</span><span class="level-item">writer.add_graph(net,input)</span></span></a></li></ul></li><li><a class="level is-mobile" href="#5-2-Transform"><span class="level-left"><span class="level-item">5.3</span><span class="level-item">5.2 Transform</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#ToTensor"><span class="level-left"><span class="level-item">5.3.1</span><span class="level-item">ToTensor</span></span></a></li><li><a class="level is-mobile" href="#归一化Normalization"><span class="level-left"><span class="level-item">5.3.2</span><span class="level-item">归一化Normalization</span></span></a></li><li><a class="level is-mobile" href="#Resize"><span class="level-left"><span class="level-item">5.3.3</span><span class="level-item">Resize()</span></span></a></li><li><a class="level is-mobile" href="#Compose"><span class="level-left"><span class="level-item">5.3.4</span><span class="level-item">Compose()</span></span></a></li><li><a class="level is-mobile" href="#RandomCrop-随机裁剪"><span class="level-left"><span class="level-item">5.3.5</span><span class="level-item">RandomCrop()随机裁剪</span></span></a></li><li><a class="level is-mobile" href="#总结"><span class="level-left"><span class="level-item">5.3.6</span><span class="level-item">总结</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#6-Torchvision的数据集使用"><span class="level-left"><span class="level-item">6</span><span class="level-item">6 Torchvision的数据集使用</span></span></a></li><li><a class="level is-mobile" href="#7-Dataloader的使用"><span class="level-left"><span class="level-item">7</span><span class="level-item">7 Dataloader的使用</span></span></a></li><li><a class="level is-mobile" href="#8-网络搭建"><span class="level-left"><span class="level-item">8</span><span class="level-item">8 网络搭建</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#8-1-Containers"><span class="level-left"><span class="level-item">8.1</span><span class="level-item">8.1 Containers</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#nn-Module"><span class="level-left"><span class="level-item">8.1.1</span><span class="level-item">nn.Module</span></span></a></li></ul></li><li><a class="level is-mobile" href="#8-2-卷积层操作与卷积层"><span class="level-left"><span class="level-item">8.2</span><span class="level-item">8.2 卷积层操作与卷积层</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#（1）卷积操作"><span class="level-left"><span class="level-item">8.2.1</span><span class="level-item">（1）卷积操作</span></span></a></li><li><a class="level is-mobile" href="#（2）卷积层"><span class="level-left"><span class="level-item">8.2.2</span><span class="level-item">（2）卷积层</span></span></a></li></ul></li><li><a class="level is-mobile" href="#8-3-池化"><span class="level-left"><span class="level-item">8.3</span><span class="level-item">8.3 池化</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#特征"><span class="level-left"><span class="level-item">8.3.1</span><span class="level-item">特征</span></span></a></li></ul></li><li><a class="level is-mobile" href="#8-4-非线性激活"><span class="level-left"><span class="level-item">8.4</span><span class="level-item">8.4 非线性激活</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#（1）-ReLu（Rectified-Linear-Unit）"><span class="level-left"><span class="level-item">8.4.1</span><span class="level-item">（1） ReLu（Rectified Linear Unit）</span></span></a></li><li><a class="level is-mobile" href="#2-Sigmoid"><span class="level-left"><span class="level-item">8.4.2</span><span class="level-item">(2)Sigmoid</span></span></a></li></ul></li><li><a class="level is-mobile" href="#8-5-Linear-model"><span class="level-left"><span class="level-item">8.5</span><span class="level-item">8.5 Linear model</span></span></a></li></ul></li><li><a class="level is-mobile" href="#9-损失函数与反向传播"><span class="level-left"><span class="level-item">9</span><span class="level-item">9 损失函数与反向传播</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#损失函数"><span class="level-left"><span class="level-item">9.1</span><span class="level-item">损失函数</span></span></a></li><li><a class="level is-mobile" href="#反向传播"><span class="level-left"><span class="level-item">9.2</span><span class="level-item">反向传播</span></span></a></li></ul></li><li><a class="level is-mobile" href="#10-优化器"><span class="level-left"><span class="level-item">10</span><span class="level-item">10 优化器</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#SGD随机梯度下降"><span class="level-left"><span class="level-item">10.1</span><span class="level-item">SGD随机梯度下降</span></span></a></li></ul></li><li><a class="level is-mobile" href="#11-现有网络模型的使用和修改"><span class="level-left"><span class="level-item">11</span><span class="level-item">11 现有网络模型的使用和修改</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#11-1-VGG简介"><span class="level-left"><span class="level-item">11.1</span><span class="level-item">11.1 VGG简介</span></span></a></li></ul></li><li><a class="level is-mobile" href="#12-网络模型的保存与读取"><span class="level-left"><span class="level-item">12</span><span class="level-item">12 网络模型的保存与读取</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#12-1-保存模型与参数"><span class="level-left"><span class="level-item">12.1</span><span class="level-item">12.1 保存模型与参数</span></span></a></li><li><a class="level is-mobile" href="#12-2-保存模型参数"><span class="level-left"><span class="level-item">12.2</span><span class="level-item">12.2 保存模型参数</span></span></a></li></ul></li><li><a class="level is-mobile" href="#12-完整模型训练套路"><span class="level-left"><span class="level-item">13</span><span class="level-item">12 完整模型训练套路</span></span></a></li><li><a class="level is-mobile" href="#13-使用GPU训练"><span class="level-left"><span class="level-item">14</span><span class="level-item">13 使用GPU训练</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#13-1"><span class="level-left"><span class="level-item">14.1</span><span class="level-item">13.1</span></span></a></li><li><a class="level is-mobile" href="#13-2"><span class="level-left"><span class="level-item">14.2</span><span class="level-item">13.2</span></span></a></li></ul></li><li><a class="level is-mobile" href="#14-完整模型验证套路"><span class="level-left"><span class="level-item">15</span><span class="level-item">14 完整模型验证套路</span></span></a></li><li><a class="level is-mobile" href="#15-Github开源代码"><span class="level-left"><span class="level-item">16</span><span class="level-item">15 Github开源代码</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-13T04:50:16.000Z">2024-08-13</time></p><p class="title"><a href="/2024/08/13/Python%E8%AF%BB%E5%8F%96-nii%E6%96%87%E4%BB%B6/">Python读取.nii文件</a></p><p class="categories"><a href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/">技能学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-11T05:51:28.000Z">2024-06-11</time></p><p class="title"><a href="/2024/06/11/%E7%95%99%E5%AD%A6%E8%AE%B0%E5%BD%95-5/">留学记录-5</a></p><p class="categories"><a href="/categories/%E7%94%9F%E6%B4%BB/">生活</a> / <a href="/categories/%E7%94%9F%E6%B4%BB/%E7%95%99%E5%AD%A6/">留学</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-21T15:23:07.000Z">2024-05-22</time></p><p class="title"><a href="/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/">PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆</a></p><p class="categories"><a href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/">技术学习</a> / <a href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-07T05:53:24.000Z">2024-05-07</time></p><p class="title"><a href="/2024/05/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BC%9A%E8%AE%AE%E5%8F%8A%E6%9C%9F%E5%88%8A%E6%80%BB%E7%BB%93/">计算机会议及期刊总结</a></p><p class="categories"><a href="/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/">知识科普</a> / <a href="/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-03-21T14:33:51.000Z">2024-03-21</time></p><p class="title"><a href="/2024/03/21/%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96/">文件或目录损坏且无法读取</a></p><p class="categories"><a href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/">技能学习</a> / <a href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E7%A1%AC%E4%BB%B6/">硬件</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">技术学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">技能学习</span></span><span class="level-end"><span class="level-item tag">11</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Java/%E7%8E%AF%E5%A2%83/"><span class="level-start"><span class="level-item">环境</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/markdown/"><span class="level-start"><span class="level-item">markdown</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86/"><span class="level-start"><span class="level-item">代码管理</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E7%A1%AC%E4%BB%B6/"><span class="level-start"><span class="level-item">硬件</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%94%9F%E6%B4%BB/"><span class="level-start"><span class="level-item">生活</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%94%9F%E6%B4%BB/%E7%95%99%E5%AD%A6/"><span class="level-start"><span class="level-item">留学</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%E7%94%9F%E6%B4%BB/%E9%97%B2%E8%AF%9D/"><span class="level-start"><span class="level-item">闲话</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/"><span class="level-start"><span class="level-item">知识科普</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA/"><span class="level-start"><span class="level-item">计算机</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Java/"><span class="tag">Java</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github/"><span class="tag">github</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/markdown/"><span class="tag">markdown</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/pytorch/"><span class="tag">pytorch</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%86%99%E4%BD%9C/"><span class="tag">写作</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D/"><span class="tag">数据恢复</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/"><span class="tag">文件读取</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A1%AC%E4%BB%B6/"><span class="tag">硬件</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%A7%91%E7%A0%94/"><span class="tag">科研</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%97%B2%E8%AF%9D/"><span class="tag">闲话</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E6%8B%8D/"><span class="tag">随拍</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%9A%8F%E7%AC%94/"><span class="tag">随笔</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"><span class="tag">项目管理</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/">一个小角落</a><p class="is-size-7"><span>&copy; 2024 Zhou</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p><p class="is-size-7">© 2019</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ZhouWentong7"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>