{"posts":[{"title":"Attention Gate in Attention UNet","text":"对Attention UNet中使用的Attention Gate（AG）进行介绍和代码分析。 1 Attention UNet 原文链接 于2018年被收录于cvpr，在UNet的基础上，decoder的部分增加Attention Gate，以突出通过跳转连接的突出特征。文中介绍了2D和3D的实现方法。 Attention UNet整体结构如下： 从原文中的实验结果来看，Attention UNet 都相较于U-Net在多个数据集（CT-150，TCIA Pancreas-CT,eg.）上有更优秀的分割性能，且从可视化结果来看，Attention UNet有更平滑且准确的边缘。 2 Attention Gate 下面来详细了解一下这个UNet中的Attention Gate。 作用：自适应地选择有用的特征，抑制无关的区域。 2.1 AG的结构与原理 $x^l$:从encoder对应层skip来的特征图，通常是高分辨率的图像。 可能包含冗余和无关信息 $g$：从上采样而来的低分辨率信号。 解码器当前关注的区域，帮助引导关注重点 处理流程 假设：$x^l$（1,64,64,64）,$g$(1,128,32,32) 通常g的空间尺寸更小，channel更大 将两个输入使用$1\\times 1$卷积映射到统一维度 对齐空间尺寸（上采样gating信号）：可以使用线性插值 权重大的特征在相加后更加明显 融合后是使用ReLU激活 $1\\times 1$卷积：通道降到1通道size:(1,1,32,32) 得到mask：sigmoid将值映射到0~1之间 mask与$x^l$相乘，得到“重要区域”特征值更强，“不重要区域”被抑制的特征图。 1234567891011121314151617181920 x (1, 64, 64, 64) │[1×1 Conv] →────────────┐ │ │ (1, 32, 64, 64) │ ▼ Add + ReLU ▲[Upsample] ←── [1×1 Conv] ← g (1, 128, 32, 32) (1, 32, 64, 64) │ [1×1 Conv + Sigmoid] ↓ Attention mask (1, 1, 64, 64) ↓ Element-wise multiplication ↓ Output: (1, 64, 64, 64) 2.2 Pytorch 实现AG（2D） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import torchimport torch.nn as nnimport torch.nn.functional as Fclass AttentionGate2D(nn.Module): def __init__(self, F_g, F_l, F_int): &quot;&quot;&quot; F_g: decoder 的通道数 (gating) F_l: encoder 的通道数 (local feature x) F_int: 中间通道数 &quot;&quot;&quot; super(AttentionGate2D, self).__init__() self.W_g = nn.Sequential( nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True), nn.BatchNorm2d(F_int) ) self.W_x = nn.Sequential( nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True), nn.BatchNorm2d(F_int) ) self.psi = nn.Sequential( nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True), nn.BatchNorm2d(1), nn.Sigmoid() ) self.relu = nn.ReLU(inplace=True) def forward(self, x, g): &quot;&quot;&quot; x: 来自 encoder 的特征图 (B, F_l, H, W) g: 来自 decoder 的 gating 信号 (B, F_g, H', W') &quot;&quot;&quot; g1 = self.W_g(g) # (B, F_int, H', W') x1 = self.W_x(x) # (B, F_int, H, W) # 上采样 gating 信号（如果大小不一致） if g1.shape[-2:] != x1.shape[-2:]: g1 = F.interpolate(g1, size=x1.shape[-2:], mode='bilinear', align_corners=True) psi = self.relu(g1 + x1) # (B, F_int, H, W) psi = self.psi(psi) # (B, 1, H, W) return x * psi # (B, F_l, H, W) × (B, 1, H, W) 在上采样过程中： 12345x = self.up(x) # 上采样 decoder feature mapskip = self.attention_gate(skip, x) # 使用 AG 筛选 encoder featurex = torch.cat([x, skip], dim=1) # 拼接经过 AG 的 skip connectionx = self.conv(x) # 双卷积融合return x","link":"/2025/04/10/Attention-Gate-in-Attention-UNet/"},{"title":"BFS和DFS","text":"广度优先搜索（BFS）与深度优先搜索（DFS）的思路,伪代码和代码实现。 一、简介 BFS和DFS是树和图中非常经典的搜索方法，他们分别用了队列和栈来记录节点以遍历整个数据。 二、BFS BFS 使用队列（Queue）从一个起始节点出发，逐层访问其邻接节点，适合用于最短路径查找等场景。 复杂度分析 （1） 在邻接表 $$O(V+E)$$ 原因：先走完一个节点的所有邻接点（遍历时放入队列中），之后从队列中取出头，然后遍历该点的所有邻接点。所以经过的是：所有的点+所有点接触的边 （2）邻接矩阵 $$O(V^2)$$ 原因：存储的是一整个矩阵，所以需要遍历这个矩阵中的所有位置。矩阵的坐标是任意2点的情况，所以是节点数的平方 ::: info 思考：图结构相比于树结构，会新遇到什么问题？ 树是一种无环结构，不需要担心BFS中出现一个节点被多多次访问的情况。图则可能有环，已经访问过得节点可能再次出现在队列中，陷入死循环。解决方法：设置visited标记，记录已经访问过的节点。 ::: 伪代码 12345678910111213141516171819breadthFirstSearch(v){ Label vertex V as reached. Initialize Q to be a queue withi only v in it. While(Q is not empty) { Delete a vertex w from the queue. Let u be a vertex(if any) adjacent from w. while(u!= NULL) { if (u has not been labeled) { Add u to the queue. Label u as reached. } u = next vertex that is adjacent from w. } }} 算法实现 实现方式： 使用 队列（通常是 collections.deque） C++版 12345678910111213141516171819202122232425virtual void bfs(int v, int reach[], int label){ arrayQueue&lt;int&gt; q(10); reach[v] = label; q.push(v); while(!q.empty()) { int w = q.front(); // 从队列中删除一个标记过的点 q.pop(); // 标记所有没有到达过的w的邻接点 vertexIterator&lt;T&gt; *iw = iterator(w); int u; while((u = iw-&gt;next()) != 0) { // 访问w的一个相邻顶点 if (reach[u]==0) { q.push(u); reach[u] = label; } delete iw; } }} vertexIterator：表示一个模板类型的 顶点迭代器 类。 *iw：声明了一个指针 iw，类型是 vertexIterator。 iterator(w)：调用函数 iterator()，传入参数 w，返回的是一个 vertexIterator 类型的对象指针。 Python版 12345678910111213141516171819202122232425from collections import dequedef bfs(graph, start): visited = set() queue = deque([start]) visited.add(start) while queue: node = queue.popleft() print(node) for neighbor in graph[node]: if neighbor not in visited: visited.add(neighbor) queue.append(neighbor)# 使用示例graph = { 'A': ['B', 'C'], 'B': ['D', 'E'], 'C': ['F'], 'D': [], 'E': [], 'F': []}bfs(graph, 'A') 三、深度优先搜索 与树的前中后遍历相似。DFS 使用回溯的方式，从一个起始节点出发，尽可能深地探索每一条路径，直到走不通再回退。 时间复杂度 （1）邻接表 $$O(V+E)$$ （2）邻接矩阵 $$O(V^2)$$ 伪代码 1234567depthFirstSearch(v){ Label vertex v as reached. for(each unrearched vertex u adjacent from v){ depthFirstSearch(u); }} 代码实现 🔹 实现方式： 递归实现 使用栈实现（模拟递归） C++ 12345678910111213141516171819202122void dfs(int v, int reach[], int label){ graph&lt;T&gt;::reach = reach; graph&lt;T&gt;::label = label; rDFS(v);}void rDFS(int v){ //递归方法 reach[v] = label; vertexIterator&lt;T&gt; *iv = iterator(v); int u; while((u= iv-&gt;next()) != 0) { if (reach[u] != 0) { rDFS(u); } } delete iv;} Python 123456789101112131415161718def dfs(graph, node, visited): if node in visited: return visited.add(node) print(node) # 访问节点 for neighbor in graph[node]: dfs(graph, neighbor, visited)# 使用示例graph = { 'A': ['B', 'C'], 'B': ['D', 'E'], 'C': ['F'], 'D': [], 'E': [], 'F': []}dfs(graph, 'A', set()) 四、对比总结 ⚖️ DFS vs BFS 对比总结 特性 DFS（深度优先） BFS（广度优先） 数据结构 栈（递归或手动） 队列 遍历策略 一路到底、回溯 一层一层遍历 是否找到最短路径 不一定 ✅ 是（在无权图中） 易陷入死循环 是（图中需 visited） 是（图中需 visited） 空间复杂度 O(h)，h 为树高 O(w)，w 为最大宽度 应用场景 拓扑排序、连通块标记等 最短路径、层级遍历等","link":"/2025/04/25/BFS%E5%92%8CDFS/"},{"title":"Dice score分割评价指标","text":"介绍分割任务中常见的评价指标Dice coefficient score。 代码实现和注意事项。 介绍代码实现注意介绍 Dice-Sørensen coefficient用于衡量两个样本相似性的统计量，最初旨在应用于离散数据。 其定义为： $$ DSC = \\frac{2|X \\bigcap Y|}{|X| + |Y|} $$ $|X|$，$|Y|$两个集合的元素。 在图像分割任务中： X和Y:一个代表预测标签，一个代表真实 代码实现 Python手动实现（By Claude）💦 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748 import numpy as npdef dice_score(array1, array2): &quot;&quot;&quot; Calculate Dice coefficient between two 2D binary arrays. Parameters: array1, array2: numpy arrays with binary values (0 and 1) Returns: dice: float, the Dice coefficient between the two arrays &quot;&quot;&quot; # Ensure the inputs are binary array1 = np.asarray(array1).astype(bool) array2 = np.asarray(array2).astype(bool) # Calculate intersection and sum intersection = np.logical_and(array1, array2).sum() sum_arrays = array1.sum() + array2.sum() # Handle edge case where both arrays are empty if sum_arrays == 0: return 1.0 # Both arrays are empty, consider them identical # Calculate Dice coefficient dice = (2.0 * intersection) / sum_arrays return diceif __name__ == '__main__': # Create two sample 2D binary arrays mask1 = np.array([ [0, 0, 0, 0], [0, 1, 1, 0], [0, 1, 1, 0], [0, 0, 0, 0] ]) mask2 = np.array([ [0, 0, 0, 0], [0, 1, 1, 0], [0, 1, 0, 0], [0, 0, 0, 0] ]) # Calculate Dice score score = dice_score(mask1, mask2) print(f&quot;Dice score: {score:.4f}&quot;) # Result: 0.8571 (6/7) 调用medpy中现有的dice计算👍 ::: success 推荐使用这个方法 ::: 1pip install medpy 其具有几个优点： 充分的测试和优化 正确处理边缘情况 无需编写复杂的计算 如果是多分类的时候，可能需要计算不同类别的Dice分数，其实现方法为： 123456789101112131415161718192021222324252627282930from medpy import metricimport numpy as np# For multi-class segmentationdef multi_class_dice(array1, array2, num_classes): &quot;&quot;&quot; Calculate Dice score for each class in multi-class segmentation. Parameters: array1, array2: numpy arrays with class labels (0, 1, 2, etc.) num_classes: number of classes including background Returns: dice_scores: list of Dice scores for each class &quot;&quot;&quot; dice_scores = [] for i in range(num_classes): # Create binary masks for the current class mask1 = (array1 == i).astype(np.uint8) mask2 = (array2 == i).astype(np.uint8) # Calculate Dice score for the current class if np.sum(mask1) == 0 and np.sum(mask2) == 0: # Both masks are empty, consider perfect overlap dice_scores.append(1.0) else: dice_scores.append(metric.binary.dc(mask1, mask2)) return dice_scores medpy中包含了很多便于处理医学图像的功能。 注意❗ CSDN博客中，有不少文章在手动实现Dice计算的时候，为了防止除以0发生，加入一个极小值smooth来计算。 这个极小值会两倍加在分子，一倍加入分母。 但是，我在实验中发现即使是再小的极小值，都会对分割分数有极大地影响，分割结果越是差，这个加入了极小值的计算方法得到的dice越高。 （如：pred全为0，但gt不为0的时候，dice不为0且有70左右。） 尚未查证具体影响的原因，但推测是因为这个极小值加在了图像整体上，float的计算无法忽视这种“距离”的接近，造成了错误的结果。 本博客中的手动实现dice在遇到0的时候采用单独判断，不会影响，可以放心使用。但最推荐的还是使用medpy的方法。","link":"/2025/03/30/Dice-score%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"title":"Hexo添加评论功能-gitalk","text":"为Hexo博客添加评论功能，使用Gitalk插件 Gitalk 基于github仓库issue实现的评论插件。配置简单，且支持markdown语法。 注册Gitalk Gitalk的github仓库中点击readme文件里面的“点击这里申请”，就可以进入注册页面。 注册时： Application name：这个评论项目的名称 Homepage URL：博客主页的url Application description：项目描述 Authorization callback url：认证回调地址（不清楚做什么用的，但我写的和Homepage url一个路径） 创建后会出现项目页面。 头像上传似乎可以跳过。重要的是吉住Client ID 和Client secret（这个需要点击一下Generate） 配置到Hexo 本博客所使用的icarus主题自带适配这个评论插件的教程 也有很多其他的评论插件可以选择，但是感觉这个直接用github的issue的方法最合我心意。 直接复制主题官网的配置代码到对应的配置文件_config.icarus.yml就可以 12345678910111213141516comment: type: gitalk client_id: xxxxxxxxxxxxxxxxxxxx client_secret: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx repo: Some-of-Your-GitHub-Repo owner: you_github_name admin: - you_github_name per_page: 20 # 可选填 distraction_free_mode: false # 可选填 pager_direction: last # 可选填 create_issue_manually: false # 可选填 proxy: # 可选填 flip_move_options: # 可选填 enable_hotkey: true # 可选填 language: zh-CN # 可选填 配置过程中参考了CSDN的博客[1] 似乎如果主题不一样，配置这个gitalk的方法也不太一样。 展示issue效果 博客最下面就是评论区，需要登录github账号进行评论。 在博客仓库的issue可以查看对应博客文章所建立的issue的评论区： Hexo博客开发之——Gitalk ↩︎","link":"/2025/03/16/Hexo%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD-gitalk/"},{"title":"Hexo标签CallOut使用方法","text":"简单讲解，就是有颜色有icon的注释，在hexo下该主题中的使用方法。 找到主题官方的介绍了。 实例 info 123{% message color:info size:default icon:&quot;fa-brands fa-github&quot; title:INFO的提示框 %}这是info的颜色。{% endmessage %} INFO的提示框 这是info的颜色。 Success 123{% message color:success icon:&quot;fa-solid fa-check-circle&quot; title:成功 %}操作成功，数据已保存。{% endmessage %} 成功 操作成功，数据已保存。 Warning 123{% message color:warning icon:&quot;fa-solid fa-exclamation-triangle&quot; title:警告 %}请检查输入内容是否完整。{% endmessage %} 警告 请检查输入内容是否完整。 Danger 123{% message color:danger icon:&quot;fa-solid fa-times-circle&quot; title:错误 %}系统发生错误，请联系管理员。{% endmessage %} 错误 系统发生错误，请联系管理员。 Icon可选 从Font Awesome中选择 图标 类名（完整） 用途示例 fa-solid fa-info-circle 信息提示 fa-solid fa-check-circle 操作成功 fa-solid fa-times-circle 操作失败 fa-solid fa-exclamation-triangle 警告提示 fa-solid fa-lightbulb 小贴士 / 灵感 fa-solid fa-star 推荐 / 收藏 fa-solid fa-book 教程 / 文档 fa-solid fa-code 代码 / 技术相关 fa-brands fa-github GitHub 链接 fa-brands fa-google Google 品牌图标 fa-solid fa-terminal 命令行 / 编程 fa-solid fa-pen-nib 写作 / 编辑 fa-solid fa-comment-dots 评论 / 留言 fa-solid fa-link 链接地址 fa-solid fa-envelope 邮箱 / 联系方式","link":"/2025/05/12/Hexo%E6%A0%87%E7%AD%BECallOut%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"},{"title":"IDEA Community 如何创建SpringBoot项目","text":"使用IDEA插件解决社区版无法自动创建Spring项目的问题。 背景介绍 以前电脑上存的IDEA专业版的激活包失效了，搞了两天没效果，只能将就用一下IDEA的社区版，但是又想学习后端技术。 就想着总有人会用社区版来写后端吧，搜一下还真有。 软件版本 需要IDEA社区版必须是2022.1.4之前的版本。 插件安装 在Plugins的marketplace中搜索：Sping Boot Helper。 不要install！ 点击进入这个插件的homepage 点击进入Version中，翻到最下面选择FreeVersions的版本，下载到你的电脑中（自己决定路径）。 下载后无需解压。 4. 在加入插件中，选择从电脑中加入插件： 选择刚才下载好的压缩包即可。 若IDEA提示，则一路选择同意。 效果 出现了创建Spring项目的选项。 现在电脑还没有配置好，暂时不展示项目创建。 参考教程：如何使用社区版IDEA创建Spring项目","link":"/2023/07/14/IDEA-Community-%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BASpringBoot%E9%A1%B9%E7%9B%AE/"},{"title":"Leetcode-Hot100-Hash","text":"Leetcode Hot100: 哈希算法部分解题记录。 代码：Python 后续会慢慢补充C++和Java版本 1. 两数之和 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案，并且你不能使用两次相同的元素。 你可以按任意顺序返回答案。 解题思路： 哈希存储 target-n : idx 每次迭代的值为n 若n的pair不在哈希表中，则将n和id存储到哈希表，一遍后续n的pair出现时可以找到n与其id 123456789class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: hash_s = {} for idx, n in enumerate(nums): if target - n in hash_s.keys(): return [idx, hash_s[target-n]] else: hash_s[n] = idx return [] 49.字母异位词分组 给你一个字符串数组，请你将 字母异位词 组合在一起。可以按任意顺序返回结果列表。 字母异位词 是由重新排列源单词的所有字母得到的一个新单词。 解题思路 把单词字母排序，作为哈希表的key，这个单词本身作为哈希表的value。value是list类型，每次append到list最后 1234567class Solution: def groupAnagrams(self, strs: List[str]) -&gt; List[List[str]]: mp = collections.defaultdict(list) for s in strs: key = &quot;&quot;.join(sorted(s)) mp[key].append(s) return list(mp.values()) collections.defaultdict(list): 什么都没有的时候默认有一个空list sorted(s)：对s排序，s可以是任何可迭代对象注意：sorted() 会返回一个列表，而不是字符串。 “”.join(sorted(s))：转为字符串 1234567891011121314151617181920class Solution {public: vector&lt;vector&lt;string&gt;&gt; groupAnagrams(vector&lt;string&gt;&amp; strs) { unordered_map&lt;string, vector&lt;string&gt;&gt; mp; for(string&amp; s: strs) { string k = s; sort(k.begin(), k.end()); mp[k].emplace_back(s); } vector&lt;vector&lt;string&gt;&gt; result; for(auto it = mp.begin(); it != mp.end(); it++) { result.emplace_back(it-&gt;second); } return result; }}; unordered_map&lt;string, vector&lt;string&gt;&gt;:哈希表，存储key-value键值对，key 为字符串，value 为字符串向量（vector&lt;string&gt;）。 mp.begin() 遍历 unordered_map，it-&gt;first 是键（排序后的字符串），it-&gt;second 是对应的 vector&lt;string&gt;（异位词列表）。 emplace_back() 和 push_back() 主要区别在于对象的构造方式。 主要区别 方法 作用 主要区别 push_back(const T&amp; value) 拷贝（或移动）对象到 vector 末尾 需要先构造对象，再拷贝或移动到 vector emplace_back(args...) 直接在 vector 末尾构造对象 避免额外的拷贝或移动，效率更高 128. 最长连续序列 给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。 请你设计并实现时间复杂度为 O(n) 的算法解决此问题。 解题思路 时间复杂度 O(n) ，说明不能用排序算法。 nums中数字可能重复出现，所以需要用set方法去重 每次迭代判断当前n-1是否存在于set中 若存在，则以n为头，寻找该序列的长度。 下面是官方的C++代码 1234567891011121314151617181920212223242526272829class Solution {public: int longestConsecutive(vector&lt;int&gt;&amp; nums) { unordered_set&lt;int&gt; nums_set; for(const int&amp; n: nums){ nums_set.insert(n); } int result = 0; for(const int&amp; n: nums_set){ if(!nums_set.count(n-1)){ // 对每个元素检查他的-1是否存在于set中 // 若不存在，则这是一个新的序列起点 int currNum = n; int currLen = 1; while(nums_set.count(currNum + 1)){ //是起点，就找以他为头的序列 currNum ++; currLen ++; } result = max(result,currLen); } } return result; }};","link":"/2025/04/03/Leetcode-Hot100-Hash/"},{"title":"Layer Norm和Batch Norm的原理与区别","text":"Batch Normalization 和 Layer Normalization的推导与Pytorch实现。 一、Batch Norm 可以使学习快速进行 —— 增大学习率 不那么依赖初始值 抑制过拟合（降低对Dropout的依赖） 思路：调整各层激活值的分布，使其拥有适当的广度。 流程：以学习时的mini-batch为单位，对每个特征在这个mini-batch的维度上进行正则化，使数据分布的均值为0，方差为1。 Pytorch:BN2d $$ \\begin{align} \\mu_B &amp;\\leftarrow \\frac{1}{m} \\sum_{i=1}^{m} x_i \\ \\sigma_B^2 &amp;\\leftarrow \\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu_B)^2 \\ \\hat{x}_i &amp;\\leftarrow \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\varepsilon}} \\end{align} $$ $B = {x_1,x_2,…,x_m}$ $\\mu_B$ ：均值 $\\sigma_B^2$:方差 BN层会对均值0方差1的数据${\\hat{x}_1,\\hat{x}_2,…,\\hat{x}_m}$ 进行缩放和平移变换： $$ y_i \\leftarrow \\gamma \\hat{x}_i + \\beta $$ $\\gamma$ 和$\\beta$是初始值为1和0的参数，然后会通过学习调整到合适的值。 12345678910111213141516171819202122232425262728293031323334import torchclass BatchNormManual: def __init__(self, num_features, eps=1e-5, momentum=0.1): self.gamma = torch.ones(num_features) self.beta = torch.zeros(num_features) self.eps = eps self.momentum = momentum self.running_mean = torch.zeros(num_features) self.running_var = torch.ones(num_features) def __call__(self, x): if self.training: batch_mean = x.mean(dim=(0, 2, 3), keepdim=True) batch_var = x.var(dim=(0, 2, 3), keepdim=True, unbiased=False) x_norm = (x - batch_mean) / torch.sqrt(batch_var + self.eps) # 更新全局的 running_mean 和 running_var self.running_mean = self.momentum * batch_mean + (1 - self.momentum) * self.running_mean self.running_var = self.momentum * batch_var + (1 - self.momentum) * self.running_var else: x_norm = (x - self.running_mean) / torch.sqrt(self.running_var + self.eps) return self.gamma[None, :, None, None] * x_norm + self.beta[None, :, None, None]# 假设输入为 3D tensor: [batch_size, num_features, height, width]x = torch.randn(16, 32, 64, 64) # batch_size=16, num_features=32# 使用手动实现的 BatchNormbatch_norm_manual = BatchNormManual(32)batch_norm_manual.training = True # 设置为训练模式output = batch_norm_manual(x)print(output.shape) 二、Layer Norm Layer Normalization (Layer Norm) 是一种深度学习中的归一化技术，用于对神经网络层中的神经元激活值进行标准化处理。它的主要作用是通过减小训练过程中不同层之间的激活值变化来加速模型训练，并改善模型的收敛性。 Pytorch:LN 具体定义： Layer Norm 的核心思想是在一个神经网络层的每一个输入样本上，对该层所有神经元的激活值进行归一化处理，而不是像 Batch Normalization (批归一化) 那样在整个 mini-batch 上进行归一化。 粗暴地理解：单个样本的所有通道上进行归一化 计算过程： Layer Norm 对输入样本 $x=(x_1,x_2,…,x_n)$ 进行以下操作： 计算均值：计算输入的均值 $\\mu$ $μ=\\frac{1}{n} \\sum_{i=1}^{n} x_i$ 计算方差：计算输入的方差$\\sigma^2$ $σ2=1n∑i=1n(x_i−μ)2\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2$ 标准化：对输入进行标准化，生成归一化输出 $\\hat{x}_i$ $x^i=xi−μσ2+ϵ\\hat{x}_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$ 其中 $\\epsilon$ 是一个很小的正数，用于防止除零。 缩放和平移：在标准化之后，Layer Norm 会引入两个可学习参数：缩放参数 $\\gamma$ 和平移参数 $\\beta$，用于恢复网络的表达能力： $yi=γx^i+βy_i = \\gamma \\hat{x}_i + \\beta$ 三、与 Batch Norm 的区别 归一化维度不同：Batch Norm 是在 mini-batch 的维度上对不同样本的激活值进行归一化，而 Layer Norm 是在样本的每一层神经元的维度上进行归一化。 应用场景不同：Batch Norm 主要用于 CNNs 等具有批处理特性的网络，而 Layer Norm 更适合于 RNNs（循环神经网络）和 Transformer 等序列模型，因为序列模型的输入长度各异，且批归一化在时间步长上会导致不稳定。 总结：* Layer Norm 的主要优点是： 加速收敛：通过归一化激活值，减少了梯度的波动，帮助网络更快收敛。 稳定训练：在序列模型（如 RNN 或 Transformer）中表现得特别好，因为它不依赖于 batch 维度，且适应于任意长度的输入。 Layer Norm 在 NLP 中的 Transformer 结构中被广泛使用，是自然语言处理任务中的常见技巧。 如果是图像中，假设一个样本shape = (C=3,H=32,W=32),那么LN会将这$3\\times 32\\times 32$作为一个整体计算均值和标准差，再进行归一化。 12345678910111213141516171819202122import torchclass LayerNormManual: def __init__(self, num_features, eps=1e-5): self.gamma = torch.ones(num_features) self.beta = torch.zeros(num_features) self.eps = eps def __call__(self, x): mean = x.mean(dim=-1, keepdim=True) var = x.var(dim=-1, keepdim=True, unbiased=False) x_norm = (x - mean) / torch.sqrt(var + self.eps) return self.gamma * x_norm + self.beta# 假设输入为 2D tensor: [batch_size, num_features]x = torch.randn(16, 128)# 使用手动实现的 LayerNormlayer_norm_manual = LayerNormManual(128)output = layer_norm_manual(x)print(output.shape) 参数含义： dim：指定在张量的哪些维度上进行计算。例如，dim=(0, 2, 3) 就是对 batch、height、width 维度进行计算，通常在 CNN 中用于特征图的归一化。 keepdim：决定是否保留计算后的维度。如果 keepdim=True，则计算出的维度将保持原有的形状，但数值会被压缩为单个值（例如，变为 1）；如果 keepdim=False，则这些维度会被移除。","link":"/2025/05/06/Layer-Norm%E5%92%8CBatch-Norm%E7%9A%84%E5%8E%9F%E7%90%86%E4%B8%8E%E5%8C%BA%E5%88%AB/"},{"title":"Markdonw-it","text":"将hexo默认的markdown解释器替换为hexo-renderer-markdown-it:链接 一、配置方法二、Demo1. markdown-it-abbr：缩写解释2. markdown-it-footnote：脚注3. markdown-it-attrs：给 Markdown 元素添加 HTML 属性4. markdown-it-container：自定义块级容器5. markdown-it-deflist：定义列表6. markdown-it-emoji：表情支持7. markdown-it-ins：插入线（下划线）8. markdown-it-mark：高亮11. markdown-it-anchor：为标题自动添加锚点12. markdown-it-toc-done-right：自动生成目录（TOC）一、配置方法 123npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-markdown-it markdown-it-abbr markdown-it-footnote markdown-it-attrs markdown-it-container markdown-it-deflist markdown-it-emoji markdown-it-ins markdown-it-mark markdown-it-sub markdown-it-sup markdown-it-anchor markdown-it-toc-done-right --save 然后在根目录中的_config.yml中添加或修改： 1234567891011121314151617181920markdown: render: html: true xhtmlOut: false breaks: true linkify: true typographer: true plugins: - markdown-it-abbr - markdown-it-footnote - markdown-it-attrs - markdown-it-container - markdown-it-deflist - markdown-it-emoji - markdown-it-ins - markdown-it-mark - markdown-it-sub - markdown-it-sup - markdown-it-anchor - markdown-it-toc-done-right 有些插件如 anchor 和 toc-done-right 可能需要额外配置参数，具体可以在 node_modules 的文档或 GitHub 仓库中查看。 二、Demo 1. markdown-it-abbr：缩写解释 123*[HTML]: Hyper Text Markup Language这是一段关于 HTML 的介绍。 2. markdown-it-footnote：脚注 添加论文或文档风格的脚注。 123这是一句话[^1]。[^1]: 这里是脚注内容。 这是一句话[1]。 3. markdown-it-attrs：给 Markdown 元素添加 HTML 属性 待补充 4. markdown-it-container：自定义块级容器 12345678::: warning这是一个警告提示框。:::::: tip这是一个提示框。::: ::: warning 这是一个警告提示框。 ::: ::: tip 这是一个提示框。 ::: 5. markdown-it-deflist：定义列表 支持 术语: 定义 形式的 Markdown 列表。 12345术语1: 定义1术语2: 定义2 术语1 定义1 术语2 定义2 6. markdown-it-emoji：表情支持 简写插入emoji 1我很开心 :smile: 我很开心 😄 7. markdown-it-ins：插入线（下划线） 支持 HTML 标签，表示插入的内容。 1++这是插入的文字++ 这是插入的文字 8. markdown-it-mark：高亮 1==高亮内容== 高亮内容 11. markdown-it-anchor：为标题自动添加锚点 生成带链接的标题，方便生成目录或直接跳转。 如你有一个标题： 1# 二、Demo 可以在页面通过下面的方式自动跳转 1[跳到标题](#一、配置方法) 跳到标题 通常配合 toc 插件使用。 12. markdown-it-toc-done-right：自动生成目录（TOC） 配合 markdown-it-anchor，可以生成文章的目录。 1[[toc]] 🡆 会生成包含当前页面各级标题的目录。(本文最开头尝试) 这里是脚注内容。 ↩︎","link":"/2025/04/25/Markdonw-it%E6%8F%92%E4%BB%B6/"},{"title":"Markdown语法基础","text":"现在很多的平台都支持使用markdown语法，包括在写hexo博客的时候，文件也是markdown格式（.md）。还有CSDN、石墨文档、Github的README文件、什么印象笔记有道笔记等等都可以使用这个语言。 可以写书、写幻灯片、写邮件、写日记、写便签、记笔记、写博客，让你专注于敲键盘搞内容，顺便用键盘搞定排版和图片啥的。Markdown就被理所当然地称为了“写作语言”。总之很爽。 我是在使用石墨文档的时候第一次接触到这个语法，第一感觉是：真麻烦啊，跟学写代码一样。现在就被打脸了：什么，不能用markdown做笔记？！我还是换一个软件吧😒。 md看起来麻烦，实际掌握十分简单，因为常用的需要的语法就那几个，熟练之后没什么感觉了，完全不用担心。 本文直接开始介绍基本语法。 先推荐一个学习markdown的超详尽书《了不起的markdown》毕小鹏著。这本书对md语言进行了非常详尽的介绍，甚至根据使用平台推荐了不同的编辑器，如何配置这些编辑器。甚至有博客Hexo的搭建方法。看了本文还想深入学高级技巧的可以看看这本书。 不过就我日常使用而言，我下面介绍的语法应该足以应付90%的文字写作情况了。 我个人喜欢在石墨文档写东西，最棒的就是全平台，手机写了电脑、平板立刻同步，很方便。md的适配做得还不错，要有的都有，而且随时在更新自己的功能，现在甚至有了思维导图的功能（还在优化，值得期待），甚至可以多人编辑文档。免费版够用，一下即用，我很喜欢。 一、写作必备语法1.1 标题1.2 引用1.3 列表（1）有序列表(2)无序列表(3)todo list1.4 代码块1.5 数学公式1.6 表格1.7 脚注1.8 分割线1.9 链接(1)简单链接(2)引用链接(3)页面内跳转(4)带协议的url1.10 字体1.11 嵌入视频1.12 嵌入图片1.13 很高级的功能1.14 正常显示那些符号一、写作必备语法 1.1 标题 一般可以设置六级标题，使用#与空格 + 题目 1234# 一级标题## 二级标题### 三级标题…… 效果： 1.2 引用 使用&gt;+内容 123&gt; 这是引用&gt; &gt; 这是引用的引用&gt; &gt; &gt; 这是三层 效果： 这是引用 这是引用的引用 这是三层 1.3 列表 都是可以相互嵌套的。我懒得写了 （1）有序列表 1231. aaaa2. bbb3. ccc aaaa bbb ccc (2)无序列表 123- aa- bb- cc aa bb cc (3)todo list 1234- [x] 第一件事情- [x] 第二件事情- [ ] 第三件事情- [ ] 第四件事情 [x] 第一件事情 [x] 第二件事情 [ ] 第三件事情 [ ] 第四件事情 1.4 代码块 英文的三个反引号```，在一行内就是段内嵌入，提行则是代码块。头部的单引号最后加入编程语言的名字，可以根据语言高亮。 这个单引号，在键盘数字1的左边，记得是英文的。 C语言 123456int main(){ int a = 14; char c = 'a'; printf(&quot;Hello World!&quot;);} Python 123456789a = 13s = &quot;Hello&quot;print(str(a) + s)def print_num(a): for i in range(a): print(i) return 1.5 数学公式 用四个美元符号包裹内容，是latex的数学公式，在网上可以查到。 看了教程还不知道怎么手写的话，可以先用在线编译器，图像选择需要的公式，再生成latex公式。这里给一个latex在线编译器吧 1\\frac{\\partial f}{\\partial x} = a\\sqrt{a}x $$ \\frac{\\partial f}{\\partial x} = a\\sqrt{a}x $$ 1.6 表格 姓名（左对齐） 年龄（右对齐） 成绩（居中） 周大猛 22 80 周不猛 10 75 1.7 脚注 就像是论文的参考文献，给上标1、2、3，然后可以在文章末尾查到对应的参考文献那样。 首先在正文需要脚注的地方： 1这个内容参考了很多资料[^视频资料] 在文章末尾： 1[^视频资料]:https://www.bilibili.com/video/BV1JA411h7Gw/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=69a3eecb8fce5149ffe1597cbbfc9364 效果： 这个内容参考了很多资料[1] 1.8 分割线 使用三根短横线，就是减号那个短横线。--- 就是这样↑↓ 另外，上面说到的脚注，是会自动生成一个分割线以区分正文和脚注的。 1.9 链接 (1)简单链接 1[百度了你一也不一定知道](baidu.com) 百度了你一也不一定知道 添加提示 1[百度了你一也不一定知道](baidu.com &quot;提示&quot;) 百度了你一也不一定知道 鼠标悬停查看效果 (2)引用链接 文章多次使用同一个链接 123我有一个引擎，叫做[百度][baidu]，可以用[百度][baidu]来搜索很多的东西，我很喜欢[百度][baidu]。[baidu]:https://www.baidu.com/ 我有一个引擎，叫做百度，可以用百度来搜索很多的东西，我很喜欢百度。 (3)页面内跳转 1我要去[表格](###6.表格) 我要去6.表格 似乎不行😰 (4)带协议的url 前面带有http或者https的url，会被自动识别为超链接。 https://www.baidu.com/ 1.10 字体 123456789101112*斜体文本*_斜体文本_**粗体文本**__粗体文本__***粗斜体文本***___粗斜体文本___==文字高亮==:smile:H~2~Ox^2^ 斜体文本 斜体文本 粗体文本 粗体文本 粗斜体文本 粗斜体文本 文字高亮 😄 H2O x2 这里的表情是使用的shortcodes，没搜到官网呢，但是csdn上有人总结了。Emoji 1.11 嵌入视频 如：b站播放器，在分享那里选择嵌入代码，粘贴html格式的播放器代码 1.12 嵌入图片 1![百度首页](图片路径 &quot;This is a picutre&quot;) 1.13 很高级的功能 这些的语法还挺复杂，这写都是用语法写出来的，不是图片。 直接搬运了菜鸟教程高级部分的评论区。 12345678910111213$$\\begin{Bmatrix} a &amp; b \\\\ c &amp; d\\end{Bmatrix}$$$$\\begin{CD} A @&gt;a&gt;&gt; B \\\\@VbVV @AAcA \\\\ C @= D\\end{CD}$$ 转换图一样的东西 $$ \\begin{Bmatrix} a &amp; b \\ c &amp; d \\end{Bmatrix} $$ $$ \\begin{CD} A @&gt;a&gt;&gt; B \\ @VbVV @AAcA \\ C @= D \\end{CD} $$ 流程图一样的东西 1234567三个代码点 mermaidgraph LRA[方形] --&gt;B(圆角) B --&gt; C{条件a} C --&gt;|a=1| D[结果1] C --&gt;|a=2| E[结果2] F[横向流程图] graph LR A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[横向流程图] 1、横向流程图源码格式： graph LR A[方形] -->B(圆角) B --> C{条件a} C -->|a=1| D[结果1] C -->|a=2| E[结果2] F[横向流程图] 2、竖向流程图源码格式： 把meraid放在代码框的代码语言那里 graph TD A[方形] --> B(圆角) B --> C{条件a} C --> |a=1| D[结果1] C --> |a=2| E[结果2] F[竖向流程图] graph TD A[方形] --&gt; B(圆角) B --&gt; C{条件a} C --&gt; |a=1| D[结果1] C --&gt; |a=2| E[结果2] F[竖向流程图] 3、标准流程图源码格式： flow st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st->op->cond cond(yes)->io->e cond(no)->sub1(right)->op st=&gt;start: 开始框 op=&gt;operation: 处理框 cond=&gt;condition: 判断框(是或否?) sub1=&gt;subroutine: 子流程 io=&gt;inputoutput: 输入输出框 e=&gt;end: 结束框 st-&gt;op-&gt;cond cond(yes)-&gt;io-&gt;e cond(no)-&gt;sub1(right)-&gt;op 4、标准流程图源码格式（横向）： flow st=>start: 开始框 op=>operation: 处理框 cond=>condition: 判断框(是或否?) sub1=>subroutine: 子流程 io=>inputoutput: 输入输出框 e=>end: 结束框 st(right)->op(right)->cond cond(yes)->io(bottom)->e cond(no)->sub1(right)->op st=&gt;start: 开始框 op=&gt;operation: 处理框 cond=&gt;condition: 判断框(是或否?) sub1=&gt;subroutine: 子流程 io=&gt;inputoutput: 输入输出框 e=&gt;end: 结束框 st(right)-&gt;op(right)-&gt;cond cond(yes)-&gt;io(bottom)-&gt;e cond(no)-&gt;sub1(right)-&gt;op 5、UML时序图源码样例： sequence 对象A->对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B-->对象A: 我很好(响应) 对象A->对象B: 你真的好吗？ 对象A-&gt;对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B–&gt;对象A: 我很好(响应) 对象A-&gt;对象B: 你真的好吗？ 6、UML时序图源码复杂样例： sequence Title: 标题：复杂使用 对象A->对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B-->对象A: 我很好(响应) 对象B->小三: 你好吗 小三-->>对象A: 对象B找我了 对象A->对象B: 你真的好吗？ Note over 小三,对象B: 我们是朋友 participant C Note right of C: 没人陪我玩 Title: 标题：复杂使用 对象A-&gt;对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B–&gt;对象A: 我很好(响应) 对象B-&gt;小三: 你好吗 小三–&gt;&gt;对象A: 对象B找我了 对象A-&gt;对象B: 你真的好吗？ Note over 小三,对象B: 我们是朋友 participant C Note right of C: 没人陪我玩 7、UML标准时序图样例： %% 时序图例子,-> 直线，-->虚线，->>实线箭头 sequenceDiagram participant 张三 participant 李四 张三->王五: 王五你好吗？ loop 健康检查 王五->王五: 与疾病战斗 end Note right of 王五: 合理 食物 看医生... 李四-->>张三: 很好! 王五->李四: 你怎么样? 李四-->王五: 很好! %% 时序图例子,-&gt; 直线，–&gt;虚线，-&gt;&gt;实线箭头 sequenceDiagram participant 张三 participant 李四 张三-&gt;王五: 王五你好吗？ loop 健康检查 王五-&gt;王五: 与疾病战斗 end Note right of 王五: 合理 食物 看医生… 李四–&gt;&gt;张三: 很好! 王五-&gt;李四: 你怎么样? 李四–&gt;王五: 很好! 1.14 正常显示那些符号 比如星号（被用来加粗了） ，可以使用转义字符反斜杠来正常输出* 1\\* graph TD A[起点] --> B{问题？} B -->|是| C[解决] B -->|否| D[放弃] https://www.bilibili.com/video/BV1JA411h7Gw/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=69a3eecb8fce5149ffe1597cbbfc9364 ↩︎","link":"/2023/04/18/Markdown%E8%AF%AD%E6%B3%95%E5%9F%BA%E7%A1%80/"},{"title":"Precision Recall and F1-score","text":"对机器学习，特别是分类任务中常见的评价指标进行介绍,附带Pytorch代码。 Precision，Recall和F1-score。 基础知识混淆矩阵Precision 精确度RecallF1-score多分类任务中Micro 平均 (Micro-Averaging)Macro 平均 (Macro-Averaging)Weighted 平均 (Weighted-Averaging)基础知识 混淆矩阵 对分类任务（二分类或多分类）而言，混淆矩阵用于分类模型的性能。 假设我们有N个类别，对于样本a建立混淆矩阵，若对A来说正确的类别应该是A，那么对于a来说类别A就是positive类（正类），而其他类对于样本a来说就是negative类（负类）。 若a被正确分到了A，那结果就是True。反之为False。 那么对于该类就有： TP（True Positive）：模型正确预测为正类的样本数 FP（False Positive）：模型错误地将负类预测为正类的样本数（也叫：假阳性） TN（True Negative）：模型正确预测为负类的样本数。 FN（False Ngative）：模型错误地将正类预测为负类的样本数（也叫&quot;假阴性&quot;）。 实际正类 (Positive) 实际负类 (Negative) 预测正类 (Positive) True Positive (TP) False Positive (FP) 预测负类 (Negative) False Negative (FN) True Negative (TN) 在医学任务中，假阳性会对患者造成不必要的负担，重大疾病应尽量减少这种错误。假阴性则比假阳性更为严重，可能耽误患者治疗，导致并且恶化，因此医学任务中通常更加关注降低假阴性的发生率。 python的scikit-learn代码实现，并使用matplotlib可视化结果： 1234567891011121314151617from sklearn.metrics import confusion_matriximport matplotlib.pyplot as pltimport seaborn as sns# 假设有一些预测值和真实标签y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 1] # 实际标签y_pred = [1, 0, 1, 0, 0, 1, 1, 0, 1, 0] # 预测标签# 计算混淆矩阵conf_matrix = confusion_matrix(y_true, y_pre)# 可视化混淆矩阵plt.figure(figsize=(6, 4))sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)plt.xlabel('Predicted labels')plt.ylabel('True labels')plt.title('Confusion Matrix')plt.show() Precision 精确度 $$ Precision = \\frac{TP}{TP+FP} $$ 预测为正类的结果中，预测对了确实就是正类的比例。 123from sklearn.metrics import precision_scoreprecision = precision_score(y_true, y_pred) 如果你的任务非常注重精准预测，比如在医疗诊断中，不允许误报阳性（例如误判健康人有病），那么高 precision 是非常好的。 Recall $$ Recall = \\frac{TP}{TP+FN} $$ 123from sklearn.metrics import recall_scorerecall = recall_score(y_true, y_pred) 预测正确是这个正类的样本量，占整个测试集中正类样本的比例。 如果你的任务更关心全面检测，比如在安检中，要尽可能检测到所有危险物品，哪怕多一些误报也无所谓，那么低 recall 是不理想的，因为你漏掉了一半的危险物品。 F1-score F1-score 是 precision 和 recall 的调和平均数，它综合了两者的表现，能够更好地衡量模型的整体性能，特别是在类别不平衡或者既关心精度又关心召回的情况下。 $$ F1-score = 2\\times \\frac{precision\\times recall}{precision+recall} $$ 12from sklearn.metrics import f1_scoref1 = f1_score(y_true, y_pred) F1-score 的值介于 0 和 1 之间，越接近 1 表示模型在 precision 和 recall 上的表现越好。 如果任务要求既要准确，又不能漏掉太多正类样本，那么 F1-score 可以作为一个有效的综合衡量指标。 多分类任务中 计算Precision、Recall、F1-score有下不同的处理方式，区别在于如何处理各个类别的权重和汇总。 Micro 平均 (Micro-Averaging) 将所有类别TP、FP、FN累加，再计算Precision、Recall、F1。 适合情况：当类别不均衡时，Micro 会给每个样本相同的权重，因此它更关注全局的准确性，而不是个别类别的表现。 Macro 平均 (Macro-Averaging) 先计算每个类别的 Precision、Recall 和 F1-score，然后对所有类别取平均值。 适合情况：当你想要观察模型在所有类别上的均匀表现时，Macro 更合适。它不会考虑类别的样本数量，因此容易受到少数类别表现的影响。 Weighted 平均 (Weighted-Averaging) 对每个类别的 Precision、Recall 和 F1-score 进行加权平均，权重为该类别的样本数量。因此，较大的类别会对结果有更大的影响。 适合情况：当类别分布不均衡且你希望考虑到类别样本数量的影响时，Weighted 平均能更好地反映整体表现。 代码总结： 1234567891011121314151617181920212223242526272829303132333435363738# 导入库from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matriximport numpy as np# 示例数据 (多分类任务)y_true = [0, 1, 2, 2, 1, 0, 1, 2, 0, 0, 1, 1] # 实际标签y_pred = [0, 2, 1, 2, 1, 0, 0, 2, 0, 0, 2, 1] # 预测标签# 计算混淆矩阵conf_matrix = confusion_matrix(y_true, y_pred)print(&quot;Confusion Matrix:\\n&quot;, conf_matrix)# 计算 micro, macro, weighted 平均的 Precision, Recall, F1-scoreprecision_micro = precision_score(y_true, y_pred, average='micro')recall_micro = recall_score(y_true, y_pred, average='micro')f1_micro = f1_score(y_true, y_pred, average='micro')precision_macro = precision_score(y_true, y_pred, average='macro')recall_macro = recall_score(y_true, y_pred, average='macro')f1_macro = f1_score(y_true, y_pred, average='macro')precision_weighted = precision_score(y_true, y_pred, average='weighted')recall_weighted = recall_score(y_true, y_pred, average='weighted')f1_weighted = f1_score(y_true, y_pred, average='weighted')# 打印结果print(f'Precision (Micro): {precision_micro}')print(f'Recall (Micro): {recall_micro}')print(f'F1-Score (Micro): {f1_micro}')print(f'Precision (Macro): {precision_macro}')print(f'Recall (Macro): {recall_macro}')print(f'F1-Score (Macro): {f1_macro}')print(f'Precision (Weighted): {precision_weighted}')print(f'Recall (Weighted): {recall_weighted}')print(f'F1-Score (Weighted): {f1_weighted}') average 参数 在 precision_score()、recall_score() 和 f1_score() 中指定如何计算平均值： micro: 对所有类别的样本进行全局统计。 macro: 计算每个类别的指标后，再取平均。 weighted: 加权平均，权重为每个类别的样本数量。","link":"/2025/03/26/Precision-Recall-and-F1-score/"},{"title":"PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆","text":"根据B站视频整理的笔记，看完基本可以入门Pytorch。 1 环境配置conda技巧pip安装Pytorch检验安装2 编辑器的选择PyCharm配置PyCharm一些技巧Jupyterjupyter 配置3 Python的两大法宝函数4 浅对比PyCharm，python控制台和Jupyter5 PyTorch加载数据提供不同的数据形式5.1 TensorBoard的使用SummaryWriterwriter.add_scalar()效果writer.add_image()writer.add_graph(net,input)5.2 TransformToTensor归一化NormalizationResize()Compose()RandomCrop()随机裁剪总结6 Torchvision的数据集使用7 Dataloader的使用8 网络搭建8.1 Containersnn.Module8.2 卷积层操作与卷积层（1）卷积操作基本原理（2）卷积层8.3 池化特征8.4 非线性激活（1） ReLu（Rectified Linear Unit）(2)Sigmoid8.5 Linear model9 损失函数与反向传播损失函数反向传播10 优化器SGD随机梯度下降11 现有网络模型的使用和修改11.1 VGG简介利用现有的网络，套到自己的数据集上12 网络模型的保存与读取12.1 保存模型与参数12.2 保存模型参数12 完整模型训练套路13 使用GPU训练13.113.214 完整模型验证套路15 Github开源代码1 环境配置 检查显卡： 在命令行底部右键打开任务管理器 也可以查看到GPU的型号 conda #conda 配置一个特定的环境 1conda create -n [env name] python=[python version] 激活环境 1conda activate [env name] 查看创建过的环境 1conda info -e 技巧pip 查看工具包 1pip list 安装Pytorch 检查电脑的GPU是否支持pytorch 打开命令行，输入nvidia-smi 查看驱动版本 Driver Version 需要保持版本号大于coda的需求的 如果不满足，可以去英伟达的官网更新驱动 选好后，输入conda命令即可 检验安装 123&gt;&gt;python&gt;&gt;import torch # 没有报错就是安装成功&gt;&gt;torch.cuda.is_available() # 检查是否可以使用GPU torch.cuda.is_available()返回False 进行以下步骤进行排除： 进入https://www.nvidia.cn/geforce/technologies/cuda/supported-gpus/ 检查是否支持cuda 检查驱动版本nvidia-smi 不够高就去更新 在正常使用一段时间后，安装各种包突然又返回False或者各种冲突。 解决方案： 卸载torch全部重来：conda remove pytorch torchvision 2 编辑器的选择 PyCharm 配置PyCharm 一些技巧 python的console，可以检查一些变量或者一些命令、方法，简便直观。 Jupyter jupyter 配置 在安装cuda的时候，这个默认安装在base的环境中。但是base中没有安装torch。可以再在base里面安装一次torch，但是还是在之前安装的torch环境中安装一下jupyter吧~ 安装一个个包 nb_conda 是一个用于 Jupyter Notebook 的插件，它可以让你在 Notebook 中使用 Conda 环境。通过运行 conda install nb_conda，你可以将这个插件安装到你的 Conda 环境中，然后在 Jupyter Notebook 中使用。这样你就可以方便地在 Notebook 中管理和切换不同的 Conda 环境了。 1conda install nb_conda 在命令行中切换到对应的项目目录 最开始在C盘 创建项目 3 Python的两大法宝函数 dir(): 打开，看见 help(): 说明书 4 浅对比PyCharm，python控制台和Jupyter rerun的区别 PyCharm会全部重新运行。 控制台：从错误的地方开始运行 notebook：任意行为块，每一块重运行。 5 PyTorch加载数据 Dataset Dataaloader Dataset: 获取的数据是混乱的，但是可以进行编号 可以获取数据和label 如何获取每一个数据和label 总共有多少个数据 Dataloader： 对Dataset进行打包 提供不同的数据形式 #os的用法 os.path.join(dir1,dir2)：可以根据系统自动拼接地址 1234567891011121314151617181920212223242526272829303132333435363738''' @Project ：pythonProject @File ：read_data.py @IDE ：PyCharm @Author ：周大猛 @Date ：2024/05/02 23:50 ''' from torch.utils.data import Dataset from PIL import Image import os class MyDataset(Dataset): def __init__(self, root_dir, label_dir): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(root_dir, label_dir) self.img_path = os.listdir(self.path) def __getitem__(self, index): &quot;&quot;&quot; 读取每一个图片 :param index: :return: &quot;&quot;&quot; img_name = self.img_path[index] img_item_path = os.path.join(self.path, img_name) img = Image.open(img_item_path) label = self.label_dir return img, label def __len__(self): &quot;&quot;&quot;获得数据集的长度&quot;&quot;&quot; return len(self.img_path) if __name__ == '__main__': root_dir = &quot;dataset/train&quot; ants_label_dir = &quot;ants&quot; bees_label_dir = &quot;bees&quot; ants_dataset = MyDataset(root_dir,ants_label_dir) bees_dataset = MyDataset(root_dir,bees_label_dir) # 拼接数据集，按顺序拼接。 train_loader = ants_dataset + bees_dataset 5.1 TensorBoard的使用 对图像进行变化：统一尺寸等 对图像进行展示 SummaryWriter 原文部分介绍： 12345678910111213141516171819202122class SummaryWriter: &quot;&quot;&quot;Writes entries directly to event files in the log_dir to be consumed by TensorBoard. The `SummaryWriter` class provides a high-level API to create an event file in a given directory and add summaries and events to it. The class updates the file contents asynchronously. This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training. &quot;&quot;&quot; def __init__( self, log_dir=None, comment=&quot;&quot;, purge_step=None, max_queue=10, flush_secs=120, filename_suffix=&quot;&quot;, ): &quot;&quot;&quot;Create a `SummaryWriter` that will write out events and summaries to the event file. Args: log_dir (str): Save directory location. Default is runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run. Use hierarchical folder structure to compare between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc. for each new experiment to compare across them. comment (str): Comment log_dir suffix appended to the default ``log_dir``. If ``log_dir`` is assigned, this argument has no effect. purge_step (int): When logging crashes at step :math:`T+X` and restarts at step :math:`T`, any events whose global_step larger or equal to :math:`T` will be purged and hidden from TensorBoard. Note that crashed and resumed experiments should have the same ``log_dir``. max_queue (int): Size of the queue for pending events and summaries before one of the 'add' calls forces a flush to disk. Default is ten items. flush_secs (int): How often, in seconds, to flush the pending events and summaries to disk. Default is every two minutes. filename_suffix (str): Suffix added to all event filenames in the log_dir directory. More details on filename construction in tensorboard.summary.writer.event_file_writer.EventFileWriter. Examples:: from torch.utils.tensorboard import SummaryWriter # create a summary writer with automatically generated folder name. writer = SummaryWriter() # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ # create a summary writer using the specified folder name. writer = SummaryWriter(&quot;my_experiment&quot;) # folder location: my_experiment # create a summary writer with comment appended. writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;) # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ &quot;&quot;&quot; 三种用法 默认保存到一个路径 writer = SummaryWriter() # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/ 自定义保存到的文件夹 writer = SummaryWriter(&quot;my_experiment&quot;) # folder location: my_experiment 可以对文件名加入一些comments writer = SummaryWriter(comment=&quot;LR_0.1_BATCH_16&quot;) # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/ writer.add_scalar() 效果 打开方法： 指定路径 --logdir 指定端口 --port 1tensorboard --logdir=[logs] --port=[6007] 但是运行多次之后可能显示图像会出bug，可以选择删掉之前的log writer.add_image() 读取图片 识别类型： numpy tensor string 但是我们常用的PIL的Image是JpegImageFile类型，所以不符合，需要转换，或者直接用别的方法读取图片，如OpenCV 在使用numpy读取图片的时候，每个通道的顺序可能与add_image默认的顺序不一样，可以ctrl进入add_image查看手册，手动设定通道顺序 1234567891011from PIL import Image from torch.utils.tensorboard import SummaryWriter import numpy as np writer = SummaryWriter('logs') image_path = &quot;dataset/train/ants/5650366_e22b7e1065.jpg&quot; iamge_PIL = Image.open(image_path) img_array = np.array(iamge_PIL) # 但是这里形状不对,np读出来之后，通道在最后：(375, 500, 3) print(img_array.shape) writer.add_image(&quot;image&quot;, img_array, 1,dataformats='HWC') # 根据官方文档里面，指定type的顺序 修改add_image的第二个参数step，可以在进度条处出现拉出新的图 writer.add_graph(net,input) 可以查看网络的结构 1234# 查看网络结构的方法 writer = SummaryWriter(&quot;./logs&quot;) writer.add_graph(net,input) writer.close() 5.2 Transform 指的是：transforms.py文件，里面又很多的“工具”： toTensor resize 拿特定格式的图片，丢进去，得到需要的图片结果。 引入的方式 1from torchvision import transforms ToTensor 12tensor_trans = transforms.ToTensor() # 实例化这个工具 tensor_img = tensor_trans(image) # 使用这个工具，输出一个结果 为什么需要Tensor这个数据类型？ tensor包含了神经网络中使用的一些参数 另一种读取方式：nparray 使用OpenCV. 导入opencv的方法： 1pip install opencv-python 归一化Normalization output[channel] = (input[channel] - mean[channel]) / std[channel] 均值和标准差都是0.5 1234trans_norm = transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5]) img_norm = trans_norm(img_tensor) writer.add_image('Normal_img', img_norm) Resize() 12345678910# Resize print(img.size) trans_resize = transforms.Resize((512,512)) # img PIL --&gt; resize --&gt; img_resize PIL img_resize = trans_resize(img) # img_resize PIL --》to_tensor --&gt; img_resize tensor img_resize = trans_totensor(img_resize) writer.add_image('Resize_img', img_resize,0) print(img_resize) writer.close() Compose() 123456# Compose - resize -2 trans_resize_2 = transforms.Resize(64) # 这里列表的顺序需要保证前一个的输出类型是后一个的输入类型。 trans_compose = transforms.Compose([trans_resize_2,trans_totensor,]) img_resize_2 = trans_compose(img) RandomCrop()随机裁剪 按照设定的尺寸随机在图片内裁剪规定尺寸大小的图片。 123456# RandomCrop trans_random = transforms.RandomCrop(64) trans_compose_2 = transforms.Compose([trans_random,trans_totensor,]) for i in range(10): img_crop = trans_compose_2(img) writer.add_image('Random_img', img_crop,i) 总结 关注输入和输出的类型 多看官方文档 看初始化的参数 输出类型可以print查看，或者debug 6 Torchvision的数据集使用 官网链接 如果下载速度太慢，可以将下载路径粘贴到迅雷中进行下载。 数据集的参数设置很多都是相同的，教程中以CIFAR10为例： 设置数据集路径 设置训练or测试集合 transform要做的操作 download：是否要网络下载（准备好了就False，没准备就True） 1234import torchvision train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True) test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True) 可以在transform参数，设置对数据集的操作，也是可以打包送进去的。 123456789101112131415161718192021import torchvision from torch.utils.tensorboard import SummaryWriter dataset_transform = torchvision.transforms.Compose([ torchvision.transforms.ToTensor(), torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=dataset_transform) test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=dataset_transform) print(test_set[0]) writer = SummaryWriter(log_dir='./logs') for i in range(10): img, label = test_set[i] writer.add_image('test_img', img, i) 7 Dataloader的使用 将数据加载到神经网络中。 如何取数据可以由Dataloader进行设置。 常用参数设置： batch_size shuffle:洗牌 num_workers:多少个进行进行加载（但是win上有时候出现错误） drop_last:分组除不尽的时是否舍去一些数据。 DataLoader会分别把数据集的数据和label，按照batch_size的大小，进行打包。 如果设置了shuffle，一个epoch打乱一次。 12345678910111213141516171819202122232425262728import torchvision from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter from torchvision import transforms data_transforms = transforms.Compose([transforms.ToTensor(),]) test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=data_transforms) test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=True,num_workers=0, drop_last=False) img, label = test_data[0] print(img.shape) print(label) writer = SummaryWriter('./logs') # 多次让dataloader取数据，shuffle就会在每次的epoch影响取值，True会打乱数据集 for epoch in range(10): step = 0 for data in test_loader: imgs, labels = data # 注意这里用的是images writer.add_images('Epoch:{}'.format(epoch), imgs,step) step += 1 writer.close() 8 网络搭建 https://pytorch.org/docs/stable/nn.html 8.1 Containers 最常用的模块，提供神经网络的最基本的框架 nn.Module 》 https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module 123456789101112131415import torch.nn as nnimport torch.nn.functional as Fclass Model(nn.Module): def __init__(self): # 调用父类的初始化 super().__init__() self.conv1 = nn.Conv2d(1, 20, 5) self.conv2 = nn.Conv2d(20, 20, 5) def forward(self, x): # 神经网络的前向传播 x = F.relu(self.conv1(x)) return F.relu(self.conv2(x)) # 这个demo进行了两次非线性卷积 8.2 卷积层操作与卷积层 （1）卷积操作 基本原理 在全连接（Affine）层中存在忽略了数据形状，它直接将整个图片拉成一维数据输入到了神经网络。 因此导致了，形状中含有的空间信息被忽略。 卷积层的优点就是，可以保持形状的不变，或许能更好的理解图片的形状信息。 卷积层的输入输出被称为特征图，。 !PyTorch深度学习快速入门教程（绝对通俗易懂！）小土堆/Pasted image 20240513161728.png]] 主要用torch.nn 的部分，对functional封装更好 卷积核：（类似图像处理的滤波器）一个小矩阵，对图像矩阵进行一坨一坨的计算 stride = 滤波器每次移动的举例 会影响最后得到的卷积输出的形状 越大，输出的矩阵越小（？） 官网参数介绍：conv2d input – input tensor of shape (minibatch,in_channels,𝑖𝐻,𝑖𝑊)(minibatch,in_channels,iH,iW) 要设置batch的带线啊哦 weight – filters of shape (out_channels,in_channelsgroups,𝑘𝐻,𝑘𝑊)(out_channels,groupsin_channels​,kH,kW) bias – optional bias tensor of shape (out_channels)(out_channels). Default: None stride – the stride of the convolving kernel. Can be a single number or a tuple (sH, sW). Default: 1 padding （在图像左右两边对图像进行填充）– implicit paddings on both sides of the input. Can be a string {‘valid’, ‘same’}, single number or a tuple (padH, padW). Default: 0 padding='valid' is the same as no padding. padding='same' pads the input so the output has the same shape as the input. However, this mode doesn’t support any stride values other than 1. 填充的内容默认为0 也会对输出结构造成影响 1234567891011121314151617181920212223242526272829303132333435363738import torch import torch.nn.functional as F input = torch.tensor([[1,2,0,3,1], [0,1,2,3,1], [1,2,1,0,0], [5,2,3,1,1], [2,1,0,1,1]]) kernel = torch.tensor([[1,2,1], [0,1,0], [2,1,0]]) # print(input) # print(kernel) # # print(input.shape) # print(kernel.shape) # 转换成nn.conv需要的形状 input = torch.reshape(input,(1,1,5,5)) # shape:batch，通道，长，宽 kernel = torch.reshape(kernel,(1,1,3,3)) # print(input) # print(kernel) # # print(input.shape) # print(kernel.shape) output1 = F.conv2d(input,kernel,stride=1) print(output1) output2 = F.conv2d(input,kernel,stride=2) print(output2) output3 = F.conv2d(input,kernel,stride=1,padding=1) print(output3) （2）卷积层 https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d Parameters in_channels (int) – Number of channels in the input image out_channels (int) – Number of channels produced by the convolution 》 有几个卷积核，就会导致输出有几个维度，也就是channels kernel_size (int or tuple) – Size of the convolving kernel 个 stride (int or tuple, optional) – Stride of the convolution. Default: 1 padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0 padding_mode (str, optional) – 'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros' dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1 groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1 bias (bool, optional) – If True, adds a learnable bias to the output. Default: True 根据这两个公式，推到论文中的padding和stride #padding计算 #stride计算 如果卷积前后尺寸不变，padding = （卷积核尺寸-1）/2 #批处理 批处理：这里将多个图像打包成一个batch，让图像变成了四维数据（batch_num, channel,height,width)进行计算，加快运算效率 8.3 池化 #池化 特征 无需学习参数（与卷积的不同） 只是从目标区域获得最大值或者平均值 通道数不发生变化 计算按照通道独立进行 对微笑的数据位置变化具有鲁棒性（健壮） Parameters kernel_size (Union[int, Tuple[int, int]__]) – the size of the window to take a max over stride (Union[int, Tuple[int, int]__]) – the stride of the window. Default value is kernel_size padding (Union[int, Tuple[int, int]__]) – Implicit negative infinity padding to be added on both sides dilation (Union[int, Tuple[int, int]__]) – a parameter that controls the stride of elements in the window return_indices (bool) – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later ceil_mode (bool) – when True, will use ceil instead of floor to compute the output shape 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torch import torch.nn as nn import torch.nn.functional as F import torchvision.datasets as datasets from torch.utils.data import DataLoader from torch.utils.tensorboard import SummaryWriter from torchvision import transforms dataset = datasets.CIFAR10(root='./data', train=False, download=True,transform=transforms.ToTensor()) dataloader = DataLoader(dataset, batch_size=64, shuffle=True) # input = torch.tensor([ # [1,2,0,3,1], # [0,1,2,3,1], # [1,2,1,0,0], # [5,2,3,1,1], # [2,1,0,1,1] # ],dtype=torch.float32) # # input = torch.reshape(input,(-1,1,5,5)) # print(input.shape) class T(nn.Module): def __init__(self): super(T, self).__init__() self.pool = nn.MaxPool2d(3,ceil_mode=False) def forward(self, x): output = self.pool(x) return output tt = T() # result = tt(input) # print(result.shape) # print(result) writer = SummaryWriter('./maxpool_logs') step = 0 for data in dataloader: imgs, labels = data writer.add_image('Input', imgs,step,dataformats='NCHW') outputs = tt(imgs) &quot;&quot;&quot; 最大池化不会改变形状， 所以不用像卷积那样还要将得到的图片进行reshape &quot;&quot;&quot; writer.add_image(&quot;Output&quot;, outputs,step,dataformats='NCHW') step += 1 writer.close() 8.4 非线性激活 （1） ReLu（Rectified Linear Unit） $$ y = \\begin{cases} x &amp; \\text{if } x &gt; 0 \\ 0 &amp; \\text{if } x \\leq 0 \\end{cases} \\tag{1} $$ $$ \\frac{\\partial y}{\\partial x} = \\begin{cases} 1 &amp; \\text{if } x &gt; 0 \\ 0 &amp; \\text{if } x \\leq 0 \\end{cases} \\tag{2} $$ 这个inplace（替换）： True：直接把变换后的值，放到input的那个变量里面 False：把变换后的值，需要一个新的变量来接收 12345678910111213141516import torch i = torch.tensor([[-1, 2, 3], [4, -5, 6], [7, 8, -9]]) i = torch.reshape(i,(-1,1,3,3)) class DemoModule(torch.nn.Module): def __init__(self): super(DemoModule, self).__init__() self.relu1 = torch.nn.ReLU(inplace=False) def forward(self, x): return self.relu1(x) mod = DemoModule() output = mod(i) print(output) (2)Sigmoid $$ \\text{Sigmoid}(x) = \\sigma(x) = \\frac{1}{1 + \\exp(-x)} $$ 8.5 Linear model nn.Linear Parameters in_features (int) – size of each input sample out_features (int) – size of each output sample（下一层要输出的个数） bias (bool) – If set to False, the layer will not learn an additive bias. Default: True 就是全连接层。把数据摊平之后，进行kx+bias的变化，再输出到指定数目的节点去。 #torchflatten torch.flatten：把数据展开到一维 9 损失函数与反向传播 损失函数 神经网络通过学习损失函数（Loss Function）寻找最优权重参数。 计算实际输出和目标之间的差距 为更新输出提供依据（反向传播），grad（梯度） #损失函数 常用的损失函数： 均方误差（mean squared erro） 交叉熵误差 只计算对应正确解标签的输出的自然对数。 1234567891011121314import torch.nn as nn import torch loss = nn.L1Loss() input = torch.randn(3, 5, requires_grad=True) target = torch.randn(3, 5) print(input) print(target) output = loss(input, target) print(output) loss_mes = nn.MSELoss() result_mse = loss_mes(input, target) print(result_mse) 反向传播 10 优化器 #优化器 用backward进行反向传播，计算出每一个节点的参数，有了参数梯度之后，就可以选择合适的优化器进行优化，对loss达到一个降低的目的。 https://pytorch.org/docs/stable/optim.html SGD随机梯度下降 #SGD 初始化 1234optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)optimizer = optim.Adam([var1, var2], lr=0.0001) 初始化参数 1234optim.SGD([ {'params': model.base.parameters(), 'lr': 1e-2}, {'params': model.classifier.parameters()} ], lr=1e-3, momentum=0.9) Pytorch中的SGD 这里的代码使用了PyTorch中的optim.SGD优化器来训练模型。这个优化器采用了随机梯度下降（Stochastic Gradient Descent，SGD）的方法，并添加了动量（momentum）来加速训练过程。 具体解释如下： optim.SGD: 这是一个优化器，它实现了随机梯度下降算法。SGD是一种常用的优化算法，用于调整模型参数以最小化损失函数。 params: 这里指定了要优化的参数集合。代码中将模型的参数分成了两组，分别设置了不同的学习率（learning rate，lr）。 {'params': model.base.parameters(), 'lr': 1e-2}：这表示模型的基础层（base）参数使用一个学习率为0.01（1e-2）的值进行优化。 {'params': model.classifier.parameters()}：这表示模型的分类器（classifier）层的参数。没有指定单独的学习率，因此这些参数将使用外层的学习率1e-3。 lr: 学习率是一个超参数，控制每次参数更新的步长。这里有两个学习率： 1e-2（0.01）用于基础层参数。 1e-3（0.001）用于分类器层参数（外层指定的学习率）。 momentum: 动量是一个超参数，用于加速SGD在相关方向上的收敛，并抑制震荡。动量项在参数更新时引入了历史梯度的累积，使得优化过程更稳定。这里设置的动量值为0.9。 综上所述，这段代码的含义是使用带有动量的随机梯度下降算法来优化模型的参数，其中基础层参数的学习率设置为0.01，分类器层参数的学习率设置为0.001。动量参数设置为0.9。这样可以在训练过程中更好地控制模型的更新步长和收敛速度。 使用demo 1234567891011for input, target in dataset:# - 在进行反向传播和梯度计算之前，先将优化器中的所有参数的梯度缓存清零。 optimizer.zero_grad() output = model(input) # 计算模型输出 `output` 和目标标签 `target` 之间的损失（误差） loss = loss_fn(output, target) # 进行反向传播，计算损失相对于模型参数的梯度 loss.backward() # - 使用计算得到的梯度，按照优化算法更新模型的参数。 # - 这里的 `optimizer` 是前面定义的优化器（如 `optim.SGD`），它根据参数的梯度和学习率来调整参数的值，使损失函数逐渐减小，从而优化模型。 optimizer.step() 训练部分代码： 123456789101112131415161718192021loss = nn.CrossEntropyLoss()# 交叉熵 net = NeuralNetwork() optimizer = torch.optim.SGD(net.parameters(), lr=0.01) for epoch in range(20): running_loss = 0.0 # 每次开始前，把loss设置为0 for data in test_loader: &quot;&quot;&quot; 这个for相当于只对data进行了一轮的学习， 通常需要好几轮的学习，才能有所改善。 所以需要外层的epoch &quot;&quot;&quot; imgs, labels = data outputs = net(imgs) result_loss = loss(outputs, labels) optimizer.zero_grad() # 对之前的记录清零 result_loss.backward() optimizer.step() # print(result_loss) running_loss = running_loss + result_loss # 整体误差总和 print(&quot;epoch:{}, loss:{}&quot;.format(epoch, running_loss)) 11 现有网络模型的使用和修改 在pytorch的官方文档中，torchvision或torchtext等文件中，包含了相关领域中的经典网络模型。 11.1 VGG简介 常用的版本： vgg16 pretrained：在ImageNet中与训练(这个数据集130G+，而且不能torchvision直接下载，需要自己寻找资源) progress：下载进度条 vgg19 初始化的时候，True会下载参数（很大） VGG16常被用来作为迁移学习等模型的前半部分，用于提取一些图像的特殊特征，在后续的模型中对这些特征进行一个进一步的学习。 利用现有的网络，套到自己的数据集上 VGG使用了ImageNet进行训练，输出的最后一层与ImageNet的类别数量相同，都是1000，如何把这个现有的模型改成我需要的模型？ 之前的数据集为例 方法一：把最后一个输出层后追加一层input为10000，output为10的线性层。 1vgg16_false.add_module('add_linear', nn.Linear(1000, 10)) 如果要加到上面那个括号（classifier）里面： 1vgg16_false.classifier.add_module('add_linear', nn.Linear(1000, 10)) 方法二：直接修改模型最后一层 12 网络模型的保存与读取 12.1 保存模型与参数 这种方法可以保存模型的结构和模型的参数。 缺点： 若模型较大，则保存文件也会很大 Save model 12vgg16 = torchvision.models.vgg16(pretrained=False)torch.save(vgg16, 'vgg16_method.pth') 第一个参数：模型 第二个参数：保存的文件名，通常用.pth作为文件类型 load model 12# Load Method 1: model_1 = torch.load(&quot;vgg16_method.pth&quot;) 这个方式是存在陷阱的： 如果是自己定义了一个模型，对这个模型进行保存。则加载的时候会产生报错。 为了解决这个问题，则需要自己重新定义一次自定义的模型结构： 比如我在model文件创建并保存了数据，在load文件里面需要重新定义（无需new）一次这个模型，才能继续正常使用 12.2 保存模型参数 这个方法将模型的参数作为字典进行保存，所以加载的时候，要用字典加载的方式，放入新的模型中。 官方推荐的方法 Save model 1torch.save(vgg16.state_dict(), 'vgg16_state_dict.pth') load model 12345678910# Specify a pathPATH = &quot;state_dict_model.pt&quot;# Savetorch.save(net.state_dict(), PATH)# Loadmodel = Net()model.load_state_dict(torch.load(PATH))model.eval() [!NOTE] 两种方式一定要对应。 ※不知道为什么，在下个章节代码实现的时候，我无法用方法二的步骤正常创建模型 12 完整模型训练套路 以CIFAR10 为例 步骤说明： 初始化训练集、测试集，转换为Dataloader 初始化自己的模型 定义损失函数和优化器 定义训练次数 epoch 进行迭代epoch 从dataloader中每次取数据进行训练 得到output 得到output与labels的loss 优化器置零 反传播 优化器优化参数 在测试集中检测——取消grad 在流程中合适的地方对结果进行输出或者保存。 定义模型 123456789101112131415161718192021222324252627282930313233343536''' @Project ：pythonProject @File ：MyModel.py @IDE ：PyCharm @Author ：周大猛 @Date ：2024/05/20 15:21 ''' import torch from torch import nn class TongModel(nn.Module): def __init__(self): super(TongModel, self).__init__() self.model = nn.Sequential( nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2), nn.MaxPool2d(2), nn.Conv2d(32, 32, 5, 1, 2), nn.MaxPool2d(2), nn.Conv2d(32, 64, 5, 1, 2), nn.MaxPool2d(2), nn.Flatten(), nn.Linear(64 * 4 * 4, 64), nn.Linear(64, 10), ) def forward(self, x): x = self.model(x) return x if __name__ == '__main__': # 测试网络模型的正确性 model = TongModel() # 64个图片，3个通道，尺寸32*32 input = torch.ones((64, 3, 32, 32)) output = model(input) #torch.Size([64, 10]) 64个图片，10个数据表示每个类别的可能性 print(output.shape) [!NOTE] 通常在专门的模型py文件中对模型进行定义，方便管理，修改、检查模型每层的正确性。 数据集 123456789101112131415# 准备训练数据 train_data = torchvision.datasets.CIFAR10(root='./data', train=True, download=True,transform=transforms.ToTensor()) # 准备测试数据 test_data = torchvision.datasets.CIFAR10(root='./data', train=False, download=True,transform=transforms.ToTensor()) # 查看数据集信息 train_data_size = len(train_data) test_data_size = len(test_data) print(&quot;Train data size: {}&quot;.format(train_data_size) ) print(&quot;Test data size: %d&quot; % test_data_size) # 使用dataloader加载数据集 train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True) test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True) [!NOTE] 下载好数据集后，用dataloader进行封装。 导入神经网络，初始化模型 模型初始化 损失函数 优化器 学习率 训练进度 测试进度 迭代次数 保存数据位置 1234567891011121314151617from MyModel import * # 创建网络模型 model = TongModel() # 损失函数和优化器 loss_fn = nn.CrossEntropyLoss() learning_rate = 1e-2 optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4) # 设置训练参数 total_train_step = 0 # 记录训练次数 total_test_step = 0 # 记录测试次数 epoch = 100 # 训练的轮数 # 使用tensorboard记录数据 writer = SummaryWriter('./logs_train') 训练与测试 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647for i in range(epoch): print('Epoch {}/{}'.format(i, epoch)) # 训练开始 model.train() # 当模型有dropout等特殊层的时候，起作用 for data in train_dataloader: imgs, labels = data output = model(imgs) # 计算输出和真实的损失 loss = loss_fn(output, labels) # 优化器优化模型 optimizer.zero_grad() # 准备优化，先梯度清零 loss.backward() #得到每个参数的梯度 optimizer.step() # 对参数进行优化 total_train_step += 1 if total_train_step % 100 == 0: print('Total train step:{}, Loss:{}' .format(total_train_step, loss.item())) writer.add_scalar('Loss/train', loss.item(), total_train_step) &quot;&quot;&quot; 每次训练一轮之后，需要知道本次训练之后在测试集上模型表现是否有进步。 在第一层的for中，对此进行检测。 这里不需要对模型进行调优。 需要知道在整个数据集上的loss &quot;&quot;&quot; model.eval() # 与train（）一个情况 total_test_loss = 0.0 # 计算ACC total_accuracy = 0 with torch.no_grad(): # 没有梯度了 # 测试开始 for data in test_dataloader: imgs, labels = data output = model(imgs) loss = loss_fn(output, labels) total_test_step += 1 total_test_loss += loss.item() accuracy = (output.argmax(dim=1)==labels).sum() total_accuracy += accuracy.item() print('Total test Loss:{}' .format(total_test_loss)) writer.add_scalar('Loss/test', total_test_loss, total_test_step) print(&quot;整体测试集的正确率:{}&quot;.format(total_accuracy/test_data_size)) writer.add_scalar('Accuracy/test', total_accuracy/test_data_size, total_test_step) torch.save(model.state_dict(), './modelData/model_{}.pt'.format(i)) writer.close() 13 使用GPU训练 有两种使用GPU的方式 13.1 .cuda 网络模型 123# 创建网络模型 model = TongModel() model = model.cuda() 数据的输入和标注 在训练和测试的部分 123imgs, labels = data imgs = imgs.cuda() labels = labels.cuda() 损失函数 123# 损失函数和优化器 loss_fn = nn.CrossEntropyLoss() loss_fn = loss_fn.cuda() 良好的写法： 13.2 方法二：.to(device) 定义训练的设备12 # 定义训练的设备 device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') 然后之前该国的地方都改成 1model.to(device) 14 完整模型验证套路 给训练好的模型提供输入。 与测试部分类似，大概流程如下： 准备数据（自己准备的，非数据集的测试部分或训练部分） 导入模型 模型初始化 模型参数初始化 在测试模式下，输入准备的数据 获得结果，并进行对比 15 Github开源代码 只说说注意事项： 仔细阅读README 参数部分可以在代码中找到描述","link":"/2024/05/22/PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%EF%BC%88%E7%BB%9D%E5%AF%B9%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%EF%BC%89%E5%B0%8F%E5%9C%9F%E5%A0%86/"},{"title":"Python项目与别人分享","text":"当有一个项目，想打包给自己的朋友的时候，需要做什么呢？ 献给小白的你我他。 必做的事情 通常一个项目，你配置python、numpy啥的版本不一样，也会影响到在别人电脑上的运行情况。 为了避免这个问题，我们可以生成一个项目的依赖文件，帮助别人在导入我们的项目后快捷的搭建好需要的环境。 打开终端 进入项目根目录（其实在pycharm下面的终端直接就可以，或者在文件夹中右键打开终端） 输入命令pip freeze &gt; requirements.txt 就可以了！ 你的朋友只需要： 1pip install -r requirements.txt 就可以在他们的环境中安装和你一样的依赖了。 打包 方法1：传到github上 看我的另一个博客git与github使用方法.md 方法2：压缩文件 使用win的命令： tar -cvzf project.tar.gz --exclude='./data/aa' --exclude='./data/bb' . 运行地方与生成依赖的目录一样 其中--exclude=是该项目下不打包的文件。 但是上面的方法导出的requirements实在是太复杂了，想要只是当前项目的依赖环境，建议使用下面的方法： 下载： 1pip install pipreqs 然后在项目根目录： 1pipreqs . --force 然后会生成一个简略版的requirements.txt，按照上面所说的执行 1pip install -r requirements.txt 就可以在新的环境中下载对应的包了。","link":"/2023/11/18/Python%E9%A1%B9%E7%9B%AE%E4%B8%8E%E5%88%AB%E4%BA%BA%E5%88%86%E4%BA%AB/"},{"title":"Pytorch自动混合精度AMP","text":"AMP（Automatic Mixed Precision）自动混合精度。 可以帮助减少深度学习网络的运行时间和内存占用。本文将简单介绍使用方法。 一、简介 在Pytorch中，官方提供了一种混合精度的方法，通过将torch.float32和torch.float16混合使用的方式，减少训练时网络的运行时间和内存占用。 在类似线性层和卷积操作中，使用float16会快很多。而其他如规约操作，则float32更合适。 在使用Pytorch构建深度学习训练脚本时，AMP通常将 torch.autocast 和 torch.cuda.amp.GradScaler 一起使用。 注意： AMP 不适用于 CPU 训练，必须使用 CUDA。 二、使用方法 在训练网络的train.py代码中，只需要简单地增加混合精度的相关代码即可。 下面整理官方示例代码。 未加入AMP时的默认训练操作 123456789101112net = make_model(in_size, out_size, num_layers)opt = torch.optim.SGD(net.parameters(), lr=0.001)start_timer()for epoch in range(epochs): for input, target in zip(data, targets): output = net(input) loss = loss_fn(output, target) loss.backward() opt.step() opt.zero_grad() # set_to_none=True here can modestly improve performanceend_timer_and_print(&quot;Default precision:&quot;) 添加AMP torch.autocast充当上下文管理器，运行脚本以混合精度运行。 如BN或者softmax这类对精度要求较高的方法，不适合使用float16，autocast会自动进行管理，无需用户感受。 torch.cuda.amp.GradScaler方便地执行梯度缩放的步骤。 有助于防止在混合精度训练时出现小幅度梯度冲至零（下溢）。 1234567891011121314151617use_amp = Truenet = make_model(in_size, out_size, num_layers)opt = torch.optim.SGD(net.parameters(), lr=0.001)scaler = torch.amp.GradScaler(&quot;cuda&quot; ,enabled=use_amp)start_timer()for epoch in range(epochs): for input, target in zip(data, targets): with torch.autocast(device_type=device, dtype=torch.float16, enabled=use_amp): output = net(input) loss = loss_fn(output, target) scaler.scale(loss).backward() scaler.step(opt) scaler.update() opt.zero_grad() # set_to_none=True here can modestly improve performanceend_timer_and_print(&quot;Mixed precision:&quot;) 验证时 也可以使用AMP，只需要包裹一层autocast，但不需要使用GradScaler（因为已经不需要饭传播了。 1234model.eval()with torch.no_grad(): with torch.cuda.amp.autocast(): output = model(input)","link":"/2025/04/28/Pytorch%E8%87%AA%E5%8A%A8%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6AMP/"},{"title":"Python读取.nii文件","text":"MRI影像处理用。 1 什么是.nii文件 .nii 文件是 Neuroimaging Informatics Technology Initiative (NIfTI) 格式的文件，是一种用于存储医学影像数据的文件格式，特别常用于功能性磁共振成像 (fMRI)、结构性 MRI、DTI（扩散张量成像）等领域。 NIfTI 文件可以存储三维或四维的医学图像数据，并且还包含有关这些图像的元数据信息，如图像的尺寸、分辨率、坐标系等。这种格式广泛应用于神经科学和医学图像处理领域，主要用于分析和处理脑部扫描数据。 .nii 文件有两种形式： 单文件格式 (.nii): 图像数据和元数据都存储在一个文件中。 双文件格式 (.hdr/.img): 图像数据和元数据分别存储在两个文件中，.hdr 文件包含头部信息，.img 文件包含图像数据。 2 Python 读取.nii 文件 需要在Jupyter notebook中运行。3D 图可以交互查看不同层的效果 2.1 准备环境 在conda环境下 1conda install nibabel numpy matplotlib ipywidgets nibabel: 用于处理医学成像文件（如 NIfTI）的库。 numpy: 提供高效数组操作和数学计算的基础库。 matplotlib: 用于创建静态、动态和交互式图形的绘图库。 ipywidgets: 在 Jupyter 笔记本中创建交互式控件的库。 2.2 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142import nibabel as nibimport numpy as npimport matplotlib.pyplot as pltfrom ipywidgets import interact, IntSlider, Layout def load_and_visualize_nifti(filename: str): # Load the NIfTI file nifti_img = nib.load(filename) data = nifti_img.get_fdata() # Remove the singleton dimension if it exists data = np.squeeze(data) # Check data dimensions if data.ndim == 3: # Function to display a slice of the 3D data def display_slice(slice_index): plt.figure(figsize=(8, 8)) plt.imshow(data[:, :, slice_index], cmap='gray') plt.title(f'Slice {slice_index}') plt.axis('off') plt.show() # Create an interactive widget interact(display_slice, slice_index=IntSlider( min=0, max=data.shape[2]-1, step=1, value=data.shape[2]//2, layout=Layout(width='80%') )) elif data.ndim == 2: # If the data is already 2D, just display it plt.figure(figsize=(8, 8)) plt.imshow(data, cmap='gray') plt.title('2D Image') plt.axis('off') plt.show() else: print(&quot;Unsupported data dimension&quot;) # Example usageload_and_visualize_nifti(img_path) 2.3 实现效果","link":"/2024/08/13/Python%E8%AF%BB%E5%8F%96-nii%E6%96%87%E4%BB%B6/"},{"title":"Win11 安装 wsl2","text":"在Windows11下安装WSL2操作记录 官方教程 大佬们总是说Linux好用极了，也看到实验室的同学在用，十分不解。 但是这个东西更多的是给我不可磨灭的难用印象……（感谢本科的教学） 唯一怀念的就是里面的Fuck命令了。 实在好奇，到底有多好用…… 本文基本上是官方文档的搬运。 什么是wsl2 WSL（Windows Subsystem for Linux）就是Windows系统下的Linux子系统，让你可以无需下载单独的虚拟机或者刷机，就可以在计算机上运行Linex环境。 可以使用各种Linux发行版：Ubuntu、Debian、Kail等 很多博客都没有提到wsl占用空间问题，我的操作尝试观察： 默认下载C盘，包括Ubuntu 整体需要6G左右（移动Ubuntu到别的盘之后） 简介 安装默认版本的Linux，使用虚拟化技术在轻量级实用程序虚拟机中运行Linux内核。 Linux在WSL2托管VM中作为独立容器运行。 WSL2比WSL1具有更高的文件系统性能，增加了完整的系统调用兼容性。 安装过程 通过PowerShell 以管理员身份打开PowerShell, 输入下面的命令安装默认版本的Linux和Ubuntu： 1wsl --install 该命令会执行： 启用可选择的wsl和Virtual Machine Platform组件 下载安装最新Linux内核 将WSL2设为默认值 下载安装Ubuntu Linux发行版本（可能需要重新启动） 设置Linux用户名和密码 官方 使用开始面板打开下载好的发行版（默认为Ubuntu），需要未Linux发行版创建用户名 和密码。 此用户名与密码与Win用户名无关，只与该发行版有关 输入密码时，屏幕不会有任何光标，这是“blind typing”。 此账户就是Linux的管理员，能运行sudo（super user do）命令 WLS运行的每个Linex都有自己的Linux用户账户和密码，每次添加分发、重新安装或者重置的时候，都需要配置Linux用户账户 官方提供修改和忘记密码的时候如何操作 更新和升级 官方建议定期升级和更新软件包，对于Ubuntu和Debian： 12sudo apt update &amp;&amp; sudo apt upgrade Win不会自动更新Linux，因为Linux用户喜欢自己更新（不愧是大佬们） 添加其他分配 略 设置Win终端 将Ubuntu转移到别的盘 网上的解决方法：https://superuser.com/questions/1550622/move-wsl2-file-system-to-another-drive/1618643#1618643 到处Ubuntu 1mkdir D:\\backup 将 Ubuntu 发行版导出到备份文件夹中的 tar 文件： 1wsl --export Ubuntu D:\\backup\\ubuntu.tar 取消注册现有分配： 从驱动器 C 中删除现有的 Ubuntu 发行版： 1wsl --unregister Ubuntu 将 Ubuntu 导入驱动器 D： 在驱动器 D 上为 WSL 安装创建新文件夹 1mkdir D:\\wsl 将 Ubuntu 发行版从备份 tar 文件导入到驱动器 D 上的新文件夹： 1wsl --import Ubuntu D:\\wsl\\ D:\\backup\\ubuntu.tar 设置默认用户 默认情况下，Ubuntu 可以使用 root 用户。要恢复到以前的用户，请执行以下步骤 打开 Ubuntu 应用程序文件夹。您可以通过运行以下命令来执行此作： 1cd %userprofile%\\AppData\\Local\\Microsoft\\WindowsApps 通过运行以下命令并将 替换为所需的用户名来设置默认用户 1ubuntu config --default-user &lt;username&gt; 但是我’wsl --install’之后点开Ubuntu并没有进行设置密码和用户，我直接搬运了Ubuntu的位置（或许是成功了）。然后默认管理员名称为root，密码未设置。 管理员root没有初始密码的时候可以此时添加密码：passwd root 其他配置 zsh and oh-my-zsh 下载Powerline字体集合 1sudo apt-get install fonts-powerline 安装zsh 123sudo apt updatesudo apt install git zsh -y 安装oh-my-zsh 1sh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot; 让命令行和命令更简洁明了。 安装参考[1] 添加用户并分配sudo权限 root : 1sudo adduser [username] 会要求输入密码 分配sudo权限 添加用户到 sudo 组（可选）： 如果你希望新用户有 sudo 权限（可以执行管理员权限的命令），可以将其添加到 sudo 组： 1sudo usermod -aG sudo [newuser] 切换用户 1su - newuser 回到root用户 1su - 需要输入root用户的密码 和win的关联 windows系统的所有文件都在/mnt/下面： 1cd /mnt/ 就可以看到个各个盘了。 且在win的文件管理系统下面可以看到Linux文件的目录。 https://blog.csdn.net/x777777x/article/details/141092913?fromshare=blogdetail&amp;sharetype=blogdetail&amp;sharerId=141092913&amp;sharerefer=PC&amp;sharesource=weixin_51636581&amp;sharefrom=from_link ↩︎","link":"/2025/03/22/Win11-%E5%AE%89%E8%A3%85-wsl2/"},{"title":"git与github使用方法","text":"学习一下如何使用git与github对代码进行管理 git与github的关系Git提交回退（重置）到某个版本状态分支branchGithub补充技巧一些规范总结git与github的关系 Git是一种分布式版本控制系统，由Linus Torvalds于2005年创建。它用于跟踪文件和代码的变化，使团队成员能够在不干扰其他人工作的情况下协同开发项目。每个开发人员都可以在自己的本地计算机上创建、修改和提交代码的版本，然后将这些变更推送到共享的代码仓库。 而GitHub是一个基于Git的代码托管平台。它提供了一个在线的服务，使开发者能够轻松地将他们的Git代码仓库托管在云端。GitHub除了支持基本的代码托管功能外，还提供了诸如协作、问题追踪、代码审核、持续集成等功能，使得团队合作更加高效。 简而言之，Git是一种版本控制系统，而GitHub是基于Git的代码托管平台，为开发者提供了更便捷的协作和管理代码的方式。 描述来自chatGPT。 写在前面： 如果想要在本地创建了git仓库并且和github连接到一起，先用git init在本地初始化，再在github上创建自己对应的仓库。按照本文一步一步走即可。 Git 使用步骤以及介绍。 提交 设置个人信息 这里设置全局的 不是每次创建一个git仓库都需要设置。设置一次就可以了。 12git config --global user.name&quot;你的昵称&quot;git config --global user.email&quot;你的邮箱&quot; 这是为了记录提交者的信息，不需要一定和github的用户名与电子邮件对应。但是设置成一样的github才能将这次提交记录为自己的贡献。 初始化 在你的对应文件夹或者文件所在位置进行初始化。 git init 在当前目录下初始化你的git管理，会生成一个隐藏.git文件夹，文件夹中保存每个git版本记录和变化。 此时文件还没有被记录 存到暂存区 git add [文件名] 将所有的更改文件添加到暂存区，存储到暂存区后，commit会把暂存区的东西提交到仓库。 若是该文件路径下的所有文件，则为git add . 项目中不推荐使用全部add的方法，首先会导致提交记录不清晰，其次是可能导入临时的数据、改变子目录结构等。 提交到仓库 git commit 但推荐下面一条命令 将暂存的修改提交为一个固定的版本。 提交后会打开一个vim的终端编辑器，这里要求写你的提交说明。 vim操作详见vim的教程。 简单说明： 进入这个步骤的时候还不能直接输入，按下（二选一）： a ： 光标之后开始插入文本 i ： 光标之前开始插入文本 编辑完成后，按下esc推出拜年祭模式。 然后输入:wq保存文件并退出。 本次提交就算完成了。 简化版（推荐）： git commit -m &quot;提交的说明&quot; 跳过vim编辑。 提交信息的书写规范，遵守Converntional Commits规范，按照&lt;type&gt;(&lt;scope&gt;):&lt;description&gt; &lt;type&gt; 提交类型，常见的有：fix修复了bug，feat新增功能，docs文档更新，style代码格式化，refactor重构代码，test测试代码。 &lt;scope&gt;提交的影响范围 &lt;description&gt;对本次提交的简单描述 vscode也自带了这些git的提交流程，可以研究一下。 查看提交信息 git log - 本次提交的随机aid - 提交的人 - Date：日期 - 提交的说明 回退（重置）到某个版本状态 git log查看版本信息 找到对应的随机编号 git rest --hard 版本编号 reset会把回到的这个版本之后的版本也清空(撤销这个版本之后的所有记录)。 如果不想清空记录，我还不会。 分支branch 用于团队开发。 创建分支 git branch &lt;branchName&gt; 进入分支 git checkout 合并分支 在主分支进行操作： git merge &lt;合进来的分支名称&gt; Github 首先，自己创建一个repository在github上面。 进入这个页面，下面的是叫你如何在自己的代码处创建git仓库和与github该仓库链接的简单教程。 git branch -M main 是一个 Git 命令，用于将当前分支重命名为 main。github现在默认创建的主要分支叫做main了，以前叫master。 这里建议设置一下。因为之前下载git的你可能不记得自己设置的git默认主分支是master还是main了。 当前项目的git分支可以通过git branch -a查看。 其实就是上图中，仓库初始化后的网站上提示的操作。 git remote add origin XXXXX ：添加一个远程仓库地址。 git push -u origin main 推送上传到这个github的远程仓库。 可能需要输入github的邮箱和密码 补充技巧 在一次推送项目的时候忘记加入.gitignore 了，导致我的png数据集全部被列入了推送list，好多个G，严重影响了我的上传速度。这里介绍：在git push 后如何终止并重新上传。 首先使用 ctrl+C 停止当前的进度。 从Git中移除所有文件：git rm -r --cached . 重新添加所有文件git add . 提交git commit -m &quot;Add .gitignore&quot; 推送到Githubgit push -u origin main 如果还不得行，就删除项目文件夹中.git ，然后重新开始init…… 遇事不决删历史。 一些规范 在commit代码的时候，备注应该怎么写呢？ Git commit的注解规范可以参考以下内容： 每个提交应该有一个简短的标题，不超过50个字符，使用大写字母和祈使语气。 标题和正文之间应该有一个空行。 正文应该简要描述本次提交的目的和具体做了什么操作。 如果需要，可以在正文中添加备注或说明。 提交信息应该尽可能准确地描述本次提交内容。 可以使用以下标识来说明提交的类别： feat：新功能（feature）。 fix：修复bug。 docs：文档（documentation）。 style：格式（不影响代码运行的变动）。 refactor：重构（即不是新增功能，也不是修改bug的代码变动）。 perf：优化相关，比如提升性能、体验。 test：增加测试。 chore：构建过程或辅助工具的变动。 revert：回滚到上一个版本。 merge：代码合并。 sync：同步主线或分支的Bug。 总结 操作完毕之后，每次提交代码的流程都是： 123git add [filename]git commit -m &quot;NXXXXX&quot;git push 就行了 下面这个视频教学非常好，参考这个来的。 B站的教学视频:git、github 保姆级教程入门 有一个闯关形式的git练习，很有创意，但是我没学会：git游戏","link":"/2023/07/23/git%E4%B8%8Egithub%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new postRun serverGenerate static filesDeploy to remote sitesQuick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment","link":"/2023/06/26/hello-world/"},{"title":"hexo博客加密","text":"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 Hey, password is required here.","link":"/2024/02/12/hexo%E5%8D%9A%E5%AE%A2%E5%8A%A0%E5%AF%86/"},{"title":"wsl与vscode","text":"使用插件将wsl与vscode连接到一起，就可以在vscode上，借助wsl运行代码。 之前的文章讲解了怎么配置miniconda环境，链接上vscode之后直接运行就行。 本文将介绍怎么简单配置编译C与C++的环境音。 我也不知道意义是什么，只是觉得很好玩的样子…… 我是win11下的wsl2，用的是ubuntu。 一、配置C和C++语言编译环境 1. 进入wsl 2.安装编译器 1sudo apt install build-essential build-essential：一个虚拟软件包，包含了编译 C/C++ 程序所需的基本工具 gcc：C语言编译器 g++：C++编译器 make 一些必要的头文件 二、 VS Code中进入wsl 安装插件 WSL Remote Development vscode终端可以进入wsl 一些教程会推荐下载 Remote WSL,但是我在插件商城没有看到名称一模一样的了。这个Development的里面似乎包含了？无所谓反正下载了。 还有一个方法：直接从终端启动VScode GPT 说的，没学会，以后再说。 从远程进入wsl 在vscode工具栏有一一个远程资源管理器： 如果顺利的话，这里的下面会有一个wsl目标，这里的Ubuntu下应该尚且是空的。鼠标悬空放置，点击箭头链接到wsl。 进入之后点击打开文件夹应该会自动让用户从/root/下选择wsl中想打开的文件。 但是我们通常在自己的用户下的项目中写代码和运行文件。 删掉root，从home中找到自己用户的文件夹工作。 三、编写代码 此时已经连接上你的wsl，并且是在wsl中的项目路径下。 但是用户应该还默认的是root，记得切换到自己的用户下。 12sudo [username] 因为是用的vscode，在这里新建代码文件就和在win中差不多。只是文件都会在wsl中了。控制台也会自动进入wsl（ubuntu）。 试着写一个cpp代码吧！ 新建cpp文件，写入代码 使用g++编译代码 1g++ hellowls.cpp -o hello g++:使用GNU C++编译器 XX.cpp：C++源代码 -o [XXXX]:输出为名称为XXXX的可执行文件，如果不指定名称，则会默认生成一个名为a.out的文件。 执行编译后的文件 1./hello 小插曲 最开始创建这个测试项目的时候用的事root用户，结果一直编译失败。 把当前目录的所有权改回当前用户 1sudo chown -R $(whoami):$(whoami) . chown：更改文件/目录的所有者 -R：递归处理目录下的所有文件 $(whoami)：当前用户名 确认目录权限 1ls -ld . 若显示了当前用户的名称，即修改权限成功。","link":"/2025/05/11/wls%E4%B8%8Evscode/"},{"title":"wsl2配置开发环境-1","text":"给我的wsl2安装上git、miniconda和node.js。 顺手安装了htop来查看和管理进程。 以及一些华而略实的玩意儿（火车、代码雨、ubuntu启动图标） 一、配置前须知 即使是这个wsl在自己的电脑上，只有自己一个用户，还是避免直接使用root用户下工作。 为什么不建议长期在 root 用户下干活？ root没有权限限制，如果发生误操作可能毁掉整个系统环境。 隔离性差：很多工具、环境变量会写在 /root/ 下，和正常用户隔离不清晰，后期迁移或调试麻烦。 和真实 Linux 使用习惯不一：如果你以后真的用服务器或部署到云端，长期用 root 会埋下很多坏习惯（甚至无法登陆 SSH） 所以最好还是创建一个用户，允许sudo权限比较好。 添加新的user并允许sudo权限 添加用户 1sudo adduser [username] 允许sudo权限 1sudo usermod -aG sudo [username] sudo:表示使用 超级用户权限 来执行后面的命令。只有具有管理员权限的用户才能修改用户组等系统设置。 usermod:是 Linux 中的一个命令，用于修改已有用户的账户信息。 -a:是 append（追加）的意思，用于将用户添加到一个附加的组中时保持其原有的组不变。必须与 -G 联合使用。 -G:指定用户要加入的附加组（supplementary group），后面跟的是组名。 sudo:是组名，表示将用户添加到 sudo 组中。这个组的成员可以使用 sudo 命令获取临时管理员权限 进入该user环境 12su [username]cd /home/[username] 二、安装git 12sudo apt updatesudo apt install git -y 检查安装是否成功： 1git --version 输出版本号则安装成功。 三、安装Miniconda Miniconda 是 Conda 的轻量版本，适合 WSL 使用。 需要使用wget : 是 Linux 中一个非常常用的命令行工具，用于从网络上 下载文件。它支持 HTTP、HTTPS 和 FTP 协议，并且可以运行在后台、断点续传、递归下载整个网站等 wget [选项] [URL] Step 1:安装wget 1sudo apt install wget -y Step 2:下载Miniconda安装脚本 1wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh Step 3:运行安装脚本 1bash Miniconda3-latest-Linux-x86_64.sh Step 4:配置环境变量 安装完 Miniconda 后，脚本会提示是否修改 .bashrc 文件。如果选择了 yes，则自动配置环境变量。如果没有自动配置，你可以手动添加。 我安装的时候没有看到提示…… 打开.bashrc文件 1nano ~/.bashrc nano： 是 Linux 系统中常用的一个 轻量级终端文本编辑器，用于直接在命令行界面中编辑文本文件，比如配置文件、脚本、日志等。 在文件末尾添加以下内容（如果没有的话）： 12# Miniconda3export PATH=&quot;$HOME/miniconda3/bin:$PATH&quot; ctrl + X + Y 保存并退出 更新.bashrc 1source ~/.bashrc 验证安装 1conda --version 清理安装包 1rm Miniconda3-latest-Linux-x86_64.sh 四、安装Node.js 装 curl 可以先装一下 1sudo apt install curl -y 是一个非常强大的 命令行工具，用于向服务器发送请求并获取数据，支持多种协议，比如 HTTP、HTTPS、FTP、SMTP 等。 安装Node.js版本管理器 1curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash 生效并测试 12source ~/.bashrcnvm --version 安装Node.js 1nvm install --lts 验证安装 12node -vnpm -v 五、htop安装 彩色进程管理器，比top好用 1sudo apt install htop top效果 htop效果 只是因为wsl是调取的win的内存，和真实的内存情况不是很一致，需要注意。 检查方法 ‌1.界面区域划分‌ ‌上左区‌：显示CPU、物理内存和交换分区的实时使用情况（不同颜色代表不同类型的负载，如绿色为用户进程、红色为内核进程等）。 ‌‌上右区‌：任务数量、平均负载（1/5/15分钟值）和系统运行时间（Uptime）。 ‌‌进程区域‌：列表显示所有进程的详细信息（如PID、用户、CPU%、内存%等）。 ‌‌操作提示区‌：底部显示F1-F10功能键的快捷功能。 ‌2. 关键功能键操作‌ ‌‌F3/F4‌：搜索或过滤进程（F3定位进程，F4筛选显示）。 ‌‌F5‌：切换进程树视图，显示父子进程关系。 ‌‌F6‌：按列排序（如CPU%、内存%、PID等）。 ‌‌F7/F8‌：调整选中进程的优先级（nice值）。 ‌‌F9‌：终止选中进程。 ‌‌空格键‌：标记多进程批量操作。 ‌3. 其他交互命令‌ ‌‌方向键‌：导航进程列表。 ‌‌M/P/T‌：快速按内存/CPU/时间排序。 ‌‌U键‌：取消所有标记的进程。 ‌‌s键‌：查看进程的系统调用。 六、其他有趣的玩意儿 neofetch 是一个用来在终端里“炫机”的系统信息展示工具，适合展示系统的版本、内核、桌面环境等内容。 安装： 1sudo apt install neofetch 使用： 1neofetch 可选：追加到自启动时显示 1echo &quot;neofetch&quot; &gt;&gt; ~/.zshrc echo &quot;neofetch&quot;：输出字符串 “neofetch” &gt;&gt;:把输出追加写入到文件中（不会覆盖原内容） ~/.zshrc:当前用户的 zsh 配置文件（登录时会自动执行） sl: 打错ls时出现火车字符动画 12sudo apt install slsl cmatrix：黑客帝国文字雨 12sudo apt install cmatrixcmatrix","link":"/2025/05/09/wsl2%E9%85%8D%E7%BD%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83-1/"},{"title":"1.为什么我要写这个博客","text":"其实这个想法存在了很久了，只是恰好拖到了现在，又恰好虽然现在忙得不行，但是就是不想干正事，这个Hexo又恰好不是很难搭建，就着手干了起来。 有想法，没计划，全靠热情和冲动，以及一点点逃避现实的懒惰和恐惧。 先说说起因吧……那其实是我还没有转到计算机的时候。我喜欢的一个油管主，他除了分享自己的学习方法、学习日常以及做推广（笑）之外，他还会分享自己读的书以及自己的读后感。一个很厉害很厉害的油管主，我很佩服他，他的学习那么忙，还剪视频、做博客，我一直都很好奇，到底是什么在推动他如此持久地记录自己的生活，分享自己的经验？For money？哈哈哈，这个理由肯定不会没有。 但是除此之外，我更多的是感受到他分享的时候，面对镜头的那种喜悦。 总而言之，他对我的影响很大。 恰好又是那段时间，我正苦于英语的学习，抱着学习要从兴趣出发 的想法，要不找一本有意思的全英文的不是那么难的书来读一读吧？然后又是恰好这个时候，这个对我影响颇深的油管主，分享了一本书 《Show Your Work》。不难、纯英文，我到现在都没读完（笑）。他说，就是这本书让他开始了自己的油管主之旅。恰好也是这个时间段吧，我开始了我的计算机之旅。 进入了这个领域之后，真的会接触到很多博客或者类似的个人发表自己的“作品”的平台：CSDN、知乎或者是公众号…… 这中最多的title就是：“手把手教你如何安装XXX”（笑）。 很感谢各位大佬的倾囊相授，很感激的同时，让我多少有些痛苦的就是：“啊，这个界面怎么来的？”，“这是啥？”，“我配对了吗？我怎么知道？”，“噫？怎么【中国脏话】报错了？怎么搞的？”。多少会有这种地方，大佬们就不会细致地讲解了，默认大家都会（悲）。 那个时期的我，还只是个office都用不熟练，下载只会默认C盘，最厉害的就是右键新建文档……的我需要在一两个月内，下载好编译器、配置好环境、学会C语言、补修大一计算机的课程、插班并跟上大二计算机的课程。第一步搞坏了我的电脑、第二步搞坏了我的脑子、第三步搞坏了我的身心健康。与此同时我还要继续我的英语学习（悲）。 稀里糊涂、慌里慌张地终于正式成为了计算机专业的大冤种的一员，学会了不要什么事情都问学长学姐和同学，要先自己百度一下，CSDN搜一搜，再不行谷歌里面StackOverFlow里面一字一句翻译的自学的“初有成效”阶段，我终于有时间看看大大推荐的书，那些为我们写下那么多“手把手带你XXX”教程的大佬们，是不是和书里面有同样的想法呢？ 我当时看了些什么不记得了，记得的就只有，为什么要展示你的工作？（基本都由我的记忆瞎编了一点，不代表书中的意思） 因为可以看到你自己的成长足迹 因为大佬们已经忘记了自己是小白的日子，忘记了什么都不会的人该怎么起步，所以他们分享的东西是不完整的，需要有人来补充，而你恰好是初学者。 学习如何把自己的工作用最简单的话展示给别人，是提升自己能力的一种。 更集中在“过程”而不是“成果” 好像还提到可以变现？没事反正我变不了现，所以无所畏了。其中，第二条对我的影响很深：我就是小白啊，我就是什么都不会，但是我还是配置好了环境，学会了写代码！ 大概就是这个这段时间，开始出现：我也想搞一个东西，展示我的学习生活。这种幼稚的想法。 但是我不知道自己可以写什么，在哪个平台发布，从零到有往往是最难的一步。 知乎吧，人均年入百万，各个出口成章、引经据典，我这个文盲还是别凑热闹了。CSDN吧…… 自从我看到一个网友比我年级小，问了个我看不懂的问题，还被大家清一色地嘲笑：“都这个年龄了这都不会！”，让我敬而远之。或者自己搞个公众号？但是我自己关注的好几个公众号都没做下去，下来了解了一下公众号的搭建流程，嫌麻烦就放弃了。搜索“如何搭建自己的公众号10次，放弃10次（笑）。 某一天，又是写不动代码的时候，看到了有的人的网站怎么既不是CSDN，又不是什么知乎，又看起来不像是什么平台上的文章，简陋的只有作者介绍和干货？哦~原来还有个叫个人博客的东西。 搭不来，百度“怎么搭建个人博客？”，推荐Hexo，XXX，XXX。这是我第一次接触到Hexo。如何搭建Hexo？oh天哪，要github、要node.js，不会，遂放弃。 再有一次在翻找各种大大写的网文，有个大大分享了个WordPress中的文章。想着顺着摸摸看能不能找到更多好文，居然是个博客！而且是大家都可以用它搭建自己的博客！ 百度：怎么搭建WordPress？ 你需要巴拉巴啦啦……需要自己的服务器…… 好的放弃了。 是的，我就是这么容易放弃的人。所以好多想法没有实现，好多事情没能做完，好多地方没有去，好多东西没有吃。就是这么一事无成、平平无奇。 但就算是这样的我，也最终还是搭建了这个博客。 或许是因为，看到身边有同学在做着同样的事情，在CSDN发布自己的学习笔记，B站发布自己的复习视频，讲解所学的课程，自己当个小老师，或许是每一次出现Erro的时候看到大佬们的文章“临帖涕零”的时候，一次又一次想起那个书里面说的那些话，让我不知道多少次又开始想：我也要整一个！ 还在化工的时候，我就在试着用思维导图做一些复习整理，这个习惯在现在愈演愈烈，我的石墨文档、幕布或者我青涩愚蠢粗暴的代码里面穿插详尽的批注（我为我的批注感到骄傲，我到现在都看得懂我的代码）。这些年，虽然不曾发表，但是积累了不少的东西，感谢这些便利的平台让我养成了写东西的习惯。 单纯因为这些平台的笔记方便手机复习。期末的时候我习惯性的会把我认为好的东西分享给我的朋友们，包括这些我自己整理的笔记。 就是有一次吧，忘了啥时候了，我朋友突然说：你搞了这么多，都可以发个CSDN的博客了。 我的心突然咯噔一下，我这粗糙的东西，也配？但是转念一想，也不是不行，毕竟CSDN很有好了……不提问的话…… 但是就是这么一句话，让第一次分享了自己的东西。 幕布社区里面或许搜得到，一个粗糙的计算机网络的笔记。 题目和内容都不是很好，没几个人看，但是还是很开心，哪怕一个节点对那个陌生人有用，也是有价值的。没价值也没事，他们知道了这种做笔记的方法很失败也行（我没有难过，嘤） 而且每次打开那个两万字的笔记，就不由得感叹，这门课真他喵的折磨。 然后，就是现在这个博客了。B站？哦，我不会剪视频，好麻烦，没设备，没时间（剪视频可比写文章麻烦多了！），而且那里现在也变得可怕起来了。（我曾录视频给室友讲过一个算法，反馈还不错，但是吧……实在是太麻烦了！！！要保证看得清、听得清、废话不多、有条理巴拉巴拉，目前的我，太难） 呵呵，回到现在。这几年，没学会Node.js(会过，忘了)，但是电脑里却配置了这个东西，不会用github，但是有了自己的账号、下载了Git，创建了demo仓库n个（这几天学会删掉了），当时看不懂的各种npm，在哪里输入这个命令，现在也知道了。 那还差什么？ 就差npm install了呀！ Android Studio都安装过的我，区区一个Hexo怕神马！（嗷呜！） 反正毕设卡住了，修考复习也一筹莫展，这个Hexo也不是很难的样子，整一个！ 然后我一个下午、又一个晚上、又一个下午，都搭在了这上面。写博客真是上头。 好吧，主要还是智商不够，这么简单的博客搭了这么久（悲）。但是确实很简单，真的，或许是我只差Hexo了，反正，比那个WordPress简单（吧）。 之前不是没想过纯手工做一个博客，我可是计算机学生，那样更自由，更有成就感，但是我真的到大四了还不会搞开发……我就是这么废物呵呵，之前做网站开发是小组作业，我一直分的是搞后端的，前端就知道个皮毛，现在后端技术也忘光光了（大悲）。这种技术流程，自己做笔记就不是很方便了，所以也没记下来，但是学习资料都保存了，后面需要的时候，再整理成笔记吧。 但是最主要的原因还是：搭建成本太高。需要自学前后端开发（很麻烦的！）、设计UI（这是很困难的！）、搭建（很麻烦的！）、部署上线（还要花钱！），一套下来不知道几个月要投入进去（纯搞这个），对我而言，做这个事情还没有重要到值得我做到这一步。 但是Hexo+Github很好的解决了这些问题。 现成的框架，不想改主题，直接写就行，简单的几行命令轻松搭建好自己的博客。Github直接让你的主页可以被人看到，要被搜到还需要别的方法，不过与我而言目前已经足够。写博客也很简单，本地保存、md格式，使用多年石墨文档的我很快可以上手。 嗯，真好~ 最后，感谢你看到了这里。我不善言辞，更不善写作，看我废话了这么久，辛苦辛苦。 这一切开始也就这么回事儿，看起来是一次冲动，但是追本溯源好像又不是那么回事儿。我不知道这个博客我会坚持多久，但是它存在的这一刻起就是我“记录”的全部意义。这篇文章只是为了稍微记录一下我的初心，它是怎么出现的，现在我把自己的小小的初心放在这里，也不知道能不能茁壮成长，总之先长吧。 如果看了到这个文章的你，也有了一个：“要不我也整一个？”的想法，我的博客里面，Hexo下面有个可以参考的搭建教程，我参考过的博客链接也在里面，希望对你有帮助，也是我的愿望之一。 谢谢。","link":"/2023/04/12/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E8%A6%81%E5%86%99%E8%BF%99%E4%B8%AA%E5%8D%9A%E5%AE%A2/"},{"title":"交叉熵的数学推导与代码实现","text":"简单介绍交叉熵（Cross Entropy） 基本概念 什么是交叉熵？ 交叉熵（Cross Entropy）是深度学习中最常见的损失函数之一，尤其在分类任务中被广泛应用。它结合了信息论与概率论的思想，能有效衡量模型输出分布与真实分布之间的差异。 信息熵 信息熵：衡量分布不确定性的指标。 $$ H(X) = -\\sum^{n}_{i=1}p(x_i)log(p(x_i)) $$ X: 事件 $p(x_i)$:发生第i种现象的可能性。 系统越是有序，信息熵越低，反之越混乱值越高。 交叉熵（Cross Entropy） 交叉熵：用于衡量两个概率分布之间的距离： $$ H(p,q) = -\\sum^{n}_{i=1}p(x_i)log(q(x_i)) $$ $p(x_i)$:真实分布（ground truth） $q(x_i)$：模型预测分布 若p=q：交叉熵最小。 数学推导 二分类任务（Binary Classification） 真实标签$∈{0,1}$, 模型的输出预测为$\\hat y ∈(0,1)$,损失函数： $$ \\mathcal{L} = -[y \\log(\\hat{y}) + (1 - y)\\log(1 - \\hat{y})] $$ 多分类（Multi-class Classification） 对于 𝐶类问题，模型输出为经过 softmax 的概率分布 $\\hat y$，真实标签为 one-hot 向量 𝑦，损失函数为： $$\\mathcal{L} = -\\sum_{i=1}^C y_i \\log(\\hat{y}i) $$ 由于one-hot只有目标类为1，公式简化为： $$\\mathcal{L} = -\\log(\\hat{y}{\\text{target}}) $$ 代码实现 Numpy 实现 Softmax + Cross Entropy 123456789101112131415161718192021222324252627282930313233343536import torchdef softmax(logits): &quot;&quot;&quot; 计算 softmax 函数，将 logits 转换为概率分布 :param logits: 未经过 softmax 的 logits 张量 :return: 应用 softmax 之后的概率张量 &quot;&quot;&quot; exp_logits = torch.exp(logits) return exp_logits / torch.sum(exp_logits, dim=-1, keepdim=True)def cross_entropy_loss_manual(logits, target): &quot;&quot;&quot; 手动实现交叉熵损失函数 :param logits: 未经过 softmax 的 logits 张量 (batch_size, num_classes) :param target: 真实标签张量 (batch_size)，为类别的索引而不是 one-hot :return: 计算得到的交叉熵损失 &quot;&quot;&quot; # 先计算 softmax 输出 probs = softmax(logits) # 取出真实标签对应的概率值 (用 gather 选择每个样本正确标签对应的概率) log_probs = torch.log(probs) target_log_probs = log_probs[torch.arange(len(target)), target] # 计算平均交叉熵损失 loss = -torch.mean(target_log_probs) return loss# 测试手动 CrossEntropyLosslogits = torch.tensor([[2.0, 1.0, 0.1], [0.5, 2.5, 1.5]], dtype=torch.float32)target = torch.tensor([0, 2], dtype=torch.int64) # 标签为类别的索引manual_ce_loss = cross_entropy_loss_manual(logits, target)print(&quot;手动实现交叉熵损失结果: &quot;, manual_ce_loss) Pytorch实现（自动处理LogSoftmax） 官方文档 12345678import torchimport torch.nn.functional as Flogits = torch.tensor([[2.0, 1.0, 0.1]])targets = torch.tensor([0]) # 真实标签为类别索引loss = F.cross_entropy(logits, targets)print(f&quot;Loss: {loss.item()}&quot;) ⚠️ 注意：F.cross_entropy() 自动包括了 softmax 和 log 操作，因此输入应该是未归一化的 logits。 补充：Label Smoothing对交叉熵的影响 什么是Lable Smoothing？ Label Smoothing 是一种正则化技术，用于避免模型过度自信地预测某个类别。在 one-hot 编码中，真实标签为： 1[0, 0, 1, 0] # 100% 相信第 3 类 加入 label smoothing 后，标签会被“平滑”成： 1[0.1, 0.1, 0.7, 0.1] # 不再绝对确信 数学形式： $$ y^{\\text{smooth}}_i = (1 - \\epsilon) \\cdot y_i + \\frac{\\epsilon}{C} $$ $\\epsilon$：平滑因子 C：类别数 好处 减少过拟合 提升泛化能力 缓解softmax饱和（梯度消失） Pytorch 从 PyTorch 1.10 开始，torch.nn.CrossEntropyLoss 支持 label_smoothing 参数： 123456789import torchimport torch.nn as nnlogits = torch.tensor([[2.0, 1.0, 0.1]])targets = torch.tensor([0])criterion = nn.CrossEntropyLoss(label_smoothing=0.1)loss = criterion(logits, targets)print(f&quot;Loss with label smoothing: {loss.item()}&quot;) 补充： Focal loss：处理类别不平衡","link":"/2025/04/05/%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"},{"title":"使用pyinstaller将Python文件打包成exe","text":"本文介绍如何使用pyinstaller将.py文件打包成exe。 1 环境准备 conda： 1conda install pyinstaller pip: 1pip install pyinstaller 检查是否安装成功： 1pyinstaller --version 2 打包 基本使用方法 打包 Python 脚本 1pyinstaller your_script.py 运行后将在当前目录生成以下文件和文件夹： dist/：生成的可执行文件所在目录。 build/：临时文件夹，包含打包时的构建文件。 your_script.spec：PyInstaller 的配置文件。 打包的可执行文件位于 dist/your_script/ 文件夹中。 生成单文件可执行文件 1pyinstaller -F your_script.py 生成的单文件可执行文件位于 dist/ 文件夹中。 指定打包路径： 1pyinstaller -F --distpath ./output script.py 无控制台窗口 如果你的程序是 GUI 应用（如使用 tkinter 或 PyQt），不需要显示控制台窗口： 1pyinstaller -F -w your_script.py -w（或 --noconsole）会隐藏控制台窗口。 完成打包后 .exe文件默认放在dist/文件夹下： 123456project/├── script.py├── build/ # 打包时的临时文件夹├── dist/ # 生成的可执行文件所在目录│ └── script.exe└── script.spec # PyInstaller 的配置文件 可以通过修改配置文件中COLLECT函数，添加或者修改distpath参数，修改文件打包位置。 单文件模式 (-F) 的可执行文件 移动 .exe 文件单文件模式 (-F) 的可执行文件 直接移动 .exe 文件到任何位置都可以运行，因为所有的依赖都已经打包进去了。例如： 12dist/└── script.exe -&gt; 移动到任意位置后仍可运行 文件夹模式的可执行文件 如果使用的是文件夹模式（–onedir 或默认模式），.exe 文件需要和生成的其他依赖文件保持在一起才能运行。例如： 1234dist/script/├── script.exe├── library.zip├── ...（其他依赖文件） 在这种情况下，移动 .exe 文件时需要整个文件夹一起移动。 常用参数详解 以下是 PyInstaller 常用参数及其功能： 参数 功能 基本参数 -F, --onefile 将所有文件打包成一个独立的可执行文件。 -D, --onedir （默认）将生成的文件放在一个文件夹中，包括依赖文件和可执行文件。 -w, --noconsole 隐藏控制台窗口（适用于 GUI 应用）。 -c, --console 默认显示控制台窗口（适用于 CLI 应用）。 --name=NAME 指定生成的可执行文件名称（默认为脚本名）。 依赖处理 --hidden-import=MODULE 手动指定未被自动检测到的模块。 --exclude-module=MODULE 从打包中排除某些模块。 --add-data=SRC;DEST 将额外的数据文件（如图片、配置文件等）打包到指定目录中。使用分号分隔源文件和目标路径。 优化与调试 --clean 清除旧的构建文件（如 build/ 目录）。 --log-level=LEVEL 设置日志级别（可选值：DEBUG、INFO、WARN、ERROR）。 运行环境 --icon=ICON_PATH 指定可执行文件的图标（支持 .ico 格式）。 --key=KEY 对 Python 字节码加密时使用的密钥。 --debug 生成带调试信息的可执行文件。 高级用法示例 添加资源文件（图片、配置文件等） 将图片或其他资源文件打包到可执行文件中： 1pyinstaller -F --add-data &quot;config.json;.&quot; --add-data &quot;images/icon.png;images&quot; your_script.py config.json;. 表示将 config.json 放到可执行文件的根目录。 images/icon.png;images 表示将 icon.png 放到 images/ 文件夹中。 指定图标 为可执行文件指定图标： 1pyinstaller -F --icon=icon.ico your_script.py 处理隐藏依赖 某些动态导入的模块可能不会被 PyInstaller 自动检测到，需要显式指定： 1pyinstaller -F --hidden-import=module_name your_script.py 加密 Python 字节码 使用加密密钥保护 Python 源码： 1pyinstaller -F --key=my_secret_key your_script.py 生成调试版本 为调试生成的可执行文件： 1pyinstaller -F --debug your_script.py 常见问题与解决 依赖模块未正确打包 使用 --hidden-import 显式添加依赖模块。 使用 pip show module_name 查看依赖路径，确保依赖已安装。 路径问题 动态加载的文件可能需要 os.path 获取运行时路径。使用以下代码适配 PyInstaller 的运行路径：123456789import osimport sysdef resource_path(relative_path): if getattr(sys, 'frozen', False): # 如果是打包后的 exe base_path = sys._MEIPASS else: base_path = os.path.abspath(&quot;.&quot;) return os.path.join(base_path, relative_path) 文件过大 使用 --onedir 打包到文件夹形式，减少启动时间。 删除不必要的模块或依赖，使用 --exclude-module 参数。 exe在用户输入后程序闪退 在程序末尾添加input(&quot;\\n按回车键退出程序...&quot;)，即使运行结束也会等待用户按回车键后退出。 使用try-except 和 log捕获运行错误，记录到日志文件中 参考命令总结 用途 命令示例 打包单文件 pyinstaller -F script.py 打包带图标的单文件 pyinstaller -F --icon=icon.ico script.py 打包隐藏控制台窗口 pyinstaller -F -w script.py 添加资源文件 pyinstaller -F --add-data &quot;data.json;.&quot; script.py 加入未检测到的模块 pyinstaller -F --hidden-import=module_name script.py 生成调试版本 pyinstaller -F --debug script.py PyInstaller 是功能强大的工具，但需要根据具体的需求和环境进行调整和优化。掌握这些参数和技巧可以更高效地创建可执行文件。 本文参考GPT和百度","link":"/2024/11/20/%E4%BD%BF%E7%94%A8pyinstaller%E5%B0%86Python%E6%96%87%E4%BB%B6%E6%89%93%E5%8C%85%E6%88%90exe/"},{"title":"关于这个Hexo博客","text":"这个主题 这个博客用的主题是：icarus，当时一眼就相中了：这玩意儿真好看，我也要整一个，所以就有了现在这个样子的主页。 放上这个帅气的主题的github和链接吧： 123https://github.com/ppoffice/hexo-theme-icarushttps://ppoffice.github.io/hexo-theme-icarus/categories/Plugins/Donation/ 这个博客 这是我第一次创建博客，也是第一次搞这个主题，稀里糊涂的怎么也看不懂这个博客怎么建立、怎么写、怎么删（写这个内容的时候还没学会删除），搞上了这个主题之后，因为各个地方的设置也不是很清楚，目前只切换了我找得到的github的url和删掉了部分我不想要的链接和功能。 删掉评论单纯是因为我不会搞也懒得搞，这些博客都是自娱自乐的东西，记录一个才开始不就自己的代码之旅已经被搞得灰头土脸的人的学习和生活。仅此而已。 在我搞这个复杂（至少在我看来是的）的主题的时候，会陆陆续续贴上自己怎么搞的这个Hexo博客（这个简单），怎么修改主题（略复杂，如果没看懂大佬们的说明的话），以及怎么把这个主题搞得面目全非。 希望自己在魔改这个博客的各种东西的时候，没有冒犯到慷慨的大佬们的权益。博客内容肯定是我这个小白的总结和笔记，参考的东西都会贴上原贴或者视频地址。就先这样吧。 今天搭建这个玩意儿花了我四个小时，问就是我不会。不过是真的很简单，只是因为看了太多的资料有些搞混罢了，后面整理一下吧。 就先这样，如果你看到了这个博客，我会非常开心，说明我将这个blog发表了。或许可以做个点赞的功能（思考）","link":"/2023/04/10/%E5%85%B3%E4%BA%8E%E8%BF%99%E4%B8%AAHexo%E5%8D%9A%E5%AE%A2/"},{"title":"多头自注意力机制-MultiHead Self-Attention","text":"在Transformer中的多头自注意力机制的讲解和代码实现。 Transformer自从被提出之后哦，已经成为NLP和CV领域中的核心架构，而其中的**多头自注意力机制（Multi-Head Self-Attention）**正是该架构被提出的核心锁在。 是否是成功的关键呢？有读到一个论文说其实注意力不是让这个架构有这么好的效果的主要因素，而是这个大的框架效果很好。 该论文被发表在2022年的cvpr，MetaFormer Is Actually What You Need for Vision 本文只会解析Transformer的多头注意力部分，从原理出发，并给出对应Pytorch代码。 1 自注意力机制（Self-Attention） 在Transformer架构中，开始计算多头自注意力的序列是已经经过了position embeding，融合了位置信息的输入。 Scaled Dot-Product Attention $$ Attention(Q,K,V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V $$ 设输入一个序列： $$ X = [x_1, x_2, …, x_n] \\in \\mathbb{R}^{n \\times d} $$ $x_i$:输入序列（一个句子）的对应词的向量。 公式中的Q,K,V均是由矩阵的形式表示的，为了方便理解，我们先看单个$x_i$，观察注意力的计算过程： 这里，$x_i$在进行了position embeding后得到$a_i$，然后与QKV矩阵相乘得到$q_i$,$k_i$,$v_i$。 之后，每个词向量的q与自己和其他词的k进行相乘，得到$\\alpha_i$。 下一步，按照比例缩小，也就是除以公式中的$\\sqrt{d_k}$(Scaled的含义来源)，经过Softmax映射到（0,1）的区间之后，乘以$v_i$,再把每个结果求和，就是当前$x_i$的Attention计算结果。 ${d_k}$:词经过QK线性映射后的向量维度。防止点积值过大而影响softmax。 使用QKV矩阵计算就可以充分利用GPU的并行运算，加快计算速度。 公式中的QKV可以如下理解： Query（查询）：$Q = XW^Q$ Key（键）：$K = XW^K$ Value（值）：$V = XW^V$ 这样计算后的每个词都会包含所有词的位置信息（自己和上下文信息），成为新的向量。 2 多头注意力（Multi-Head Attention） 第一章节实现的注意力，相对于多头注意力而言，是单头注意力。 那多头注意力又是怎么来的，为什么要这么做呢？ 一次注意力，可以抽象的理解为从一种视角去认识这个词，但这缺乏灵活性，如果我用别的视角理解这个词，这个词的含义或许就不一样了。 所以作为改进，单头是每个词做一组QKV，现在每个词进行多次不同的QKV进行计算，也就是多头注意力。 也就是下面的步骤： 第一步：为每个头生成自己的 Q、K、V $$ Q_i = X W^Q_i,\\quad K_i = X W^K_i,\\quad V_i = X W^V_i $$ 其中： $W^Q_i, W^K_i, W^V_i \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$ 第二步：每个头计算注意力 $$ head_i = Attention(Q_i, K_i, V_i) = softmax \\left( \\frac{Q_i K_i^T}{\\sqrt{d_k}} \\right) V_i $$ 第三步：拼接所有头的输出 $$ Concat(head_1, \\ldots, head_h) \\in \\mathbb{R}^{L \\times (h \\cdot d_v)} $$ 第四步：线性变换输出 $$ \\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, …, \\text{head}_h) W^O $$ 其中： $W^O \\in \\mathbb{R}^{(h \\cdot d_v) \\times d_{\\text{model}}}$ 常用维度设定（默认每头相同维度）： $$ d_k = d_v = \\frac{d_{\\text{model}}}{h} $$ 3 多头注意力机制代码 Generate by chatGPT 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import torchimport torch.nn as nnimport torch.nn.functional as Fclass MultiHeadSelfAttention(nn.Module): def __init__(self, embed_dim, num_heads): &quot;&quot;&quot; Args: embed_dim: 嵌入维度 num_heads: 注意力头数 &quot;&quot;&quot; super(MultiHeadSelfAttention, self).__init__() assert embed_dim % num_heads == 0, &quot;Embedding dim must be divisible by number of heads&quot; self.embed_dim = embed_dim self.num_heads = num_heads self.head_dim = embed_dim // num_heads # 线性变换 self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3) self.out_proj = nn.Linear(embed_dim, embed_dim) def forward(self, x): &quot;&quot;&quot; Args: x: 输入张量，形状为 (B, N, D)，其中 B 是批大小，N 是序列长度，D 是嵌入维度 Returns: 输出张量，形状为 (B, N, D)&quot;&quot;&quot; B, N, D = x.size() # Batch, Seq_len, Embedding_dim qkv = self.qkv_proj(x) # -&gt; (B, N, 3D) 一个全连接层同时生成 Q、K、V，效率更高。 qkv = qkv.reshape(B, N, 3, self.num_heads, self.head_dim) # (B, N, 3, H, D_head) 离出 Q、K、V，并按头数分开 qkv = qkv.permute(2, 0, 3, 1, 4) # (3, B, H, N, D_head) Q, K, V = qkv[0], qkv[1], qkv[2] # 注意力得分 attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5) attn_weights = F.softmax(attn_scores, dim=-1) attn_output = torch.matmul(attn_weights, V) # (B, H, N, D_head) # 合并多头输出 attn_output = attn_output.transpose(1, 2).reshape(B, N, D) # -&gt; (B, N, D) output = self.out_proj(attn_output) return outputdef main(): # 测试 MultiHeadSelfAttention embed_dim = 64 num_heads = 8 batch_size = 32 seq_len = 10 model = MultiHeadSelfAttention(embed_dim, num_heads) x = torch.randn(batch_size, seq_len, embed_dim) output = model(x) print(&quot;Input shape:&quot;, x.shape) # (B, N, D) print(&quot;Output shape:&quot;, output.shape) # (B, N, D)main() 后续会补充labml.ai版的代码，带mask 给我帮助很大的网络材料： Transformer 其实是个简单到令人困惑的模型【白话DeepSeek06】 Multi-headed Self-attention（多头自注意力）机制介绍 补充Transformer的一个博客，Transformer的注解版： The Annotated Transformer","link":"/2025/04/15/%E5%A4%9A%E5%A4%B4%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-MultiHead-Self-Attention/"},{"title":"学会提问-读后感","text":"《学会提问》 作者：[美] Neil Browne / [美] Stuart Keeley 原名： Asking the Right Questions: A Guide to Critical Thinking 推荐值：4/5 起摘要？感受1感受2收获（笔记？）总结起 从2024年12月开始断断续续阅读这本书，终于在25年的二月读完，总共大概花了不到10个小时。 说来惭愧，大部分时间是趁着M1的病态分子学上课的时候读的，课听不明白，也没有心情在上课的时间来看论文，索性找了本书。 读这本书的目的很简单，我太需要一些在梳理逻辑上的帮助了。 摘要？ 书的内容其实和书名差不多，教你怎么去提问。 这或许有些难以理解，其实英文书名里面提到一个单词：Critical Thinking，才这个书的真正核心思想。 中文翻译为”批判性思维“，但我总觉得这个翻译虽然准确，却略有些强硬。忘记在哪里看到的，思辨能力这个词我更为喜欢一些。 作者从我们为什么需要Critical Thinking，如何判断什么时候需要用Critical Thinking来审视问题，再用生动的案例讲解进行Critical Thinking的时候的思维陷阱，逐步引领读者学会通过提问的方法获取知识。 这种思维模式不仅适用于我们接收一个论点，在输出论点（如写作）时，Critical Thinking也可以很好的帮助我们反思自己的逻辑是否完备。 感受1 其实这个书并没有非常详尽地书写一个非常严谨的论证过程，而是通过各种案例，如同一个娓娓道来的老师，带着读者从一个个观点中思考其中值得审视的地方，进行合理的提问，并尝试找到答案，最终让我们学会判断是否要接受这个观点的信息。 它不是一本教科书，更像是一本科普读物。 看到豆瓣上有的读者对此表示不满，觉得这个书太浅，而我却觉得刚刚好。它既保证了能读下去的趣味性，又足够广泛的讨论了如何建立批判性思维，以及批判性思维的重要性的事情。 若说不足之处的话，后面的章节，感觉有的小节分的太细，感觉没有太大的必要。不过不影响整体内容的呈现，只是我在做笔记的时候有些无从下手。 感受2 学会提出正确的问题。 首先需要思考的是，我们为什么要提问？ 本书在第一章节对此进行了简单的讲述：我们生活在一个充满信息的嘈杂的世界，对这些信息不假思索地吸取，会导致不正确的、甚至是有害的信息进入我们的大脑，所以我们需要时刻保持警醒。 以前我总想着，所有的知识我都吸收进去，总有一天我会有明辨是非的能力。但实际却未必如此。 从我想要开始锻炼自己的思维以来，我不假思索地看了多东西，却没有进一步思考和查证，回过头来，一些偏激的观点和懒惰的思维习惯已经在我脑中形成。 以往我直觉这种学习/思考方式似乎存在问题，却无法找到一个合适的方式进行优化。虽然在学校中《离散数学》等课程中学习了三段式推理等方法，但当时的学习更多的是为了完成作业和考试，学习依旧是应试式，没有融会贯通到自己的生活中，实在是可惜。 看本书的一些关于如何逻辑推理论点和论据之间，论据和论据之间的关系时，时不时会恍惚回忆起曾经学过的推理，充要条件、充分不必要和必要不充分…… 像是过去的一颗子弹，击穿现在的我的眉心，控诉我对思考的轻视。 收获（笔记？） 下面记录一点阅读此书后记忆深刻的知识，其实现在已经是三月了，且中间有很大一段空挡，书并不是每天或者每周阅读一点连续性读完的，所以能回忆起来的内容有限。 但是这种无法磨灭的记忆，或许就是这个书留给我的最关键的内容。 我应该是没办法用各种生动的语言来总结我记忆中的东西了，会复制很多原文的内容…… 接下来的内容没有结构上的逻辑，只是单纯的记忆碎片的搬运。 批判性思维者拥有的主要价值观 自主决断 好奇心 谦恭有礼 发自内心地尊重严密的论证 “理查德·费曼（Richard Feynman）是20世纪最著名的物理学家之一，他曾说过，当一个科学家有了一个想法时，他的第一步不是走出去为自己的想法寻找证据，而是思考想法中每一个可能的错误。” 论题的定义 描述性论题：关于各种对过去、现在或将来的描述准确与否的问题。 规定性论题：关于什么该做、什么不该做、什么是对、什么是错、什么是好、什么是坏的问题。 先确定论题本身的性质，再来继续思考该从设么角度探讨这个人对这个论题的立场是被什么支撑的。 提示词找理由 理由的提示词： 由于（as a result of） 研究显示（studies show） 因为这个事实（because of the fact that） 因为这个原因（for the reason that） 由以下材料支撑（is supported by） 因为证据显示（because the evidence is） 让我想起应对语言类考试的理解性题目时，那些所谓的解题技巧。我们很多时候都是被迫记忆这些关键词，却未被引导去梳理背后的修辞逻辑。 意义不明确的词 NLP领域中一个很经典的任务就是实体命名抽取。因为自然语言中充斥着太多模糊不清、多重含义的表达。我们第一直觉所想的含义未必是表达者真正的意思，甚至表达者会利用这些模糊不清来诱导你进行并不准确的逻辑推理。 最常见的一种值得警惕的词语就是描述程度的词。 价值观 价值观的冲突经常发生在社会议题中。 如言论自由与社会稳定 我曾和父母、朋友之间因此有过好几次口角，幸运的是，我们的感情足够坚固，以至于不会导致关系破裂。我们的关系反而因为一次又一次的深度交流，更加密切。我也非常感谢家人和朋友对我所拥有的不同价值观倾向给予包容。 首先，价值观冲突不是一个非此即彼的事情。打个比方：我支持言论自由，不代表我愿意牺牲所有的社会稳定，只是相比之下我觉得人的自由更为重要，因为这是人的基本权利。 但是，什么人什么话都可以说，这必然存在安全隐患。欺骗、唆使犯罪都还只是最为显而易见的会危害社会安全的因素。 所以，为了社会稳定，我们限制一些不合理言论在社交媒体上流传，是不得已的手段。这并不是不能理解的事情。 至于何为不合适的言论，又是另一个议题了。 判定价值观假设的一个重要方法就是问一下这个问题：​“为什么那个人如此看重他用作理由的特定后果或结果？​” 这让我想到，之所以我在和家人朋友发生价值观冲突仍然能维持关系，就是因为我们能从对方的角度思考，他们看重这个价值观作用的后果和理由，即使我们有不同的倾向，仍能相互理解和包容。 论证的谬误 了解常见的谬误种类，就像是我们在遇到自然灾害钱前预演过逃生技巧，让我们遇到时能迅速反应。 诉诸公众谬误：试图通过引述很多人都持有这一观点，以证明某个断言有道理。错误地以为很多人支持的事就是可取的。 诉诸可疑权威谬误：引用某一权威的话来证明结论，而该权威对这一论题并没有特别的专门知识 诉诸感情谬误：使用带有强烈感情色彩的语言来分散读者或听众的注意力，让他们忽视相关的理由和证据。常被用来加以利用的情感有：恐惧、希望、爱国主义、怜悯和同情 稻草人谬误：歪曲对方的观点，使其容易受到攻击，进而攻击事实上根本就不存在的观点 虚假的两难选择谬误：在现实中存在两种以上的选择时，却假想只有两种选择 乱扣帽子谬误：错误地以为因为你给某个特定事件或行为起了个名字，所以你合理解释了这一事件。 计划谬误：人们或者机构倾向于低估他们完成一项工作所需的时间，尽管有很多过去的经验显示他们曾一直低估完成某件事所需要的时间。 粉饰谬误：使用模糊、引发人们强烈情感认同的描述品行的词语，使我们倾向于同意某件事而不去细查其理由 转移话题谬误：插入一个不相干的话题，以将人们的注意力从原来的论题上转移开，通过将注意力从当前的论证转移到另一个论题上以赢得论证。这个例子中的谬误顺序如下：1）甲主题正被讨论；2）将乙主题引入，它好像和甲主题有关，实际上两者并不相干；3）甲主题被置之不理。 循环论证谬误：在论证过程中假设自己的结论成立的论证。 这只是书中列举出的部分谬误，但只是阅读这些谬误的定义，无需具体的案例，一些新闻和言论就已经在脑中复现…… 证据的效力 个人经历、典型案例、当事人证言和专家陈述 这种证据其实很难判断其效力如何。要判断事情的真假，陈述者与该论题的相关人员的利益纠纷，陈述者本身的表达能力等。 总而言之，随时提高警惕，我们无法做到神那样的无所不知，但不能因为做不到就放弃思考。 1）证据是立论者为支持一项主张而提供的明确信息。 2）所有说服力强的论证都需要高质量的证据。高质量的证据具有相关性、充分性和代表性。3）假设也需要证据支持。 4）几乎没有证据是完美的，我们希望找到有更好证据的论证。 5）大多数个人证据，无论是证词、案例研究还是直觉，都需要额外的支持才能令人信服。 6）科学证据最有可能是较好的证据 证据也是可以被选择的。 替代原因 论述者在阐述某个因果关系是，除了思考因果顺序是否成立之外，想想他所说的“因”是否有可能是别的，他没有注意到或者是故意忽视了？ 一直很想学习《因果推论》的相关知识，用统计的方法对因果关系进行分析，很有趣。 数据的欺骗性 做科研的人可太懂操作数据了。 数据来源、分析方法、评价指标…… 从别的角度分析 这就复杂了，除了从陈述者的论点顺着思考他的论据和证据是否能支持他的结论，也试着从反对他的角度来思考。 就像是准备一场辩论比赛（其实也差不多了），我们不仅要思考自己该怎么很好的支撑己方观点，对方会如何支持他们的论点，他们又会怎么辩驳我们的论点…… 思维的博弈会让我们更加接近真实。 总结 穷尽真理，更正谬误。","link":"/2025/03/14/%E5%AD%A6%E4%BC%9A%E6%8F%90%E9%97%AE-%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"title":"恢复SD卡被格式化数据","text":"今天又不小心把SD卡搞得出问题了，提示不格式化不能进行任何操作……记录一下恢复的过程。 误删相机中的照片可以尝试用同样的方法恢复数据。 事故发生 在准备把SD卡中拍摄的照片转移到我的U盘里面的时候，看到我的读卡器有点点松，就碰了一下，然后就无法转移数据了，所有的相片、视频都显示数据受损。 电脑提示：驱动损坏，需要格式化该硬盘。 插回相机：内存卡未格式化 原因分析 在SD卡的读写过程中不可以进行任何的热插拔操作，不然就会造成内存卡数据出错，可能会导致数据损坏。 发生这种提示的原因其实不只是这一中，据网络搜索，读卡器受损、相机受损、电脑系统故障，都有可能出现这种提示。这里做出上述判断纯粹是知道这是自己手贱造成的（哭）。 其实之前也有一次手滑，在相机里面删除了所有的照片。并且在相机上进行了强制格式化后继续拍照。这样很有可能会导致数据无法恢复，请勿模仿，把卡换下来，换备用卡谢谢。 解决方法 使用数据恢复软件对格式化后的SD卡进行数据恢复。 使用的软件：Recuva（免费版） 需要知道自己需要恢复的数据的路径。 很多别的软件是要收费的，说的是免费，但是其实是免费下载。我当时选了一个软件，扫描完了我的数据，都找到了，点击恢复说要给钱…… 操作步骤 当然是给他权限进去 选择恢复的数据类型 选则恢复路径 知道确切路径的话，就选择 In a specific location. 然后就会开始扫描这个路径下面有些什么残留的文件信息，会出现一个列表，选中自己要恢复的数据，列表回显示数据的时间、是否可恢复的状态等，根据需求恢复即可。 我记得好像是提示了不建议恢复到原位，这次我是选择了恢复到我的目标U盘里面。 之前删除照片的时候，是直接恢复到了原来的位置。倒也没影响我的这张卡的使用。 我的卡是32G的，恢复了34个G的数据……，失去数据前应该是有十多个G的视频和照片，我没有细看多恢复了哪些东西。但是其中有4个G的数据是无法查看的，估计是很久以前的东西，因为我这次要转移的数据都是新拍的，扫了一眼基本都是回来了的。 数据珍贵，操作消息 😢","link":"/2023/07/27/%E6%81%A2%E5%A4%8DSD%E5%8D%A1%E8%A2%AB%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%95%B0%E6%8D%AE/"},{"title":"我的小角落","text":"","link":"/2023/07/27/%E6%88%91%E7%9A%84%E5%B0%8F%E8%A7%92%E8%90%BD/"},{"title":"搭建自己的Hexo","text":"下面来讲讲怎么创建自己的Hexo博客，难度不是很大，顺利的话问题也不会怎么有，不顺利当我没说。 你需要准备的东西或者配置： Git Node.js Hexo 你的宝贝github账号 Git和Node.js的教程太多了，我也是很久以前安装的这个东西，大家随便在CSDN找个教程安装一下就行。 安装步骤 安装Git 安装Node.js 安装Hexo并配置 和你的Github链接 粗糙分就是这么几个步骤。 安装Git windows：到git官网上下载,Download git,下载后会有一个Git Bash的命令行工具，以后就用这个工具来使用git。 问就是别的系统我不会 安装Node 请自行搜索 检查node安装和版本，在cmd或者git bush（安装git后右键会有） 1node -v github注册和建库 github注册是我见过的最友好的注册了相信不需要细讲。实在不会b站有手把手的视频教学…… 建立用于hexo博客的专用Repositories 进入自己的主页 Repositories列表 看到一个绿色的按钮，写的New New一个 怎么New ！！ （注意） 这里的名字一定要和你的账号名字一样 Repository name：onername的那个name.github.io 别的不需要设置，跳过是可以的。我反正跳过了。 最后就是create。 这一步就结束了。 需要注意的地方 记得将SSH添加到Github 在git bash 中 12git config --global user.name &quot;yourname&quot;git config --global user.email &quot;youremail&quot; 然后创建SSH,一路回车 1ssh-keygen -t rsa -C &quot;youremail&quot; 在你的C盘的某个文件下面能找到一个.ssh的文件夹。 C:/User/.ssh 这个文件夹中的.pub用记事本打开，之后到github中： 鼠标放在头像，进入settings 点击左边导航栏：SSH and GPG keys SSH 那里 New SSH key 把pub的秘钥粘进去。 在github上面差不多就这了。 安装Hexo 这是官网：https://hexo.io/zh-cn/ 首先你需要准备一个空空荡荡的文件夹，名字无所谓，之后你的博客所有的配置都会下载到里面，包括你要发表的东西、主题等等。同样的，你瞎搞搞坏了博客，直接删掉这个文件夹，重新搭建Hexo就行。 假设你创建好了一个在D盘的博客文件夹 Blog 在这里，右键，打开 git bash 输入： 123456npm install -g hexo-clihexo init myblogcd myblog //进入这个myblog文件夹npm install 就安装好了，这个时候文件夹应该啪的一下有很多东西。 我现在知道的： theme：放你下载的主题的地方 source：用来存放你的文章 别的还不会用，以后更新。不过先贴出来： node_modules: 依赖包 public：存放生成的页面 scaffolds：生成文章的一些模板 _config：非常重要的配置文件 检查版本命令： 1hexo -v 在本地运行： 1hexo -s 就可以从localhost的那个地址看到自己的本地博客了。 将你的博客和github链接起来 前面已经创建了的那个仓库，就派上用场了。和github结合起来之后，大家就可以通过 username.github.io访问到你的博客了！ 下面介绍咋个搞： 在创建的这个Blog 文件夹里，找到_config 这个文件，打开。 在deploy的部分修改： 1234deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: main 记得对应好你的用户名 你需要先执行： 1npm install hexo-deployer-git --save 让你用命令部署到GitHub。 下载成功就可以，之后不会用到。 然后就是推送到你的github的那个io的仓库： 12hexo generatehexo deploy 成功之后就可以从https://YourgithubName.github.io.git找到你的博客了。 每次写完或者修改了什么之后，记得 12hexo ghexo d (前面的缩写) 才会刷新，相当于保存一下。 不是非常的及时，差不多等个几分钟就行。 可能会搜到有的人在保存之前都先 hexo c了一下，我不知道这是做什么，知道的话以后更新。不做好像问题不大。 每次写文章的步骤 hexo new &quot;Article Name&quot; hexo clean hexo g -d 如果要先写草稿： hexo new draft &quot;Article Name&quot; hexo publish &quot;Article Name&quot; hexo clean hexo g -d 参考的博客： https://blog.csdn.net/sinat_37781304/article/details/82729029","link":"/2023/04/10/%E6%90%AD%E5%BB%BA%E8%87%AA%E5%B7%B1%E7%9A%84Hexo/"},{"title":"文件或目录损坏且无法读取","text":"在导照片的时候……出现了这个提示。 这是GPT给的答案。 遇到U盘提示**“文件或目录损坏且无法读取”**的问题时，可以尝试以下几种方法来解决： 使用Windows磁盘检查工具： 打开“运行”窗口（可以按Windows+R），输入cmd打开命令提示符。 输入chkdsk X: /f（其中X是U盘的盘符）并回车，这将修复磁盘上的错误。 更改驱动器号和路径： 在“计算机管理”中选择“存储”-&gt;“磁盘管理”，找到U盘对应的“可移动磁盘”。 右键点击并选择“更改驱动器号和路径”，然后选择一个未被占用的盘符。 卸载并重新连接U盘： 在“设备管理器”中找到“通用串行总线控制器”，下的“USB大容量存储设备”。 右键点击并选择“卸载设备”，然后重新插入U盘。 如果上述方法都不能解决问题，可能需要使用专业的数据恢复软件来尝试恢复数据，或者联系专业的数据恢复服务。在尝试修复之前，建议不要对U盘进行写入操作，以免数据丢失。 希望这些方法能帮助您解决问题。如果还有其他问题，欢迎继续咨询。🛠️ 源: 与必应的对话， 2024/3/21 (1) U盘出现文件目录损坏或无法识别和读取，这该怎么办？ - 知乎. https://www.zhihu.com/question/22170790. (2) U盘出现文件目录损坏或无法识别和读取，这该怎么办？ - 知乎. https://www.zhihu.com/question/22170790/answers/updated. (3) U盘无法访问 “文件或目录损坏且无法读取” 的解决方法 - 搜狐. https://www.sohu.com/a/752395656_121271335. (4) U盘文件或目录损坏且无法读取的正确解决方法 - 百家号. https://baijiahao.baidu.com/s?id=1787759357483741041. (5) 关于u盘文件或目录损坏且无法读取的解决方法 - CSDN博客. https://blog.csdn.net/lmq1993/article/details/123241687.","link":"/2024/03/21/%E6%96%87%E4%BB%B6%E6%88%96%E7%9B%AE%E5%BD%95%E6%8D%9F%E5%9D%8F%E4%B8%94%E6%97%A0%E6%B3%95%E8%AF%BB%E5%8F%96/"},{"title":"无文件类型MRI数据处理方法","text":"在处理医学数据的时候遇到MRI数据未显示文件类型的状况，且不同序列的MRI混杂在一起无明显标记，只能通过软件打开后查看字段。 记录处理方法：DICOM转换为NIFTI 一、分析文件 文件显示如下： 文件无后缀名 文件中多序列MRI混杂 希望转化为序列名称_nii.gz的样式 既然有软件能自动识别不同的序列，且能显示序列信息，说明这个数据是可以读取和通过代码区分的。 问题是，win上并没有显示文件类型，首先需要确定文件类型。 mimetypes检测文件类型失败 无需install，可直接import。 1234567891011121314import osimport mimetypesfile_path = &quot;...&quot;# 检查文件是否存在if os.path.exists(file_path): # 获取文件的 MIME 类型 mime_type, _ = mimetypes.guess_type(file_path) if mime_type: print(f&quot;文件类型是: {mime_type}&quot;) else: print(&quot;无法确定文件类型，可能是未知格式。&quot;)else: print(&quot;文件路径不存在。&quot;) 检查文件类型，但是输出无法确定文件类型，可能是未知格式。 失败原因：它只看文件名的扩展名。但是现在需要处理的文件没有扩展名。 magic检测文件类型 Win： 1pip install python-magic-bin 12345678910111213141516import osimport magic # 需要安装 python-magic 库file_path = r&quot;..1&quot;# 检查文件是否存在if os.path.exists(file_path): # 使用 python-magic 检测文件类型 try: mime = magic.Magic(mime=True) mime_type = mime.from_file(file_path) print(f&quot;文件类型是: {mime_type}&quot;) except Exception as e: print(f&quot;检测文件类型时出错: {e}&quot;)else: print(&quot;文件路径不存在。&quot;) python-magic 的工作原理： 它 不依赖文件扩展名（如 .txt、.jpg）来判断类型。 它通过读取文件前几个字节的内容(magic number) 来判断文件的真实类型。 例如：一个 PNG 文件的前几个字节是固定的 89 50 4E 47，而 PDF 文件开头是 %PDF-1.x。 这意味着即使你把 .jpg 文件改名成 .txt，它也能识别出它是 JPEG 图片。 这次输出的是：文件类型是: application/dicom 二、图像解码 将上数学信息交给AI后，使用import pydicom进行解析。 但是，出现解码像素失败的提示。 通过AI提示，我们首先分析传输语法： 1传输语法: 1.2.840.10008.1.2.4.70 你遇到的错误说明：虽然 DICOM 文件可以被读取（即头信息没问题），但它的像素数据采用了 压缩编码（JPEG Lossless），而你当前环境 缺少支持解码这种压缩格式的库。 解决方案 把可能需要的解码插件全部install： 1pip install pylibjpeg pylibjpeg-libjpeg pylibjpeg-openjpeg 和： 1pip install python-gdcm 检查解码器状态 1234import pydicom.pixel_data_handlers as pdhprint(&quot;GDCM available:&quot;, pdh.gdcm_handler.is_available())print(&quot;pylibjpeg available:&quot;, pdh.pylibjpeg_handler.is_available()) 期望输出都是True 但是实际操作的时候，遇到了和Python版本不匹配问题：让GPT生成一个指定版本的install命令。 以及，install成功之后（在conda list中确定了该解析器存在）但始终输出为False，后来关关开开……uninstall和install来回搞了几次终于成功了，不知道到底是哪一步起了作用。 三、自动化处理 把上述信息处理好之后，丢给GPT，让他自动生成处理代码，下面对代码进行解析。 功能需求： 从raw处理到对应路径 按照序列划分nii 保存异常log 1 函数定义 1def convert_dicom_to_nifti(dicom_dir, output_dir, log_f, prefix=&quot;&quot;): dicom_dir: DICOM 文件的根目录（递归搜索所有子目录）。 output_dir: 转换后的 NIfTI 文件保存目录。 log_f: 打开状态的日志文件（用于写入错误信息）。 prefix: 日志中前缀标识符，用于标记任务来源等。 2 按照序列分组DICOM 123456dicom_groups = {}for root, _, files in os.walk(dicom_dir): ... series_uid = ds.SeriesInstanceUID series_name = getattr(ds, &quot;SeriesDescription&quot;, series_uid) ... 使用 os.walk() 递归遍历所有文件。 用 pydicom 读取 DICOM header，提取 SeriesInstanceUID（一个序列的唯一标识）来分组。 同时也提取 SeriesDescription 作为序列名字（用于文件命名）。 失败时写入日志。 3 逐序列读取图像切片 1for series_uid, (series_name, file_list) in dicom_groups.items(): 每个序列处理一次，读取所有切片： 12ds = pydicom.dcmread(file_path)arr = ds.pixel_array 如果是 2D 图像就正常处理； 如果是 3D 图像（少数特殊情况），就提取其中一层（避免 shape 异常）； 高维 (&gt;3D) 图像直接跳过，并复制原始文件夹备份 靠，这里需求写错了 4 统一图像尺寸 12max_h = max(shape[0] for shape in shapes)max_w = max(shape[1] for shape in shapes) 先找出所有切片中的最大高宽，作为统一目标尺寸。 然后将每张图像： 如果太小：padding 到最大尺寸。 如果太大：中心裁剪 到最大尺寸。 这样做的目的是为了能用 np.stack() 沿 z 轴堆叠成 3D 体积。 5 保存为 NIfTI 文件 12volume = np.stack(padded_slices, axis=-1)nifti_img = nib.Nifti1Image(volume, affine) 日志和返回值 日志文件会写入所有处理失败的文件路径与原因。 sequence_shapes 是一个字典，返回每个序列对应的 3D 图像 shape，例如： 12345{ &quot;T1_Post&quot;: (512, 512, 150), &quot;FLAIR&quot;: (256, 256, 180), ...} 完整处理代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import osimport shutilimport pydicomimport nibabel as nibimport numpy as npfrom tqdm import tqdmdef convert_dicom_to_nifti(dicom_dir, output_dir, log_f, prefix=&quot;&quot;): os.makedirs(output_dir, exist_ok=True) sequence_shapes = {} # 扫描 DICOM 文件并按序列分组 dicom_groups = {} for root, _, files in os.walk(dicom_dir): for file in files: file_path = os.path.join(root, file) try: ds = pydicom.dcmread(file_path, stop_before_pixels=True) series_uid = ds.SeriesInstanceUID series_name = getattr(ds, &quot;SeriesDescription&quot;, series_uid) if series_uid not in dicom_groups: dicom_groups[series_uid] = (series_name, []) dicom_groups[series_uid][1].append(file_path) except Exception as e: log_f.write(f&quot;{prefix}\\t[读取失败] 跳过文件: {file_path}\\t错误: {e}\\n&quot;) log_f.flush() # 处理每个序列 for series_uid, (series_name, file_list) in dicom_groups.items(): slices = [] shapes = [] has_invalid_dim = False for file_path in sorted(file_list): try: ds = pydicom.dcmread(file_path) arr = ds.pixel_array if arr.ndim == 2: pass elif arr.ndim == 3: arr = arr[0] if arr.shape[0] &lt;= arr.shape[-1] else arr[..., 0] else: log_f.write(f&quot;{prefix}\\t[跳过NIfTI转换，高维] {series_name}\\t{file_path}\\tshape: {arr.shape}\\n&quot;) log_f.flush() has_invalid_dim = True continue shapes.append(arr.shape) slices.append((arr, file_path)) except Exception as e: log_f.write(f&quot;{prefix}\\t[加载失败] {series_name}\\t{file_path}\\t错误: {e}\\n&quot;) log_f.flush() if has_invalid_dim or len(slices) == 0: raw_copy_dir = os.path.join(output_dir, f&quot;raw_{series_uid}&quot;) os.makedirs(raw_copy_dir, exist_ok=True) for f in file_list: try: shutil.copy2(f, raw_copy_dir) except Exception as e: log_f.write(f&quot;{prefix}\\t[复制失败] {series_name}\\t{f}\\t错误: {e}\\n&quot;) log_f.flush() sequence_shapes[series_name] = None continue max_h = max(shape[0] for shape in shapes) max_w = max(shape[1] for shape in shapes) padded_slices = [] for (arr, file_path), shape in zip(slices, shapes): try: h, w = arr.shape pad_top = max((max_h - h) // 2, 0) pad_bottom = max_h - h - pad_top pad_left = max((max_w - w) // 2, 0) pad_right = max_w - w - pad_left if h &gt; max_h or w &gt; max_w: crop_h_start = (h - max_h) // 2 crop_w_start = (w - max_w) // 2 arr = arr[crop_h_start:crop_h_start + max_h, crop_w_start:crop_w_start + max_w] else: arr = np.pad(arr, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant') padded_slices.append(arr) except Exception as e: log_f.write(f&quot;{prefix}\\t[处理失败] {series_name}\\t{file_path}\\t错误: {e}\\n&quot;) log_f.flush() try: volume = np.stack(padded_slices, axis=-1) affine = np.eye(4) nifti_img = nib.Nifti1Image(volume, affine) safe_name = &quot;&quot;.join(c if c.isalnum() or c in (' ', '_', '-') else '_' for c in series_name).replace(&quot; &quot;, &quot;_&quot;) output_file = os.path.join(output_dir, f&quot;{safe_name}.nii.gz&quot;) nib.save(nifti_img, output_file) sequence_shapes[series_name] = volume.shape # 保存尺寸 except Exception as e: log_f.write(f&quot;{prefix}\\t[保存NIfTI失败] {series_name}\\t错误: {e}\\n&quot;) log_f.flush() sequence_shapes[series_name] = None return sequence_shapes","link":"/2025/05/08/%E6%97%A0%E6%96%87%E4%BB%B6%E7%B1%BB%E5%9E%8BMRI%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/"},{"title":"数据结构与算法-1","text":"使用C语言实现的数据结构与算法。都非常基础。 用于自己备考和练习。 本文包含： 数据结构：栈、链表 算法：搜索、排序 Data Structure Data Structure栈 - Stack栈的定义与销毁栈的一些基本操作和特性：push(item)pop()top()isEmpty()size()：获取栈中元素的个数。链表 - Link一般链表定义节点创建节点从头插入删除特定值按照升序插入链表反转链表归并排序算法 - AlgorithmSearch Algorithm线性查找 - Linear Search二分查找 - Binary Search1. binary_search1：左闭右闭2. binary_search2：左闭右开3. 使用递归的方法排序算法 - Sort插入排序 - Insertion_Sort选择排序 - select sort冒泡排序及其优化 - Bubble Sort常规优化快速排序 - Quick Sort栈 - Stack 栈的主要特点如下： 后进先出（LIFO）：最后插入的元素将最先被移除。类比于一叠盘子，最后放上去的盘子最先被拿走。 压栈和弹栈：栈的主要操作包括压栈（push）和弹栈（pop）。压栈将元素放入栈的顶部，弹栈将顶部元素移除。 栈顶指针：栈中用一个指针来指示栈顶元素的位置，可以称之为&quot;栈顶指针&quot;。 适用场景：栈常用于需要&quot;先进后出&quot;处理的场景，比如函数调用栈、表达式求值、逆波兰表达式求值、括号匹配等。 功能简单：相比其他数据结构如队列、链表等，栈的功能较为简单，通常只包含压栈和弹栈两种基本操作。 栈的定义与销毁 1234567891011121314151617181920212223typedef struct stack{ int *data; int top; int max_size;}*stack;// 销毁栈void destroy_stack(stack s){ free(s-&gt;data); free(s);}// create a stackstack create_stack(int max_size){ stack s = (stack)malloc(sizeof(struct stack)); s-&gt;data = (int *)malloc(sizeof(int) * max_size);// 创建动态数组 s-&gt;top = 0; s-&gt;max_size = max_size; return s;} 栈的一些基本操作和特性： push(item) 将元素item压入栈的顶部。 12345678void push(stack s, int val){ if (s-&gt;top &lt; s-&gt;max_size) { s-&gt;data[s-&gt;top++] = val; } return;} pop() 弹出栈顶的元素，并返回该元素。 1234567int pop(stack s){ if(s-&gt;top &gt; 0){ return s-&gt;data[--s-&gt;top]; }} top() 获取栈顶的元素，但不对栈进行修改。 12345678910int top(stack s){ if(s-&gt;top &gt; 0) { return s-&gt;data[s-&gt;top - 1]; } return -1;} isEmpty() 检查栈是否为空。 1234int isEmpty(stack s){ return (s-&gt;top == 0);} size()：获取栈中元素的个数。 1234int size(stack s){ return s-&gt;top;} 链表 - Link 一般链表 无空头。 定义节点 这段代码定义了一个结构体类型NODE，用于表示链表中的节点。结构体中包含两个成员变量： int val: 这是一个整数类型的变量，用于存储节点中的数据。 struct _NODE* next: 这是一个指针变量，用于指向链表中的下一个节点。由于结构体类型NODE在定义时还没有完全定义，因此需要使用struct _NODE*来表示指向自身类型的指针。 1234567typedef struct _NODE{ /* data */ int val; // 存储数据 struct _NODE * next;// 指向下一个的指针 }NODE; 创建节点 1234567NODE* create_node(int v){ NODE* newNode = (NODE*) malloc(sizeof(NODE)); //创建新的结构体对象 newNode-&gt;val = v; //初始化 newNode-&gt;next = NULL; return newNode;} 说明： NODE* newNode: 这是一个指针变量，用于指向新创建的链表节点。NODE*表示这是一个指向NODE类型的指针。 (NODE*) malloc(sizeof(NODE)): 这是动态内存分配的部分。malloc函数用于在堆上分配一块指定大小的内存空间，并返回指向该内存块的指针。sizeof(NODE)用于计算结构体类型NODE所占用的字节数，这样malloc就会为新的节点分配足够大小的内存空间。 从头插入 123456NODE* insert_head(NODE *h, int v){ NODE* newNode = create_node(v); newNode-&gt;val = v; newNode-&gt;next = h; return newNode;} 删除特定值 12345678910111213141516171819202122232425262728293031323334353637// 删除值为v的节点NODE* del(NODE* h, int v){ NODE *p, *q; p = h, q = h; // 若头就是目标节点 if(h-&gt;val == v){ p = h-&gt;next; free(h); return p; } // 其余情况 while(p-&gt;val != v) { q = p;// q记录要删掉的节点的前一个节点 p = p-&gt;next; if(p == NULL){ // check printf(&quot;This Node is not exist.\\n&quot;); return h; } } // 此时p指向被删节点，q在前一个 printf(&quot;The target number: %d, current Node: %d \\n&quot;, v, p-&gt;val ); // q-&gt;next指向被删节点的下一个节点，链接两部分。 q-&gt;next = p-&gt;next; // 删除节点 free(p); return h;} 按照升序插入 1234567891011121314151617181920212223242526272829303132NODE* insert_ordered(NODE* h, int v){ if (h == NULL){ h = create_node(v); return; } // 若插入的梳子小于head，则作为新的头 if(h-&gt;val &gt;= v) { h = insert_head(h,v); return h; } // 一般情况 NODE* p = h, *q = h; while(p-&gt;val &lt; v){ q = p; p = p-&gt;next; // 要插到尾巴,跳出循环 if(p == NULL){ break; } } NODE *newNode = create_node(v); q-&gt;next = newNode; newNode-&gt;next = p; return h;} 链表反转 123456789101112131415161718192021NODE *reverse(NODE* h){ if(h-&gt;next == NULL){ return h; } // p记录反转后的头 // q源列表剩下的头 // tmp 暂存源列表的下一个 NODE *p, *q, *tmp; p = h; q = h-&gt;next; h-&gt;next = NULL;// head变成tail while(q){ tmp = q-&gt;next; //剩下的头 q-&gt;next = p; // p = q; q = tmp; } return p;} 链表归并排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647NODE* merge(NODE *h1, NODE *h2){ printf(&quot;START MERGE:\\n&quot;); if (h1 == NULL) return h2; if (h2 == NULL) return h1; NODE* result, *p, *q;// p记录1，q记录2 p = h1, q = h2; // 先确定头 printf(&quot;SETTING HEAD.....\\n&quot;); if(p-&gt;val &lt; q-&gt;val){ result = p; p = p-&gt;next; }else{ result = q; q = q-&gt;next; } // body 这里都是result的尾插 NODE *tail = result; printf(&quot;MERGING.....\\n&quot;); while(p &amp;&amp; q){ if(p-&gt;val &lt;= q-&gt;val){ tail-&gt;next = p; p = p-&gt;next; }else{ tail-&gt;next = q; q = q-&gt;next; } tail = tail-&gt;next; } if(p){ tail-&gt;next = p; } if(q){ tail-&gt;next = q; } return result;} 算法 - Algorithm Search Algorithm 手动定义顺序数组 input： target output：find or not. 线性查找 - Linear Search 线性查找计算量为O(n)。 1懒得写 二分查找 - Binary Search 使用二分查找的前提是，数组为有序数组，且数组钟不可以有重复元素（因为可能返回的下下标不止一个）。 注意二分查找的边界，left 和 right 该如何定义与变化。 主要需要注意，right在边界是如何取值的，是否包含有边界会影响终止条件与对目标的搜索范围。 时间复杂度：O(log n) 1. binary_search1：左闭右闭 建议死记硬背这一种 被初始化为 ```SIZE - 1```，即数组 a 的最后一个元素的索引。这使得待搜索区间为全封闭区间 ```[l, r]```，包括了边界上的元素。12345678910111213141516171819202122232425262728293031323334循环条件是 ```while (l &lt;= r)```，即当左边界 l 小于或等于右边界 r 时继续循环。当搜索区间为空——```l &gt; r```的时候终止循环。```Cvoid binary_search1(int a[], int t){ // 当 t 定义在全封闭[l,r]的范围内。 int l,r,mid; l = 0; r = SIZE - 1; // 这里r注意 // 因为left == right是有意义的 while(l &lt;= r) { mid = (l + r) / 2; if(t &lt; a[mid]){ r = mid - 1; } else if(t &gt; a[mid]) { l = mid + 1; } else{ printf(&quot;True.&quot;); return ; } } printf(&quot;False&quot;); return ;} 2. binary_search2：左闭右开 被初始化为 ```SIZE```，即数组 a 的长度。这使得待搜索区间为半关半开区间 ```[l, r)```，不包括右边界。12345678910111213141516171819202122232425262728293031323334循环条件是 while (l &lt; r)，即当左边界 l 小于右边界 r 时继续循环。当搜索区间为空——```l == r```的时候终止循环。```Cvoid binary_search2(int a[], int t){ // 当 t 定义在半关半开[l,r)的范围内。 int l,r,mid; l = 0; r = SIZE; // 这里r注意 // 因为left == right没有意义了 while(l &lt; r) { mid = l + ((r-l)&gt;&gt;1); if(t &lt; a[mid]){ r = mid ; // 这里，右边始终保持开区间 } else if(t &gt; a[mid]) { l = mid + 1; } else{ printf(&quot;True.&quot;); return ; } } printf(&quot;False&quot;); return ;} 3. 使用递归的方法 123456789101112131415161718192021222324252627void binary_search(int a[], int t){ int flag = _binary_search(a,0,SIZE - 1,t); if(flag == 1){ printf(&quot;True.\\n&quot;); } if(flag == -1){ printf(&quot;False.\\n&quot;); }}int _binary_search(int a[], int l, int r, int t){ if(r &gt;= l) { int mid = (l + r) / 2; if( a[mid] == t) return 1; else if(a[mid] &gt; t) return _binary_search(a,l,mid-1,t); else return _binary_search(a, mid + 1, r, t); } return -1;} 排序算法 - Sort 插入排序 - Insertion_Sort 将数组A[0…n-1]分为两个部分，已排序部分A[0…j-1] 和未排序部分A[j…n-1]。 每次将未排序部分的第一个数，有序地插入已排序的部分。 时间复杂度：$$ O(n^2)$$ 123456789101112131415161718192021void insertion_sort(int nums[]){ printf(&quot;-------- Insertion_Sort_Optimized ----------\\n&quot;); for(int j = 1; j&lt;SIZE; j++) { int key = nums[j]; // insert nums[j] into sorted sequence A[0...j-1] int i = j - 1; while(i &gt;= 0 &amp;&amp; nums[i] &gt; key) { nums[i+1] = nums[i]; i--; } nums[i+1] = key; printf(&quot;Loop %d: &quot;,j-1); print_array(nums); } printf(&quot;END:&quot;); print_array(nums); printf(&quot;==================================\\n&quot;);} -------- Insertion_Sort_Optimized ---------- Loop 0: 3 6 2 7 9 8 0 1 5 4 Loop 1: 2 3 6 7 9 8 0 1 5 4 Loop 2: 2 3 6 7 9 8 0 1 5 4 Loop 3: 2 3 6 7 9 8 0 1 5 4 Loop 4: 2 3 6 7 8 9 0 1 5 4 Loop 5: 0 2 3 6 7 8 9 1 5 4 Loop 6: 0 1 2 3 6 7 8 9 5 4 Loop 7: 0 1 2 3 5 6 7 8 9 4 Loop 8: 0 1 2 3 4 5 6 7 8 9 END:0 1 2 3 4 5 6 7 8 9 选择排序 - select sort 将数组A[0…n-1]分为两个部分，已排序部分A[0…j-1] 和未排序部分A[j…n-1]。 从未排序部分选出最小的元素，与未排序部分的第一个元素进行交换。 12345678910111213141516171819202122232425262728293031void select_sort(int nums[]){ printf(&quot;-------- Select_Sort_Optimized ----------\\n&quot;); int pos = 0,tail = 0; int tmp ; while(tail&lt; SIZE) { // find the smallest one, remember the position. for(int i = tail;i&lt;SIZE;i++) { if(nums[i] &lt; nums[pos]) { pos = i; } } // exchange tmp = nums[tail]; nums[tail] = nums[pos]; nums[pos] = tmp; tail++; pos = tail; printf(&quot;\\nloop %d: &quot;,tail); print_array(nums); } printf(&quot;END:&quot;); print_array(nums); printf(&quot;==================================\\n&quot;);} -------- Select_Sort_Optimized ---------- loop 1: 0 6 2 7 9 8 3 1 5 4 loop 2: 0 1 2 7 9 8 3 6 5 4 loop 3: 0 1 2 7 9 8 3 6 5 4 loop 4: 0 1 2 3 9 8 7 6 5 4 loop 5: 0 1 2 3 4 8 7 6 5 9 loop 6: 0 1 2 3 4 5 7 6 8 9 loop 7: 0 1 2 3 4 5 6 7 8 9 loop 8: 0 1 2 3 4 5 6 7 8 9 loop 9: 0 1 2 3 4 5 6 7 8 9 loop 10: 0 1 2 3 4 5 6 7 8 9 END:0 1 2 3 4 5 6 7 8 9 ================================== 冒泡排序及其优化 - Bubble Sort 常规 反复交换相邻的未按次序排序的元素。低效但常用。 123456789101112131415161718192021222324void bubble_sort(int nums[]){ printf(&quot;-------- Bubble_Sort ----------\\n&quot;); int i, j,tmp; for(i = 0; i &lt; SIZE; i++) { for(j = 1; j&lt; SIZE- i ; j++) { if(nums[j] &lt; nums[j-1]) { tmp = nums[j]; nums[j] = nums[j-1]; nums[j-1] = tmp; } } printf(&quot;bubble loop %d: &quot;,i); print_array(nums); } printf(&quot;END:&quot;); print_array(nums); printf(&quot;==================================\\n&quot;);} -------- Bubble_Sort ---------- bubble loop 0: 3 2 6 7 8 0 1 5 4 9 bubble loop 1: 2 3 6 7 0 1 5 4 8 9 bubble loop 2: 2 3 6 0 1 5 4 7 8 9 bubble loop 3: 2 3 0 1 5 4 6 7 8 9 bubble loop 4: 2 0 1 3 4 5 6 7 8 9 bubble loop 5: 0 1 2 3 4 5 6 7 8 9 bubble loop 6: 0 1 2 3 4 5 6 7 8 9 bubble loop 7: 0 1 2 3 4 5 6 7 8 9 bubble loop 8: 0 1 2 3 4 5 6 7 8 9 bubble loop 9: 0 1 2 3 4 5 6 7 8 9 END:0 1 2 3 4 5 6 7 8 9 ================================== 优化 1234567891011121314151617181920212223242526272829303132void bubble_sort_optimized(int nums[]){ printf(&quot;-------- Bubble_Sort_Optimized ----------\\n&quot;); int j,tmp,last,cnt; last = SIZE-1; // last will remember the last time where the swap happened. cnt = 0; while(last) { last = 0; // Ever time reset to 0 because we start from the first position. for(j = 1; j &lt; SIZE; j++) { if(nums[j] &lt; nums[j-1]) { tmp = nums[j]; nums[j] = nums[j-1]; nums[j-1] = tmp; last = j-1; printf(&quot;last = %d; &quot;,last); } } printf(&quot;\\nbubble loop %d: &quot;,cnt); print_array(nums); } printf(&quot;END:&quot;); print_array(nums); printf(&quot;==================================\\n&quot;);} -------- Bubble_Sort_Optimized ---------- last = 1; last = 4; last = 5; last = 6; last = 7; last = 8; bubble loop 0: 3 2 6 7 8 0 1 5 4 9 last = 0; last = 4; last = 5; last = 6; last = 7; bubble loop 0: 2 3 6 7 0 1 5 4 8 9 last = 3; last = 4; last = 5; last = 6; bubble loop 0: 2 3 6 0 1 5 4 7 8 9 last = 2; last = 3; last = 4; last = 5; bubble loop 0: 2 3 0 1 5 4 6 7 8 9 last = 1; last = 2; last = 4; bubble loop 0: 2 0 1 3 4 5 6 7 8 9 last = 0; last = 1; bubble loop 0: 0 1 2 3 4 5 6 7 8 9 bubble loop 0: 0 1 2 3 4 5 6 7 8 9 END:0 1 2 3 4 5 6 7 8 9 快速排序 - Quick Sort 最坏时间复杂度：$$ O(n^2) $$ 期望时间复杂度：$$ O(nlg n) $$ 将数组分为三个部分： 左段：所有元素不得大于middle 右段：所有元素不得小于middle middle：一个轴元素，可称为支点（pivot） 这个middle不代表是这个数组的中间值，仅是用于分段。 首先对nums[0:n-1]进行快排，找到一个元素作为支点（此时这个元素已经在排序后的位置） 对左边进行快排 对右半部分进行快排 直到子序列长度为0 使用两个函数： 递归入口quick_sort ：记录轴函数位置，以及对子序列进行排序 PARTITION ：子数组进行原地址重排。 x：记录轴元素的啊小 i：表示已经处理过的元素中，最后一个小于等于轴元素 x 的元素的索引。 j：遍历子数组，与x对比看是否需要换到左边。 代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243void quick_sort(int nums[], int p, int r){ /* 传入进行排序的数组，起始位置p和终止为止r */ if(p&lt;r){ int q = PARTITION(nums,p,r); quick_sort(nums,p,q-1); quick_sort(nums,q+1,r); } // print_array(nums); return ;}int PARTITION(int nums[], int p, int r){ /*对子数组进行原地址重排*/ int x = nums[r]; // x为轴元素 int i = p - 1; //i 的值表示已经处理过的元素中，最后一个小于等于轴元素 x 的元素的索引。 int j = p; for( j; j&lt;r;j++) { if (nums[j]&lt;= x) { i++; // 交换 swap(nums,i,j); } } swap(nums,i+1,r); printf(&quot;%d %d &quot;,p,r); for(int i =0;i&lt;r;i++){ printf(&quot;%d &quot;,nums[i]); } printf(&quot;\\n&quot;); return i+1;} 另一种写法 将两个函数结合在一起。 123456789101112131415161718192021222324252627282930313233void quick_sort_inOne(int nums[], int l, int r){ /*将两个函数结合在一起完成快排*/ if(l&gt;= r) return ; int i = l; int j = r; int pivot = nums[l];// 以最左边的为基准 // i 找到左边大于pivot的，j 找到小于pivot的。 while(i &lt; j) { while(nums[i] &lt; pivot) { i++; } while(nums[j] &gt; pivot) { j--; } if(i &lt; j) swap(nums,i,j); else break; } printf(&quot;tmp: &quot;); print_array(nums); quick_sort_inOne(nums,l,i-1); quick_sort_inOne(nums,i+1,r); return; } 和老师的不一样，这是老师的写法： 12345678910111213141516171819202122232425262728293031void quick_r(vector&lt;int&gt;&amp; nums, int l, int r){ if (l &gt;= r) return; int i = l; int j = r; int pivot = nums[l];// 以最左边的为基准 while (i &lt; j) { while (i&lt;j &amp;&amp; nums[j] &gt; pivot) j--;// 必须先从右往左扫，找到第一个小于p的位置 if (i &lt; j) { nums[i] = nums[j];// 应该也可以写作：nums[i++] = a[j]; 一行 i++; } while (i &lt; j &amp;&amp; nums[i] &lt; pivot) i++;// 从左到右扫，直到找到大于p的 if (i &lt; j) { nums[j] = nums[i]; j--; } } // 最后i的位置就是p应该在的位置 nums[i] = pivot; // 稍微看看快排每次啥情况 cout &lt;&lt; &quot;快排调用：&quot;; printArry(nums); // 处理左半边和右半边 if (l &lt; i - 1) quick_r(nums, l, i - 1); if (i + 1 &lt; r) quick_r(nums, i + 1, r);}","link":"/2025/04/01/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-1/"},{"title":"更换Hexo主题","text":"来讲一下怎么更换自己喜欢的主题吧，如何查找喜欢的主题、如何更换，都有写的。 我用的最麻烦的一种方式，因为我还不是很会git的语句。 但是，简单的来说就是以下几个步骤： 找到喜欢的主题 hexo官网theme： https://hexo.io/themes/ 某呼会有人写推荐 任何你想得到的别人会推荐这个博客主题的地方。 把这个主题下载到theme文件夹内，文件名用这个主题的名字 把_config.yml 中的theme改为这个名字 接下来用我使用的这个主题ICARUS进行介绍 1. 下载这个主题 https://github.com/ppoffice/hexo-theme-icarus 作者会分享到github上面，在github上下载到你的themes文件夹中 理论上这一步可以通过git指令完成。等我学会了再说。 非常的easy对吧 2. 设置yml 根据大佬github的指示干就行 12$ npm install hexo-theme-icarus$ hexo config theme icarus 第一句不知道是啥，但是看起来是icarus这个主题要做的，什么效果不知道，反正搞就是了。 第二句是属性设置，可以不用进到yml文件里手动修改theme的属性，这行代码就可以搞定。 3. 之后 其实下载好之后，你会发现还有很多需要自己去设定的东西，比如你的头像、昵称、你的社交媒体的链接等等，icaus的作者在自己的展示页面是配备了修改的讲解的，可以按照说明来。 据我观察，基本都是修改config文件，或者是主题自带的它的configXX文件。 说了这么多，我自己的主题都没有修改完哈哈。就先这样吧。","link":"/2023/04/11/%E6%9B%B4%E6%8D%A2Hexo%E4%B8%BB%E9%A2%98/"},{"title":"浏览器存储简介","text":"前端常见数据存储方式：Cookie，Local Storage和Session Storage 一、Cookie 已知HTTP是一种无状态协议，而我们在使用Web的过程中，经常需要保持状态。 Cookie查看 按住f12进入开发者模式，在网络中查看： 由服务端产生 浏览器保存至本地 每次浏览器像同一服务端发送请求时，都会将Cookie发送回服务器。 Cookie 可以被这样来回在前后端传递。 用于记录 会话状态 身份验证 跟踪用户行为 …… 优点 可以在浏览器和服务器之间来回传递，用于跟踪用户行为 可手动设置过期时间，灵活调整存储时间 缺点 每次传递Cookie增加流量浪费性能 HTTP中明文传递，易被篡改 存储容量较小，一般为4kb 二、Local Storage 为解决耗流量和浪费性能问题，HTML5中引入Local Storage. 这个API允许浏览器长期存储键值对数据。不会随着HTTP请求发送到服务器。 优点 存储容量较大：5M 永久存储在客户端浏览器，不担心丢失 操作方便，API可通过JavaScript直接访问 缺点 只能访问自己域下的LS 对跨域数据共享、单点登录等功能有限制 不支持不同浏览器共享数据 LS通常保存个人偏好设置：隐私、浏览器外观等 查看LS： f12 Application 三、Session Storage 也是HTML5引入的新Web存储方式，与Local Storage最大的区别还是数据尽在留恋其会话期间有效，会话结束后会被清除。 单个浏览器标签页或者窗口之间共享数据。 官方 优点 数据仅存储在客户端 刷新后保留会话数据 每个标签/窗口间数据独立 缺点 不适合长期存储 数据不共享，使用场景有限 使用场景 多步骤表单 用户可以在填写过程中点击上一步、下一步修改数据。使用Session Storage暂存内容。 四、总结 特性 Cookie Local Storage Session Storage 存储容量 ~4KB ~5MB ~5MB 生命周期 可设置过期时间；不设置则会话结束失效 永久保存，除非手动删除 仅在当前会话中有效，关闭标签页即清除 与服务器通信 每次请求都会自动携带 不自动发送 （只存储本地，不与服务器交互） 不自动发（只存储本地，不与服务器交互）送 可被访问的页面范围 当前域名下所有页面 当前域名下所有页面 当前标签页 数据类型支持 仅支持字符串 仅支持字符串 仅支持字符串 安全性 易受 XSS 攻击；可设置 HttpOnly 降低风险 易受 XSS 攻击 易受 XSS 攻击 使用场景示例 登录状态、用户追踪等 用户偏好、缓存数据等 表单填写临时保存、会话状态数据等 选择方法 客户端和服务器之间共享数据+长期存储 Cookie 只在客户端长期存储+无需服务器交互 Local Storage 只在客户端+会话期间暂存 Session Storage","link":"/2025/04/29/%E6%B5%8F%E8%A7%88%E5%99%A8%E5%AD%98%E5%82%A8%E7%AE%80%E4%BB%8B/"},{"title":"激活函数-ReLU-LeakyReLU","text":"对激活函数： ReLU Leaky ReLU 进行定义介，包括公式定义、代码实现和优缺点，以及适用场景。 1 ReLU 公式： $$ ReLU(x)=x^{+}=max(0,x)=\\frac{x+|x|}{2} $$ ✅优点 计算简单：没有复杂的函数操作，计算速度快。 缓解梯度消失：相比 sigmoid/tanh，ReLU 在正区间的梯度恒为 1，有利于反向传播。 稀疏激活：当输入为负时输出为 0，有助于模型的稀疏性与鲁棒性。 ⚠️ 缺点：死亡ReLU问题（Dying ReLU） ReLU的导数： ![grad of ReLU](grad of ReLU.png) 当输入始终小于 0 时，ReLU 输出恒为 0，对应神经元在训练过程中就“死了”，不再更新权重 2 Leaky ReLU 为了缓解“死亡 ReLU”问题，Leaky ReLU 提出了一种小改动： $$ \\text{Leaky ReLU}(x) = \\begin{cases} x &amp; \\text{if } x \\geq 0 \\ \\alpha x &amp; \\text{if } x &lt; 0 \\end{cases} $$ 其中 $\\alpha$ 是一个很小的常数，通常取值如 0.01。 斜率系数是在训练之前确定的，即在训练期间不会学习。这种类型的激活函数在我们可能遭受稀疏梯度的任务中很受欢迎，例如训练生成对抗网络。 ✅ 优点 解决死亡问题：负值区域有一个小斜率，不会完全丢失梯度。 提升模型鲁棒性：在某些任务中可以提高模型性能。 ⚠️ 缺点 仍然不是零均值输出，可能导致一定的偏移。 引入了超参数 $\\alpha$，需要手动设定或调参。 代码以及可视化 Pytorch 1234import torch.nn as nnrelu = nn.ReLU()leaky_relu = nn.LeakyReLU(negative_slope=0.01) 可视化和对比 1234567891011121314import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-10, 10, 1000)relu = np.maximum(0, x)leaky_relu = np.where(x &gt; 0, x, 0.01 * x)plt.plot(x, relu, label=&quot;ReLU&quot;)plt.plot(x, leaky_relu, label=&quot;Leaky ReLU&quot;)plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)plt.legend()plt.title(&quot;ReLU vs Leaky ReLU&quot;)plt.grid(True)plt.show() 4 总结与选择建议 特性 ReLU（Rectified Linear Unit） Leaky ReLU 数学表达式 f(x) = max(0, x) f(x) = x (x &gt; 0), αx (x ≤ 0), α 通常为 0.01 非线性 是 是 是否允许负值通过 否，负值直接输出 0 是，负值被缩放（αx） 是否容易导致神经元失活 是（“神经元死亡” 问题） 否，可以缓解该问题 计算效率 高（非常简单） 略低（多一个乘法） 使用的超参数 无 需要选择或设定泄漏因子 α 常见使用场景 通用神经网络中默认的激活函数 在出现大量死神经元或训练不稳定时尝试使用 激活函数 推荐使用情况 理由说明 ReLU ✅ 默认优先选择（尤其是简单网络） 计算开销小，效果好，已被大量实验证明有效，是深度网络的标准激活函数。 Leaky ReLU ⚠️ ReLU 出现大量“神经元死亡”时 引入负数区域的非零梯度，有助于避免神经元在训练中“死掉”，提升梯度流动性和收敛稳定性 如果你 初次搭建神经网络模型，建议从 ReLU 开始。 如果你在训练中发现 loss 不下降、部分神经元长期输出为 0，可以尝试切换到 Leaky ReLU。 在一些 对梯度传播更敏感的任务或深层网络中，Leaky ReLU 更能保障梯度不为 0。 为什么不直接一开始就用Leaky ReLU呢？ ReLU更简单，而且计算代价更低。Leaky ReLU中的斜率参数在大规模模型中影响性能。 α作为超参数，在不同任务或数据分布时适合各敏感值，需要调参。","link":"/2025/04/12/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-ReLU-LeakyReLU/"},{"title":"深度学习-Softmax","text":"从概率角度看 Softmax：公式推导、数值稳定性与代码实现 一、引言 在分类任务中，我们常常希望模型输出的是一个概率分布，而非仅仅是 raw logits。Softmax 函数应运而生，它能将任意实数向量“压缩”为概率分布的形式，是神经网络输出层的标配。 转换成概率分布之后的各列别的值分布在0~1的区间中，所有类别的概率和为1. 虽然也是激活函数，但是主要用在输出层（多分类任务中）。 二、Softmax 的数学定义 对于输入向量$\\mathbf{z} = [z_1, z_2, \\dots, z_C]$，Softmax 的定义如下： $$ Softmax(z_i) = \\frac{e^{z_i}} { \\sum_{j=1}^{C} e^{z_j}} $$ 其输出满足两个性质： 所有输出为正： $Softmax(z_i) &gt; 0 $ 总和为 1：$\\sum_i Softmax(z_i) = 1 $ 因此，Softmax 的输出可解释为类别的预测概率。 三、为什么 Softmax 能输出概率分布？ 指数函数保证了非负性 $e^x &gt; 0$ 对任意实数成立。 归一化使得总和为 1 将所有指数值除以总和，即可得到一个合法的概率分布。 可微性 &amp; 梯度友好 Softmax 函数是可导的，便于神经网络训练中的反向传播。 四、数值稳定性问题与解决方法 当 $z_i$ 很大时，$e^{z_i}$容易导致 数值溢出（overflow）。 ✅ 解决方法：减去最大值（不影响相对关系） $$ \\text{Softmax}(z_i) = \\frac{e^{z_i - \\max(z)}}{\\sum_{j} e^{z_j - \\max(z)}} $$ 这样可以有效避免过大指数导致的溢出。 五、代码实现 ✅ Numpy 实现 1234567891011import numpy as npdef softmax(x): x = x - np.max(x, axis=-1, keepdims=True) # 提升数值稳定性 exp_x = np.exp(x) return exp_x / np.sum(exp_x, axis=-1, keepdims=True)logits = np.array([2.0, 1.0, 0.1])probs = softmax(logits)print(probs) # 输出概率分布 Pytorch 1234567import torchimport torch.nn.functional as Flogits = torch.tensor([[2.0, 1.0, 0.1]])probs = F.softmax(logits, dim=1)print(probs) 六、Softmax vs Argmax vs Sigmoid 函数 输出含义 常见用途 是否可导 输出范围 Softmax 多分类概率分布 多分类任务 ✅ 可导 (0, 1)，总和为1 Argmax 最大值的索引 推理阶段，选类别 ❌ 不可导 整数索引值 Sigmoid 每类独立概率 多标签分类、多输出 ✅ 可导 (0, 1) ⚠️ 注意：Sigmoid 用于 多标签任务，Softmax 用于 互斥多分类任务 七、Softmax输出可视化 1234567891011121314151617181920212223import torchimport torch.nn.functional as Fimport matplotlib.pyplot as plt# 输入范围：-5 到 5x = torch.linspace(-5, 5, steps=100)# 构造 3 类 logits：一个随 x 变化，另两个固定（0 和 -x）logits = torch.stack([x, torch.zeros_like(x), -x], dim=1)# 使用 softmax 计算概率（沿类别维度 dim=1）probs = F.softmax(logits, dim=1)# 绘图plt.plot(x.numpy(), probs[:, 0].numpy(), label=&quot;Class 0&quot;)plt.plot(x.numpy(), probs[:, 1].numpy(), label=&quot;Class 1&quot;)plt.plot(x.numpy(), probs[:, 2].numpy(), label=&quot;Class 2&quot;)plt.xlabel(&quot;Input value (logit z)&quot;)plt.ylabel(&quot;Softmax Probability&quot;)plt.title(&quot;Softmax Output vs Input (PyTorch)&quot;)plt.legend()plt.grid(True)plt.show() 当某一类 logit 增大时（比如 x 变大），对应的 softmax 概率也会提高。 而其他类的概率会下降。 Logits 是模型的“原始判断力道” Softmax 是把这些力道转成“概率的形式” 得分高的类别，变成的概率也会高！ Think：为什么不直接对 logits 用 CrossEntropy？ 因为交叉熵定义的是对概率分布的比较： logits 是“未归一化的原始分数” 概率分布要求的是 softmax 后的“归一化值” 所以你不能直接把 logits 当概率用——需要经过 softmax。 不过 PyTorch 为了效率，让你直接传 logits，它内部帮你做了。 本文由GPT指导生成","link":"/2025/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0-Softmax/"},{"title":"激活函数-Sigmoid","text":"理解 Sigmoid 激活函数：公式、特点与应用 基本概念 代码调用 1 什么是Sigmoid？ 一个形状像是躺平的S的平滑函数： $$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$ 输出范围（0，1） 常用于将值映射为概率 1.1 常见场景（与Softmax对比） 🔍 Sigmoid vs Softmax：本质区别 特性 Sigmoid Softmax 输出范围 每个神经元输出范围是 (0, 1) 所有输出加起来为 1 激活方式 对每个输出神经元 单独 使用 Sigmoid 对整组输出向量使用 Softmax 标签之间的关系 互相独立，不排斥 互斥，只能属于一个类别 应用场景 多标签分类（multi-label classification） 多类别分类（multi-class classification） 损失函数 Binary Cross Entropy Categorical Cross Entropy 输出解读 每个标签为“是/否”的概率 所有类别中选择概率最大的一个作为预测类别 Sigmoid会将每个标签的raw结果独立转化为概率，所以能得到多个标签的值。 BCE：多标签分类，常与Sigmoid一同使用，对每个标签独立做的二分类损失。nn.BCELoss() + Sigmoid() CE: 多个类别中 只能选一个，常配合 Softmax 使用。Pytorch 中CE的包含了softmax 2 sigmoid的代码以及可视化 Numpy实现 123456789101112# 可选Python绘图代码示例（可在Jupyter中运行）import numpy as npimport matplotlib.pyplot as pltx = np.linspace(-10, 10, 100)y = 1 / (1 + np.exp(-x))plt.plot(x, y)plt.title(&quot;Sigmoid Function&quot;)plt.xlabel(&quot;x&quot;)plt.ylabel(&quot;σ(x)&quot;)plt.grid()plt.show() Pytorch调用 12345678910import torchimport torch.nn as nn# 假设 batch_size = 2，有 3 个标签logits = torch.tensor([[0.2, -1.5, 3.0], [0.8, 0.4, -2.0]]) # 模型输出的 raw logits# ✅ 使用 sigmoid 将每个标签输出转为概率（独立计算）sigmoid = nn.Sigmoid()probs = sigmoid(logits)print(&quot;Sigmoid 概率输出：\\n&quot;, probs)","link":"/2025/04/14/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0-Sigmoid/"},{"title":"留学日记-1","text":"23年7月4日到达日本，现在已过去4天，简单记录一下。 路还是要亲自走走，才知道难与否。 伴随互联网的发展，入境日本填写纸质申报单已经不是必要的事情了，可以在 Visit Japan Web上提前申请，得到黄色和蓝色的QR码，截图保存，就可以丝滑入境。 到达日本后，成田机场的工作人员非常的耐心，他们大多都是年长的叔叔阿姨，只会说几个简单的英语单词。 不用担心听不懂看不懂的问题，翻译+手势足以。 我走的留学生通道，带上自己的护照、语校录取通知和外出申请书（打工用的申请），交给审查官，就可以办下暂时没有住址的在留卡。在留卡的上面会写明是否能打工的申请。 入境的检查也没有那么严格，扫码（VJW的码）后，询问了几句就放人了。主打一个自觉。 离开机场，非常感谢我的叔叔大老远来接我，还送我去我租的房子，帮我收拾了一下亚马逊下单的床上用品，带我吃了个晚饭，我才能在第一天还有人样，不至于累的要死还不知道咋办也不敢进饭店吃饭在房间里面哭。 叔叔带我吃的拉面，是干拌面那种拉面，我说不上来像国内的哪种，比甜水面细一点的粗面，以及日本的酱油味和他们的叉烧，加上几个鸣人卷和几片海带，味道很独特，就是我到日本的第一顿饭。 为了找到能停车能吃饭的店，叔叔带我在城里绕了好久。 这里并没有给我一种先进或者发达的感觉，仿佛一切都停止在了二十世纪初，倒是哪些霓虹灯、刷卡支付、机器点单让我感受到突兀，与周围的老旧环境格格不入。 还有就是，小、窄、挤、严格和收费真他妈贵。 一切都像是中国的0.75倍：街道、车子、房子、立交桥…… 但是规矩是那么严格，路上不能停车，而且到处没有停车位，因为这边土地实在是太少了。店面也是那么的小，可能就三五十左右平方的用餐区，堆放六七八九个餐桌。那么晚了警察都会在立交桥追着超速的车跑，路边没有停车位，有也会严格设置你可以停放的时间和停放车辆的类型，好多车位是给店铺卸货用的。 路上的行人也大多都是靠左走，男的穿西装，女的穿碎花长裙。 三三两两的行人，偶尔经过的车辆，我好像与这个城市格格不入。 第二天还什么都不会就要去语校报道。 谷歌你能不能优化一下导航 我跟着谷歌map，走错了路…… 错过了车站入口，大着胆子拉了一个路人问了路，那个姐姐很好，一边比划一边跟我说怎么走，只是我只听懂了前面路口要左转…… 神奇的是找到车站了……甚至是对的入口。 但是不知道怎么看车子的方向，坐反了，愚蠢的我坐反了还出站了，痛失180日元。 一路磕磕绊绊到了学校的本馆，被告知我在新馆上课，感谢中国兄弟带路。 迟到了，但是跟老师说明后被原谅了。 那天是大家第一次上课，我虽然错过了开学会，但是还好没有错过我们班的第一节课。 有的人是中级班升上来的，有的则是和我一样，刚入学。 我们班全是中国人，不愧是优秀的大家。 做自我介绍的时候，我彻底懵了，都是中国人，干嘛把自己的名字日语化？？？下来愣是一个人没记住，就记住了大家的志愿。 后来我懂了，老师不会念我们的名字，为了方便老师，也或许为了以后给本地人做自我介绍的时候方便吧。 课程很简单，进度很慢，甚至比不上我在国内为了备考的时候自学的效率，但是老师全程日语讲课，给了我很多机会学习他们的表达。 而且，语法稀烂的我，在这个龟速教学下多少开始学着怎么去理解不同的语境下的表达了。 下课后，办了学生证，结识了另外两个班的也是刚到日本的同学，加了好友。她们住在学校宿舍。 宿舍就是好啊，可以一下子交到朋友，家具什么的也都配齐了。我现在孤身一人，一无所有。 学校的事情办完了之后，不敢去吃饭，不敢上街，在大厅里面呆呆地等中介带我办手续。 我不知道他会不会坑我，但是我除此之外无依无靠，毕竟不可能麻烦在工作的叔叔大老远的带我办这些事情。 理论上说，这些一个人也该能办的。 但是我就是怕。 怕说不好，怕做错事，怕被骗，怕自己问的太多被人嫌弃。 我没有那么强大的内心，也没有那么多的试错成本。 这天办事情没那么顺利，说最近来的中国人太多了，处理不过来，窗口关了许多。 中介说他这么久，从来没遇到过这种情况，问我飞机上是不是很多留学生。 我说：具体不太清楚，但是据说我这班机是因为来日本的人太多了，加的航班。 最近的国际形势并不和谐，日本排放核废水就是在这个夏天。 我问中介，你在日本生活这么久，对这个怎么看。 他说：你看看来日本的是变多了还是变少了呢？ 我不知道具体的数据，但是看登记所的情况，这个夏天人肯定是不少的，我们只是七月生。 认识了很有趣的朋友。 今日宜交友 首先是班上的同学，奇迹的是我们住在一个街区，相隔5min路程。 她带我知道了好多百元店，我之前只知道大创，带我吃饭，带我找路。 下午自己去办理手机卡，又结识了一个来自都匀的朋友，也是相聊甚欢。 晚上班上的同学和她对象带我在街区走了好久，认识了一下周围的情况，听了好多故事和生活技巧，很是感谢。相约第二天一起去上学。 一个人的生活好像没有那么孤单了。 七月七日是日本的七夕，老师介绍了他们这边的七夕的来源，中国。 他们对于来自中国的文化和习惯都是大大方方的承认，也对自己文化中特有的部分感到自豪。 说起这个，我们学习汉字的时候，老师们的态度真的很有趣。经常会说：“哎，你们都是中国人，这个应该很简单吧。“ 然后开始讲一些特殊意义和读法。 老师，我们写确实是会写的，但是读是读不准的，你们一个汉字根据不同的情况有不同的读音，不是一两个是三四个，我们很懵逼。 所以还是能学到不少东西，虽然是汉字。 下午，我终于在各种犹豫+询问+大胆与大爷店员交流，通过翻译软件+蹩脚的日语+手舞足蹈买到了我的窗帘。 真好，我也是有窗帘的人了。 这几天一直都是纸板贴墙+叔叔的猫猫的毯子保护我的隐私。 谢谢纸板，谢谢猫猫。 这里的设计还真是好啊，很多都是统一的或者兼容性很高的尺寸和配件，让我的shopping没有那么难过。 记得家里的窗帘每次安装我都生不如死筋疲力尽，这边安装窗帘真的丝滑，小房子真好。 晚上叔叔来帮我把床板搭了起来，申请了邮局的银行卡，带了吃的给我，我好像又可以活几天了~真开心 (●’◡’●) 床++ ， 垃圾++。 现在还是乱七八糟，还有好多事情没做，虽然不知道赶不赶得上考试……但是一切都在慢慢走向正轨。 一个人生活还真是不容易。 这几天生活下来我算是知道了为什么日本人安静、喜欢整洁，做事规矩。 鄙人浅薄的见解 小，太小了。 房间稍微有一点点杂乱，就会非常明显。 声音稍微大一点，自己都觉得吵闹。 稍微走快一点，就很容易撞到别人。 所以要靠左行，自己急着前走挤着路上慢慢走的人要稍微表示歉意。 所以要小声说话，别影响到别人，说话声音刚刚好能交流就行。 所以东西都不便宜，地小人多。 以前只是网上看到，但是来了之后，切实生活在其中，才真正领会到这些东西。","link":"/2023/07/08/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-1/"},{"title":"留学日记-2","text":"来这边一周多了，再来记录一下自己的生活。 日本真的生活起来很舒服吗？ 我的小家 现在租的这个小房子总算有了点人类居住所的感觉了。 添置了桌椅、冰箱、洗衣机、热水壶和电饭煲。但是我的厨具还没有到，锅碗瓢盆一个没有。 上次去百元店本来想买个刀和菜板的……才反应过来刀需要刀架，菜板得有地方放。我那个狭小的地方，哪里来的空间放这些东西，总不能放在头顶的厨柜里面吧。 做饭啥的还不急，慢慢来吧。 家里的垃圾还是堆在那里，这边的垃圾分类，要说多复杂，到好像也没有，但是有这么个流程，总归是麻烦的。 因为要处理垃圾，我买东西欲望都降低了，全是生存的欲望导致我购买食物和水。 别的则是能不买，就不买了。 在语校 这周的课程依旧不是很难，虽然每次都会涉及到完全陌生的知识点，全程日本老师纯日语上课，用他们的理解为我们讲解哪些词语和文法。 今天做了个小考试，在手机上使用谷歌classroom软件完成。 手机做卷子嘛，都懂的。 不得不说，这种成绩高低无所谓，重要的是自己学会了这个知识点没，无关利益的感觉真好。 虽然，确实这样会导致我的学习非常的敷衍。 我的社交 出了最开始在班上找到的和我住很近的女生，以及某次排队认识的两个别的班的女生，我又认识了几位朋友。 当然都是女生。 在班上又认识了一位本科学习油画的朋友，现在准备攻读这边的插画专业。 然后通过别的班的那两位同学，又认识了她们宿舍的同学。 大家都是来这边考大学院的，文科或艺术专业。（目前遇到的艺术最多，其次社科，最后是理工科。数据仅参考我的身边。） 理工科我现在只知道我们班上有一个学机器人的，和一个学电气的。 我现在经常和那群宿舍的同学们一起出去吃饭，我们都冲着好吃且便宜的餐馆去。虽然这几次我们去的餐厅都不便宜。 这边我知道的最便宜的是松屋，最便宜的套餐，肥牛盖饭+生菜沙拉和一碗味增汤是420日元左右（21RMB），贵的当然也有八九百日元的套餐。还有个SAIZERIYA，西式的餐厅，最便宜的焗饭320日元。 这几天，跟着这几位同学去了书店，去了文具店。唯有书店的漫画书的价格还较为亲民，我看到《暗杀教室》的漫画单行本110日元（5RMB），有的是220日元。但是文具店也是一支笔好几十。 不得不说，从国内带文具是多么的明智，自动铅笔成了我不得不用的选择。因为笔芯便宜，还可以修改。 同样的斑马、百乐，甚至是我喜欢的白金钢笔，都比国内的价格高上一些，谢谢国内的商家没有涨价，谢谢晨光得力的一路护航，不然这书我是真的读不起。 现在认识了这么些朋友，虽然我们每天只有短暂的交流时间，但是让我孤独的学校生活好上了不少，非常感谢。 我的生活 现在基本上开始了两点一线的生活。 早上八点过一点出发去车站，到学校上课，上了课后和同学吃个饭，再去采买一些东西，回家。晚上大部分是靠着便利店的食物过活。 下午这两天主要是收拾东西，学习什么的，甚是惭愧，还没有起步。 就是这样简单的生活，或许也有最近几日的高温天气影响，回到家后就已经筋疲力尽。 不过现在要开始了，一边收拾屋子，一边看论文，一边复习我的课程。 好像我的生活很无聊，没有那些留学生的精彩灿烂。 说实话，这边物价这么贵，大学院也还没有考上，生活还是一团乱麻。 我第一次自己一个人handle所有的一切，在照顾自己好好生活上好像也没有什么经验和才能，唯一能松一口气的也就是经济还是靠着家里的支持（感谢我的爸爸妈妈）。 很多时候我回到家，打开门看到乱糟糟空荡荡的房间，心里面都沉沉的，我好像很难过，但是又没有难过到想哭，放下书包打开空调，也就这样了。 我好像有什么事情想说给什么人听，但是又好像没什么说的必要，也不知道该说给谁。 我也想出去走走，但是家里还那么乱，书还没有打开，出去妈的坐一趟地铁起步价9RMB，太阳仿佛要把人晒穿，算了算了。 打车？记得昨天准备去一个比较远的地方看看台灯（结果并没有买到，还走了一个多小时的路），做地铁就190左右的日元，如果打车大概是10倍的价格（数据来自谷歌打车价格计算） 虽然家里吹空调也贵。 这边，感觉做啥都束手束脚。 走路必须要随大流靠左，路太窄了稍微走随意一点就可能撞到人。 吃个饭都安安静静（大部分的店），然后店里面也窄得很。 吃饭贵，买东西贵，东西还买不到。 我不熟悉这边该去那里买需要的东西，只知道自己认识的那几个小店。大点的店，东西就不是一两倍的贵了。 网购，东西少，还贵，还撇。国内更好的配置，更低的价钱，这边的电商……好吧，有总比没有好，不然现在我还在奔波于买生活用品。 我点名表扬：淘宝、京东、拼多多。亚马逊你是什么品种的垃圾。（可能有些粗暴了，但是是真情实感） 我知道这有点那种，端起碗吃饭放下碗骂娘。 来说说使用体验吧： 首先是东西的丰富度：亚马逊完败。然后是页面的展示，网页版：亚马逊很简陋且，产品信息混乱，每次看一个新的东西，详细信息要用放大镜看才看得清，手机版：有一种怼在我脸上的美。功能上：送货要想免费就用时间换，无法跟踪详细物流信息，只能知道非常粗糙的信息。 要说好处，听说亚马逊买东西，评分的信任度很高，不用担心刷分，还有就是下单的时候说几号到就真的是几号到，京东或许可以达到这个效果，但是淘宝和拼多多，菜鸟驿站的时间不一定可以如此准时。 还有什么可以聊聊呢…… 说一些网上流传的对日本的印象，以及我经历的亲身体验吧。 首先是日本街道、河道真的那么干净么？路上看不到垃圾桶？ 说不上一尘不染，但是真的干净。走在路上给人一种干净整洁的感觉。之前去秋叶原路上路过了一条河，确实是没有垃圾漂浮。 也确实，很难找到垃圾桶。但是通常可以在贩卖机、便利店、超市和餐馆的背后找到垃圾桶，请注意也是需要分类的。别丢错了。 日本人讲规矩，什么红绿灯没人都是按规矩走。 不守规矩的人哪里都有。守规矩的肯定是大多数。 办事效率低 真。刚来日本需要办理在留卡的居住证明，由于这个月前来居住的外国人过多所以不少地方窗口都限时了，只能上午办理（我不理解）。我好不容易找到一个能办理这个手续的分局一样的地方。那个人叫我填了一张纸，也就是一些简单的个人信息。顺便办了普通的国民健康保险。从到我，等了半个多小时，到办完，花了一个半小时……俺也不明白就几行字，他在那个玻璃墙后面到底在干嘛搞了那么久。 地铁安静 真。我都不敢打电话，和朋友说话都是把声音压倒极低。 这里的地铁没有安检，前几天和大学同学聊到这个问题。这确实提高了通勤效率，但是也确实导致了几次大型恶性事件犯人行凶时的一路畅通。 服务好 我不知道日本人心里在想什么，但是作为客人，我很的感受到了他们的贴心和温柔，这就足够了。 目前差不多是这些。 接下来就不是我亲自经历的事情了，说一下我的朋友们分享在朋友圈的或是讲给我听的他们的故事吧。 我在手机店认识的那个很漂亮的女生，遇到了搭讪的大爷，邀请她去喝茶；遇到了一些大叔上下盯着她打量，说她可爱。走过了一条全是牛郎的街道。 我一个朋友，去了一家中餐厅，那里的老板对日本人点头哈腰，对中国人爱答不理，甚至优先给日本人上菜。 这个朋友的老师，买东西的时候，租房的时候，办手机卡的时候，被中国人坑，导致银行卡信用卡无法正常使用，签证可能都会受到影响。 希望大家都能远离这些不愉快。还有就是中国人别骗中国人。 嗯，虽然还有很多麻烦的事情没有处理好、等着做，但是好歹是一步步开始走上正轨（也真的花了很多的钱）。算不上高效，也有很多时候在摆烂，在emo，在睡觉，往前总是好的。 现在开始看书了，又会遇到很多的困难吧，害，除了努力好像也做不了别的什么，加油咯。 放几个图吧，导都导进来了： 拉面哦，720日元 一条街","link":"/2023/07/13/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-2/"},{"title":"留学日记-3","text":"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 Hey, password is required here.","link":"/2023/11/18/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-3/"},{"title":"留学日记-4","text":"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 Hey, password is required here.","link":"/2024/03/18/%E7%95%99%E5%AD%A6%E6%97%A5%E8%AE%B0-4/"},{"title":"留学记录-5","text":"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 Hey, password is required here.","link":"/2024/06/11/%E7%95%99%E5%AD%A6%E8%AE%B0%E5%BD%95-5/"},{"title":"笔记本电脑部署BitNet","text":"BitNet是微软在2025年发布的，可以在CPU上运行的本地大模型。 之前在电脑上配置的wsl终于有了用武之地，成功在ubuntu上完成了部署。本文将介绍部署方法并进行效果展示。 一、简介 BitNet是第一个支持在CPU上进行推理的LLM。 本机环境 Win11下的wsl2。安装教程可查看之前的博客。 我的电脑： CPU：AMD Ryzen9 7940H GPU：NVIDIA GeForce RTX 4060 Laptop GPU 二、部署 按照repo中的readme进行部署，不过我个人推荐在linux下操作，因为如果是win，会强制下载Visual Studio，这个软件需要的存储空间大，而且万一哪里点漏了需要重来，Linux上几行命令就可以搞定。 如果本来就在高强度使用visual studio就当我没说。 WSL（Ubuntu）准备 可参考博客 git pip conda README——简略中文版（Linux） 操作照搬官方仓库的readme，部分地方进行中文翻译。 Requirements python&gt;=3.9 cmake&gt;=3.22 clang&gt;=18 就是这个clang，在win上必须要下载visual studio2022，我拒绝。但是ubuntu简单 下载clang 1bash -c &quot;$(wget -O - https://apt.llvm.org/llvm.sh)&quot; 说明：下载安装并执行 LLVM 官方提供的安装脚本，常用于在 Ubuntu 或 Debian 系统中安装 LLVM 工具链（如 clang、lld 等） 这些软件包提供 LLVM + Clang + compiler-rt + polly + LLDB + LLD + libFuzzer + libc++ + libc++abi + openmp + libclc + libunwind + MLIR + BOLT + flang + libc + wasm 支持。 没成功安装也没关系，我好像就没有成功，后续手动安装了clang…… Build from source wsl：进入自己的用户（有sudo权限的）和对应的空文件夹。 1. Clone the repo 12git clone --recursive https://github.com/microsoft/BitNet.gitcd BitNet 2. Install the dependencies 12345# (Recommended) Create a new conda environmentconda create -n bitnet-cpp python=3.9conda activate bitnet-cpppip install -r requirements.txt 后续需要cmake，可用cmake --version命令先检查。没有的话就执行: 12sudo apt updatesudo apt install cmake 3. Build the project 123# Manually download the model and run with local pathhuggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4Tpython setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s 说明： 从 Hugging Face 下载 BitNet-b1.58-2B-4T-gguf 模型文件，并保存到你本地的 models/BitNet-b1.58-2B-4T 文件夹中。 使用 setup_env.py 脚本，基于本地路径下的 BitNet 模型，准备并编译运行环境，用于后续高效推理。 1234567891011121314151617181920212223242526272829usage: setup_env.py [-h] [--hf-repo 模型仓库名] [--model-dir 模型目录] [--log-dir 日志目录] [--quant-type 量化类型] [--quant-embd] [--use-pretuned]Setup the environment for running inferenceoptional arguments: -h, --help 显示帮助信息并退出 --hf-repo {1bitLLM/bitnet_b1_58-large,1bitLLM/bitnet_b1_58-3B,HF1BitLLM/Llama3-8B-1.58-100B-tokens, tiiuae/Falcon3-1B-Instruct-1.58bit,tiiuae/Falcon3-3B-Instruct-1.58bit, tiiuae/Falcon3-7B-Instruct-1.58bit,tiiuae/Falcon3-10B-Instruct-1.58bit}, -hr {同上} 要用于推理的模型（从 Hugging Face 下载） --model-dir MODEL_DIR, -md MODEL_DIR 模型保存或加载的本地目录 --log-dir LOG_DIR, -ld LOG_DIR 保存日志信息的目录 --quant-type {i2_s,tl1}, -q {i2_s,tl1} 模型的量化类型（如：i2_s 表示 2-bit 对称量化） --quant-embd 是否将嵌入层量化为 float16（f16） --use-pretuned, -p 是否使用已预调优的底层内核参数（提高性能） 如果前面的LLVM成功安装的话，这里不会有任何报错。 如果失败，需要手动下载clang。 失败提示： 1clang --version 提示无命令 安装clang 1sudo apt install clang clang 是必要的，无法通过gcc绕过。 三、Usage 用法 Basic usage 12# Run inference with the quantized modelpython run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p &quot;You are a helpful assistant&quot; -cnv 说明 12345678910111213141516171819run_inference.py [-h] [-m MODEL] [-n N_PREDICT] -p PROMPT [-t THREADS] [-c CTX_SIZE] [-temp TEMPERATURE] [-cnv] -h, --help 显示帮助信息并退出 -m MODEL, --model MODEL 模型文件的路径 -n N_PREDICT, --n-predict N_PREDICT 生成文本时预测的 token 数量 -p PROMPT, --prompt PROMPT 用于生成文本的提示词 -t THREADS, --threads THREADS 使用的线程数量 -c CTX_SIZE, --ctx-size CTX_SIZE 提示词上下文的长度 -temp TEMPERATURE, --temperature TEMPERATURE 温度系数，控制生成文本的随机程度 -cnv, --conversation 是否启用对话模式（用于 instruct 模型） （启用时，-p 指定的 prompt 会作为系统提示词） 执行完之后就可以继续对话了。 说实话看起来笨笨的，之后再慢慢研究。 四、 权重版本总结 让GPT根据hugging face 部分的命令提供的注释，总结了仓库中提供的权重： 模型 权重大小 使用场景 精度 下载命令 1bitLLM/bitnet_b1_58-large 大 高精度推理任务，复杂语言任务处理 高 huggingface-cli download 1bitLLM/bitnet_b1_58-large --local-dir models/bitnet_b1_58-large 1bitLLM/bitnet_b1_58-3B 3B 大规模语言理解，复杂的推理任务 极高 huggingface-cli download 1bitLLM/bitnet_b1_58-3B --local-dir models/bitnet_b1_58-3B HF1BitLLM/Llama3-8B-1.58-100B-tokens 8B 大规模数据处理，长文本生成和理解 极高 huggingface-cli download HF1BitLLM/Llama3-8B-1.58-100B-tokens --local-dir models/Llama3-8B-1.58-100B-tokens tiiuae/Falcon3-1B-Instruct-1.58bit 1B 指令型任务，如问题回答、文本生成 高 huggingface-cli download tiiuae/Falcon3-1B-Instruct-1.58bit --local-dir models/Falcon3-1B-Instruct-1.58bit tiiuae/Falcon3-3B-Instruct-1.58bit 3B 指令型任务，要求较高的精度 高 huggingface-cli download tiiuae/Falcon3-3B-Instruct-1.58bit --local-dir models/Falcon3-3B-Instruct-1.58bit tiiuae/Falcon3-7B-Instruct-1.58bit 7B 需要更强推理能力的指令型任务 极高 huggingface-cli download tiiuae/Falcon3-7B-Instruct-1.58bit --local-dir models/Falcon3-7B-Instruct-1.58bit tiiuae/Falcon3-10B-Instruct-1.58bit 10B 高精度指令型任务，大规模文本生成 极高 huggingface-cli download tiiuae/Falcon3-10B-Instruct-1.58bit --local-dir models/Falcon3-10B-Instruct-1.58bit microsoft/BitNet-b1.58-2B-4T-gguf 2B 资源受限环境，性能和精度之间的平衡 高 huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T 总结： 可以直接在 BitNet 上运行 的模型是 BitNet 系列 的模型（如 bitnet_b1_58-large 和 bitnet_b1_58-3B）以及 microsoft/BitNet-b1.58-2B-4T-gguf 这样的变体。 其他模型，如 Llama3 和 Falcon3，虽然可能可以在 BitNet 上运行，但需要额外的适配或转换，具体取决于模型格式、量化方式和框架支持。 五、配置其他更大权重（GPT整理，尚未尝试） 如果你想在 BitNet 上下载并运行一个更高精度的模型，可以选择 BitNet 系列中更大的模型。例如，选择 bitnet_b1_58-large 或 bitnet_b1_58-3B，这些模型具有更大的参数量，因此可以提供更高的精度。 以下是下载和配置这些更高精度模型的完整命令： 1. 下载更大的 BitNet 模型： 选择 bitnet_b1_58-large 或 bitnet_b1_58-3B 作为目标模型。你可以使用 Hugging Face CLI 下载。 下载 bitnet_b1_58-large： 1huggingface-cli download 1bitLLM/bitnet_b1_58-large --local-dir models/bitnet_b1_58-large 下载 bitnet_b1_58-3B： 1huggingface-cli download 1bitLLM/bitnet_b1_58-3B --local-dir models/bitnet_b1_58-3B 2. 设置 BitNet 环境： 下载完模型后，你需要设置环境，并选择适合的量化方式（例如 i2_s）。以下命令会将模型配置好并进行量化优化。 配置命令： 1python setup_env.py -md models/bitnet_b1_58-large -q i2_s 或者对于 bitnet_b1_58-3B 模型： 1python setup_env.py -md models/bitnet_b1_58-3B -q i2_s -md 选项指定了本地模型路径。 -q 选项指定了量化方式，i2_s 是一种优化的量化类型，你也可以使用 tl1（具体选择取决于你的硬件和性能需求）。 3. 运行推理： 配置好模型之后，你可以使用 python 来运行推理任务。以下是一个简单的推理示例命令： 1python inference.py -m models/bitnet_b1_58-large/ggml-model-i2_s.gguf -p &quot;Your input prompt here&quot; -n 128 或者如果使用 bitnet_b1_58-3B 模型： 1python inference.py -m models/bitnet_b1_58-3B/ggml-model-i2_s.gguf -p &quot;Your input prompt here&quot; -n 128 -m 选项指定了模型文件路径。 -p 选项是你要输入的提示文本。 -n 选项指定要生成的 token 数量。 4. 配置日志和输出目录（可选）： 如果你希望指定日志目录或输出目录，可以使用以下命令： 1python setup_env.py -md models/bitnet_b1_58-large -q i2_s -ld /path/to/logs -ld 选项指定了日志输出目录。 5. 配置更多高级选项（可选）： 如果需要进行预调优或使用其他量化选项，可以在命令中添加更多参数。例如： --use-pretuned：使用预调优的内核参数（如果有）。 --quant-embd：将嵌入量化为 f16。 例如： 1python setup_env.py -md models/bitnet_b1_58-large -q i2_s --use-pretuned --quant-embd 总结： 选择更大的模型：下载 bitnet_b1_58-large 或 bitnet_b1_58-3B。 设置环境并量化优化：使用 setup_env.py 设置模型并选择量化方式。 运行推理：使用模型进行推理。 这样，你就可以运行更高精度的 BitNet 模型，并根据需求调整性能和精度。","link":"/2025/05/12/%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%94%B5%E8%84%91%E9%83%A8%E7%BD%B2BitNet/"},{"title":"自动执行多个终端命令-Python","text":"深度学习实验，后期有许多要交叉验证或者需要多对比的实验，一个一个在终端修改命令参数再执行太麻烦了，可以用subprocess的方法，在某文件中录入所有需要执行的命令，程序自动书序读取执行。 一、需求分析 在科研或开发过程中，我们经常需要批量执行多个实验命令，比如训练多个模型、不同参数组合的对比实验等。而手动逐个运行不仅麻烦，还容易出错，尤其当某些命令执行失败需要重试的时候。 为了解决这一痛点，该脚本的目标是： 从文件中批量读取命令 逐个执行，并记录日志 若命令执行失败，支持自动重试 实时输出运行状态 简而言之，这是一个批处理实验命令的执行器，适合用于科研实验或部署任务中。 二、整体结构梳理 代码核心结构分为三部分： 函数名 功能说明 log(message) 统一日志记录函数，打印并写入日志文件 run_command(command, index) 核心命令执行逻辑，支持实时输出和自动重试 main() 主流程：读取命令文件，循环执行每条命令 全局变量设置了日志文件路径、命令文件路径、最大重试次数。 这里，假设需要运行的脚本的名称是train.py,参数通过命令传入。你需要对模型、batch size、数据集路径和其他超参数进行组合测试： 假设需要以下参数支持： 123456789--model：模型结构名称，如 UNet, TransUNet, SwinUNet--batch_size：批大小--lr：学习率--trainset、--validset、--testset：数据集路径--epochs：训练轮数（可选） 那我们可以把顺序读取命令的文件experiments_auto.txt内按照如下方式记录：每一行一个命令。 12345python train.py --model UNet --batch_size 8 --lr 0.001 --trainset ./data/fold1/train --validset ./data/fold1/valid --testset ./data/fold1/test --epochs 100python train.py --model UNet --batch_size 16 --lr 0.0005 --trainset ./data/fold2/train --validset ./data/fold2/valid --testset ./data/fold2/test --epochs 100python train.py --model TransUNet --batch_size 8 --lr 0.001 --trainset ./data/fold1/train --validset ./data/fold1/valid --testset ./data/fold1/test --epochs 100python train.py --model TransUNet --batch_size 16 --lr 0.0005 --trainset ./data/fold2/train --validset ./data/fold2/valid --testset ./data/fold2/test --epochs 100python train.py --model SwinUNet --batch_size 8 --lr 0.0001 --trainset ./data/fold3/train --validset ./data/fold3/valid --testset ./data/fold3/test --epochs 100 三、代码细节解析 1. CMD_FILE 与 LOG_FILE 123CMD_FILE = 'experiments_auto.txt'LOG_FILE = 'experiment_log.txt'MAX_RETRIES = 3 experiments_auto.txt：你要提前准备的命令清单文件，每一行一个命令。 experiment_log.txt：用于记录命令运行时的所有输出和状态。 MAX_RETRIES = 3：每个命令失败后会最多尝试 3 次。 2. 日志函数：log(message) 12345def log(message): timestamp = time.strftime('%Y-%m-%d %H:%M:%S') full_message = f&quot;[{timestamp}] {message}&quot; print(full_message) ... 打印带时间戳的信息 同时写入到 LOG_FILE 保证运行过程中出现的每一条信息都能被追踪和复现 3. 执行器：run_command(command, index) 这是脚本的核心逻辑部分，关键点如下： 1process = subprocess.Popen(...) 使用 subprocess.Popen 启动命令，支持实时读取输出流 使用 stdout=subprocess.PIPE + for line in process.stdout 实现输出实时打印效果 成功执行后返回 True，失败最多重试 MAX_RETRIES 次 12if process.returncode == 0: log(f&quot;成功执行第 {index+1} 条命令。\\n&quot;) process.returncode 用来判断命令是否成功退出（0 表示成功） 失败则进入 except subprocess.CalledProcessError 分支，写入失败日志并重试 4. 主流程：main() 12if os.path.exists(LOG_FILE): os.remove(LOG_FILE) # 清空旧日志 运行前清空日志文件，确保这次实验结果是干净的 12with open(CMD_FILE, 'r', encoding='utf-8') as f: commands = [line.strip() for line in f if line.strip()] 从文件中读取命令，并清洗空行 遍历所有命令，调用 run_command 四、使用说明 1. 准备命令文件 创建一个名为 experiments_auto.txt 的文件，每一行写一条你希望执行的命令，例如： 123python train.py --config config1.yamlpython train.py --config config2.yamlpython evaluate.py --model model1.pth 2. 运行脚本 直接运行： 1python run_multi_experiments.py 然后你会看到控制台和 experiment_log.txt 文件中有实时输出。 完整代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&quot;&quot;&quot;@Project Name: @File Name: run_multi_experiments@Author: @Created: 2025/4/18 14:17@Version: 1.1@Description: 带日志记录与实时输出的多命令运行器，支持自动重试&quot;&quot;&quot;import subprocessimport timeimport osCMD_FILE = 'experiments_auto.txt'LOG_FILE = 'experiment_log.txt'MAX_RETRIES = 3def log(message): &quot;&quot;&quot;写入日志并打印到控制台&quot;&quot;&quot; timestamp = time.strftime('%Y-%m-%d %H:%M:%S') full_message = f&quot;[{timestamp}] {message}&quot; print(full_message) with open(LOG_FILE, 'a', encoding='utf-8') as log_f: log_f.write(full_message + '\\n')def run_command(command, index): &quot;&quot;&quot;尝试执行命令，支持自动重试和实时输出&quot;&quot;&quot; for attempt in range(1, MAX_RETRIES + 1): log(f&quot;第 {index+1} 条命令：尝试第 {attempt} 次运行：{command}&quot;) try: process = subprocess.Popen( command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True, bufsize=1 ) with open(LOG_FILE, 'a', encoding='utf-8') as log_f: for line in process.stdout: print(line, end='') # 实时打印 log_f.write(line) # 同时记录日志 process.wait() if process.returncode == 0: log(f&quot;成功执行第 {index+1} 条命令。\\n&quot;) return True else: raise subprocess.CalledProcessError(process.returncode, command) except subprocess.CalledProcessError: log(f&quot;命令执行失败（第 {attempt} 次）&quot;) if attempt &lt; MAX_RETRIES: time.sleep(5) else: log(f&quot;第 {index+1} 条命令在 {MAX_RETRIES} 次尝试后仍失败，跳过该命令。\\n&quot;) return Falsedef main(): if os.path.exists(LOG_FILE): os.remove(LOG_FILE) # 每次运行前清空旧日志 with open(CMD_FILE, 'r', encoding='utf-8') as f: commands = [line.strip() for line in f if line.strip()] log(&quot; 实验开始运行...\\n&quot;) for idx, cmd in enumerate(commands): run_command(cmd, idx) log(&quot;所有命令执行完毕。\\n&quot;)if __name__ == &quot;__main__&quot;: main() 五、总结 这个脚本简单实用，是科研或开发中批量执行命令的好帮手。它结合了日志记录、实时输出、失败重试等功能，可靠性强、可读性高，非常适合做成通用工具或集成进自己的项目中。 现在其实还有一些深度学习管理平台可以可视化编辑每次运行的超参数，等以后学到了之后补充。","link":"/2025/04/20/%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E5%A4%9A%E4%B8%AA%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4-Python/"},{"title":"贝叶斯与频率派","text":"准备开始阅读《概率论沉思录》，但是数学忘得差不多了。 之前在看B站的《机器学习-白板推导系列》的时候，开篇up对贝叶斯和频率派进行了简单的讲解，彼时就勾引起了我的兴趣，但后来没有坚持学习下去，这些概念也就抛之脑后了。 现在借着看书的契机，打算好好学习一下这个自己最感兴趣的数学领域。 先从这里开始吧. 找到一个可视化数学概念的网站： Seeing-theory 统计学中的两大派系:频率学派(Frequentist)、贝叶斯学派（Bayesian） 自从接触到数学之后，我总是在幻想，我们是不是可以通过一套非常严谨的数学公式，模拟出这个世界的运行规律？ 其中概率是我直觉上感觉最为有可能找到这个规律的工具。从机器学习的发展来看，或许真的有这么一天吧（笑）。 把这个想法践行到极致的，或许就是统计学的学者们。 统计推断中有两种主要的方法：频率论和贝叶斯，区别在于他们对不确定性的解释不同。[1] 这两个学派的争论也持续了多年，甚至牵扯到了哲学和意识形态上的争论[2]。 《概率论沉思录》的作者E.T.Jaynes是坚定的贝叶斯支持者，现在贝叶斯的优越性已经在上百个领域中得到充分的验证。 但作为一个数学小白，我想首先我应该去总结了解一下频率派和贝叶斯之间的区别。 频率派（Frequentist） 核心观点 事件的概率就是无限重复实验中发生的频率。这个概率函数的参数是固定但未知的常数。 概率模型 假设$X$ 是数据，$\\theta$是参数： $$ X = \\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1P} \\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2P} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ x_{N1} &amp; x_{N2} &amp; \\cdots &amp; x_{NP} \\end{bmatrix} $$ $X$服从一个概率模型： $$ x \\sim p(x|\\theta) $$ 在频率派中，他们认为这个$\\theta$是一个未知的常量，而$X$是随机变量（r.v）。他们关心的是数据，需要把这个$\\theta$估计出来，最常用的就是最大似然估计[3]。 最大似然估计：常用的估计概率模型参数的方法：在所有可能的参数中，找出最有可能“生成”我们观察到的数据的那一组参数。 一般形式 $$ \\hat{\\theta}{\\mathrm{MLE}} = \\arg\\max{\\theta} p(x \\mid \\theta) $$ 找到一组参数$theta$,使似然函数$p(x|\\theta)$最大化，也就是找到“最可能”生成数据x的参数值。 多个样本且保持独立同分布： $$ \\hat{\\theta}{\\mathrm{MLE}} = \\arg\\max{\\theta} \\prod_{i=1}^{n} p(x_i \\mid \\theta) $$ 对数化表示： $$ \\hat{\\theta}{\\mathrm{MLE}} = \\arg\\max{\\theta} \\sum_{i=1}^{n} \\log p(x_i \\mid \\theta) $$ log是为了便于运算，这样连乘就变成了连加。 也会使用置信区间与假设来辅助决策。比如：若p值小于0.05，则拒绝原假设。 简单总结 频率派发展出来的模型一般来说称为统计机器学习。本质上来说是一个优化问题。 建立一个模型 设计loss function 具体的算法：梯度下降…… 贝叶斯派（Bayesian） 核心观点 参数和假设被视为概率分布，数据则被视为固定的。假设先验知识的存在，然后再用采样逐渐修改先验知识并逼近真实知识。 $\\theta$: r.v, $\\theta \\sim p(\\theta)$ 通常情况下，我们称这个$p(\\theta)$为先验概率。 先验是频率论和贝叶斯推理之间的主要区别之间，频率论分析的结果主要基于数据，而先验可以由专家信念、历史数据或两者组合决定。 概率模型 借助贝叶斯定理，将先验（Prior）和后验(Posterior)用似然联系在一起。 $$ Posterior = \\frac{Likelihood \\times Prior}{Evidence} $$ 也就是： $$ P(\\theta|X) =\\frac{P(X|\\theta)P(\\theta)}{P(X)} $$ $P(\\theta|X)$后验概率：观察到数据$X$后，参数$\\theta$取某个值的概率。 $P(X|\\theta)$似然函数：在参数$theta$的前提下，观测到数据$X$的概率。 $P(\\theta)$先验概率：在观测到数据前，我们对$\\theta$f的信念。 $P(X)$边际似然marginal likelihood：又称证据，在没有知道具体$theta$是多少的前提下，观测到数据$X$的总概率。 其中$P(X)$的数学形式是： $$ P(X) = \\int P(X \\mid \\theta) , P(\\theta) , d\\theta $$ 也就是说，把所有可能的参数值下数据的可能性（加权先验）都加总起来。 这里我们引入MAP：最大后验估计（Maximum A Posteriori estimation）。 因为$\\theta$是一个分布，我们找到一个合适的值，使这个后验概率最大。 $$ \\hat{\\theta}{MAP} = \\arg\\max{\\theta} P(\\theta \\mid X) $$ 也就是说，MAP估计是在最大化 似然函数 与 先验分布 的乘积。 贝叶斯估计：观察到数据$X$后，基于后验分布，对参数$\\theta$进行推断。MAP是贝叶斯估计的一个特例。 而求这个后验概率的其中一个目的，就是在贝叶斯预测中，预测新数据$x_{new}$的分布： $$ P(x_{\\text{new}} \\mid X) = \\int P(x_{\\text{new}} \\mid \\theta) \\cdot P(\\theta \\mid X) , d\\theta $$ 符号 含义 $x_{\\text{new}}$ 想要预测的新数据点 $X$ 已经观察到的数据 $\\theta$ 模型的未知参数 $P(\\theta \\mid X)$ 后验分布：在观察 (X) 之后对参数的认知 $P(x_{\\text{new}} \\mid \\theta)$ 参数给定下新数据的生成概率 $\\int \\cdots d\\theta$ 对所有可能的参数值加权平均 我们不知道真实的 $\\theta$，所以不直接用一个点估计，而是： 利用后验分布 $P(\\theta \\mid X)$， 对所有可能的 (\\theta) 进行加权，得到新样本的综合预测分布。 然后，从贝叶斯发展出来的就是概率图模型（求积分问题）。（因为上述这些公式的积分，在高纬、多变量、复杂模型中太难算了，往往没有解析解） 解析解求不出啦，就用蒙特卡洛等方法来求积分。 概率图模型和蒙特卡洛以后解释 蒙特卡洛方法（Monte Carlo Methods）的简单说明：“采样 + 平均”来近似积分的数值方法 在贝叶斯推论中，前一次得到的后验概率分布可以视作下一次的先验概率。 在数据量趋近于无限时，频率派和贝叶斯派得到的结果是一致的，有一种说法是频率方法是贝叶斯方法的极限[4]。 所以在实验次数较少的时候，贝叶斯方法非常有用，将先验知识纳入考虑，获得的数据越多，先验概率更新到后验分布。 总结 方面 频率派 (Frequentist) 贝叶斯派 (Bayesian) 概率定义 事件发生的频率，基于大量重复试验 对未知参数的主观信念，用概率分布描述 参数 固定但未知的常数 随机变量，有先验分布 核心方法 最大似然估计（MLE）、置信区间、假设检验 贝叶斯定理，后验概率，最大后验估计（MAP） 不确定性处理 仅通过数据，参数无概率分布 利用先验知识结合数据，参数带概率分布 目标 估计参数的“真实值” 得到参数的后验分布，更全面表达不确定性 预测 基于估计参数做点预测 通过后验分布对新数据进行概率预测 计算挑战 通常优化问题，计算相对简单 需计算积分，复杂模型时用蒙特卡洛等数值方法 适用场景 大样本，缺少先验信息 样本少且有先验知识时更有效 哲学基础 客观频率主义 主观概率主义 代表学者 Ronald Fisher，Jerzy Neyman，Egon Pearson Thomas Bayes，Pierre-Simon Laplace，E.T. Jaynes Understanding the Differences Between Bayesian and Frequentist Statistics：是文章也是播客，讲述了频率派和贝叶斯之间的差异，讨论两种方法的潜在优缺点。 ↩︎ 《概率论沉思录》——E.T.Jaynes ↩︎ B站机器学习白板推导系列 ↩︎ 统计学里频率学派(Frequentist)与贝叶斯(Bayesian)学派的区别和在机器学习中的应用 ↩︎","link":"/2025/05/18/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%8E%E9%A2%91%E7%8E%87%E6%B4%BE/"},{"title":"计算机会议及期刊总结","text":"【权威】CCF(中国计算机协会) A会/刊 B会/刊 C会/刊 全部会议汇总 计算机图形学 会议 A类","link":"/2024/05/07/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BC%9A%E8%AE%AE%E5%8F%8A%E6%9C%9F%E5%88%8A%E6%80%BB%E7%BB%93/"},{"title":"迁移Hexok博客","text":"尝试迁移Hexo文件，因为换了新的电脑。 是Windows10 换到 Windows11。 一套做下来，其实和系统版本关系不大。 原来的Hexo是链接了Github和配置了新的主题的。 迁移背景 原来电脑的Node.js 和 Git版本都和新电脑不一样 原来的电脑Hexo博客已经和Github链接，且更新了一些文章 原Hexo主题不是默认主题，且修改了这个主题的配置 因为很早就打算换电脑了，也知道Hexo迁移没那么简单，所以很久没有更新了。 简单来说，我之前的Hexo博客已经基本上什么都设置了一遍了（主题、Github），所以迁移的时候我希望能尽可能地保存我之前的配置。 这段时间看了很多的迁移博客，看不懂，后来就直接勇敢向前冲了，目前看来迁移成功。所以记录一下。 1. 拷贝原来的博客文件 网上看了很多的说法，但是我选择了保留的东西最多的一种。 除了node_models 全部拷贝！ 也有说public、deploy_git、.github什么的也可以不带的，但是好像也是在后面上传新的文章的时候，这些文件会自动更新，目前看来我拷贝过来也没有受到什么新的影响。 2. 环境配置 安装git并配置 安装Node.js 在CSDN上有非常多的教程，我就不献丑了。或许以后补充 我在安装新的环境的时候并没有按照之前版本安装，都是官网上最新的版本，目前使用正常。 建议： git 的user.name 和 user.email 都一样 新的SSH的title是为了表示你的电脑来自哪里，可以换成新的电脑的名字。 剩下的后面补充。 推荐的安装博客(感谢大佬们的分享）： 安装Git，并与Github链接 Node.js安装与环境配置 3. 配置Hexo 因为之前复制的时候没有带 node_models 文件 所以需要创建一下。 在博客的文件夹下右键，点击 Git Bash Here 在命令行中依次键入： 1. 安装Node.js相关的包。 npm install 是一个命令行命令，它用于安装 Node.js 包。 Hexo 博客目录中运行 npm install 时，它会安装 package.json 文件中列出的所有依赖项。这些依赖项是 Hexo 博客正常运行所必需的。 也会创建node_models 这个文件夹了。 2. 创建Hexo环境 npm install -g hexo-cli 为电脑全局安装Hexo，没事全局就全局，自己用嘛。 3.安装 hexo-deployer-git 模块 npm install hexo-deployer-git --save 这是一个用于安装 hexo-deployer-git 模块的命令。 npm install 是用来安装 Node.js 模块的命令。 hexo-deployer-git 是一个用于将 Hexo 博客部署到 Git 仓库的模块。 --save 选项表示将模块保存到项目的 package.json 文件中，以便在其他电脑上重新安装时能够自动安装这个模块。 运行这个命令后，它会在当前目录下安装 hexo-deployer-git 模块，并将其添加到 package.json 文件中。您可以在 Hexo 博客的配置文件中配置相关选项，然后使用 hexo deploy 命令将博客部署到 Git 仓库。 补充说明 好像这个过程中都没有看到自己迁移后的博客怎么和自己的GitHub连接到一起？ 其实在转移过来的_config.yml的最下面（我的是最下面），deploy的部分，已经设置了与Github对应仓库的配置，所以会自动绑定啦。 4. 检查 尝试发布新的文章： hexo new &quot;迁移Hexo博客&quot; 然后编辑一波 清除缓存 hexo clean 可以写也可以不写的命令，用于清除缓存文件（db.json）和已生成的静态文件（public）。在某些情况下（尤其是更换主题后），如果发现对站点的更改无论如何也不生效，可能需要运行该命令。 生成静态文章 hexo g 本地预览效果 hexo s 可以不这么做。 推送到远程服务器 hexo d 部署到远程服务器，会根据Hexo博客中的配置文件指定的部署选项进行推送。 若已经在配置文件中制定了使用hexo-deployer-git并配置了Git仓库的地址，就会推送到Github仓库啦。 因为同步需要时间，过一两分钟之后打开自己的github博客主页，就可以看到自己的Hexo博客更新啦！ 而且之前的发布时间没有受到影响。 参考博客 知乎：更换新电脑后，hexo无损方式重新部署 CSDN：hexo史上最全搭建教程 CSDN：换电脑后怎么迁移Hexo博客？","link":"/2023/06/26/%E8%BF%81%E7%A7%BBHexok%E5%8D%9A%E5%AE%A2/"},{"title":"写博客有感-1","text":"今年一股脑写了十多篇博客，有些小小的感悟…… 从本科开始有了在电脑上做复习笔记的习惯，期末的时候会邀请室友合作完成复习资料。当时用的是石墨文档。 那也是我最开始接触markdown。 现在回想起来，那或许就是我写作的起点。 再后来，接触到了Obsidian，当时还是这个软件刚刚起步的时候，双链模式让我非常欣喜，建立自己的知识网络真的很酷。 可惜当时Ob刚刚起步，没有多少插件，也不具备多端同步的功能，所以没用多久就放弃了。 而第一次分享自己的复习笔记，则是在幕布上。 这是一个思维导图的软件，用不同阶级的节点（也就是大纲），可以自由的从顺序列表转换为思维导图。 《计算机网络》的复习结束后，将自己整理的半吊子笔记公开到了幕布的社区。不过没多少人看。 到此为止，我所做的笔记都还是停留在知识架构的梳理与总结。没有自己的思考，没有自己的见解。 也不知道思考什么，但直觉给别人看的东西，不应该只是纯粹的搬运。 大四的时候，建立了这个个人博客。也没公开，到现在为止也只是分享给了些身边的人。后面因为忙于学业，也没有积极地更新，也不知道写什么好。 正儿八经公开的博客，其实是知乎上的三篇文章。写作的初心只是一种原始的冲动：尽量不要让后续要来日本留学的同学踩同样的坑。 或许是因为情绪高涨吧，潇潇洒洒几千上万字的博客（或者说是攻略）就完成了。 距离文章发布刚好过去一年左右，已经有上万人浏览，四百多赞和上千收藏。 啊，这或许就是博客的意义之一吧。 但是写作的结构算不上清楚，词汇、语序有许多混乱的地方。我时不时回去修改文章中有歧义的句子，每次都能找到让我汗颜的地方。 博客，和写日记和写笔记最不一样的地方是，这玩意儿是给别人看的。 在写博客的这个时间点，我自己已经解决了这个问题。怎么解决这个问题，已经从最开始的无从入手，变成了对解决问题过程的理所当然。 所以写的时候很难再共情最开始还什么都不知道的自己了，而这正是你的读者。 知乎的其中两篇文章收效甚好，现在反观来看，就是因为在留学的过程中积攒了太多的“怨气”，即使是自己已经上岸了，也对那种“迷茫”无法忘怀，写的是一直抱着“当时要是知道这个该多好”的想法，可以说是怒气冲冲地完成了文章。 这种“分享”的精神，多多少少也是受程序员开源精神的影响吧。 但还有一本不得不提到的书，虽然我只阅读了短短的十页（英文原著阅读对我来说还是太难以坚持了），还是想要在这里和可能读到这个短短的文章的人分享： 书名 Show Your Work!: 10 ways to Share Your Creativity and Get Discovered 这是一个很牛的国外youtuber推荐的书，据观察这个人应该是个真大佬，以前跟着他的自学视频自习，现在人家已经创业成功许久了。（笑） 好久没打开这个书了，看到里面的笔记记录都是2021年写下的，哈哈，时过境迁。 其中印象最深的一句话： The fellow-pupil can help more than the master because he knows less. The difficulty we want him to explain is one he has recently met. The experit met it so long ago he has forgotten. 翻译：徒弟比师傅更有帮助，因为他知道的少。我们要他解释的困难是他最近遇到的一个。这位专家很久以前就遇到过这个问题，他已经忘记了。 大学的时候，还没有掌握自学的技巧，也没有GPT什么的大模型帮忙，只能点开一个个搜索网站，一个个博客，翻找那个和自己正在遇到的问题一样的答案…… 阅读的过程也是审阅的过程，看着看着，除了找到了自己想要的答案，心中也有了对博客的评判，什么样的博客写得好，什么样的博客写得跟加密文件没什么区别。 后来……因为这本书遇到的生词太多就放弃了阅读。但不得不说，这短短的几页，那几句话让我至今铭记于心。 或许是时候再次捧起这本书了。 博客，也会坚持写；书也会坚持读。 希望比昨天更好一点点。","link":"/2025/05/23/%E5%86%99%E5%8D%9A%E5%AE%A2%E6%9C%89%E6%84%9F-1/"}],"tags":[{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"deep learning","slug":"deep-learning","link":"/tags/deep-learning/"},{"name":"AMP","slug":"AMP","link":"/tags/AMP/"},{"name":"machine learning","slug":"machine-learning","link":"/tags/machine-learning/"},{"name":"数据结构与算法","slug":"数据结构与算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"C语言","slug":"C语言","link":"/tags/C%E8%AF%AD%E8%A8%80/"},{"name":"碎碎念","slug":"碎碎念","link":"/tags/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"Attention","slug":"Attention","link":"/tags/Attention/"},{"name":"Image Segmentation","slug":"Image-Segmentation","link":"/tags/Image-Segmentation/"},{"name":"搜索算法","slug":"搜索算法","link":"/tags/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"},{"name":"图","slug":"图","link":"/tags/%E5%9B%BE/"},{"name":"BFS","slug":"BFS","link":"/tags/BFS/"},{"name":"DFS","slug":"DFS","link":"/tags/DFS/"},{"name":"评价指标","slug":"评价指标","link":"/tags/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"哈希","slug":"哈希","link":"/tags/%E5%93%88%E5%B8%8C/"},{"name":"BatchNorm","slug":"BatchNorm","link":"/tags/BatchNorm/"},{"name":"LayerNorm","slug":"LayerNorm","link":"/tags/LayerNorm/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"},{"name":"写作","slug":"写作","link":"/tags/%E5%86%99%E4%BD%9C/"},{"name":"github","slug":"github","link":"/tags/github/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"项目管理","slug":"项目管理","link":"/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/"},{"name":"文件读取","slug":"文件读取","link":"/tags/%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Windows","slug":"Windows","link":"/tags/Windows/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"wsl","slug":"wsl","link":"/tags/wsl/"},{"name":"vscode","slug":"vscode","link":"/tags/vscode/"},{"name":"ssh","slug":"ssh","link":"/tags/ssh/"},{"name":"项目分享","slug":"项目分享","link":"/tags/%E9%A1%B9%E7%9B%AE%E5%88%86%E4%BA%AB/"},{"name":"读后感","slug":"读后感","link":"/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"硬件","slug":"硬件","link":"/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"数据恢复","slug":"数据恢复","link":"/tags/%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D/"},{"name":"随拍","slug":"随拍","link":"/tags/%E9%9A%8F%E6%8B%8D/"},{"name":"链表","slug":"链表","link":"/tags/%E9%93%BE%E8%A1%A8/"},{"name":"栈","slug":"栈","link":"/tags/%E6%A0%88/"},{"name":"排序算法","slug":"排序算法","link":"/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"front end","slug":"front-end","link":"/tags/front-end/"},{"name":"Software Development","slug":"Software-Development","link":"/tags/Software-Development/"},{"name":"Activation Function","slug":"Activation-Function","link":"/tags/Activation-Function/"},{"name":"ReLU","slug":"ReLU","link":"/tags/ReLU/"},{"name":"Leaky ReLU","slug":"Leaky-ReLU","link":"/tags/Leaky-ReLU/"},{"name":"激活函数","slug":"激活函数","link":"/tags/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/"},{"name":"softmax","slug":"softmax","link":"/tags/softmax/"},{"name":"Sigmoid","slug":"Sigmoid","link":"/tags/Sigmoid/"},{"name":"随笔","slug":"随笔","link":"/tags/%E9%9A%8F%E7%AC%94/"},{"name":"BitNet","slug":"BitNet","link":"/tags/BitNet/"},{"name":"LLM","slug":"LLM","link":"/tags/LLM/"},{"name":"终端命令","slug":"终端命令","link":"/tags/%E7%BB%88%E7%AB%AF%E5%91%BD%E4%BB%A4/"},{"name":"概率论","slug":"概率论","link":"/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"},{"name":"贝叶斯","slug":"贝叶斯","link":"/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"频率派","slug":"频率派","link":"/tags/%E9%A2%91%E7%8E%87%E6%B4%BE/"},{"name":"机器学习基础","slug":"机器学习基础","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"},{"name":"科研","slug":"科研","link":"/tags/%E7%A7%91%E7%A0%94/"}],"categories":[{"name":"技术学习","slug":"技术学习","link":"/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"},{"name":"技能学习","slug":"技能学习","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"技术学习/深度学习","link":"/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"计算机基础","slug":"计算机基础","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"},{"name":"生活","slug":"生活","link":"/categories/%E7%94%9F%E6%B4%BB/"},{"name":"Hexo","slug":"技能学习/Hexo","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Hexo/"},{"name":"Java","slug":"技能学习/Java","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Java/"},{"name":"Leetcode","slug":"计算机基础/Leetcode","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/Leetcode/"},{"name":"数据结构与算法","slug":"计算机基础/数据结构与算法","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"name":"碎碎念","slug":"生活/碎碎念","link":"/categories/%E7%94%9F%E6%B4%BB/%E7%A2%8E%E7%A2%8E%E5%BF%B5/"},{"name":"markdown","slug":"技能学习/markdown","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/markdown/"},{"name":"代码管理","slug":"技能学习/代码管理","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E4%BB%A3%E7%A0%81%E7%AE%A1%E7%90%86/"},{"name":"Linux","slug":"技能学习/Linux","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Linux/"},{"name":"环境","slug":"技能学习/Java/环境","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Java/%E7%8E%AF%E5%A2%83/"},{"name":"配置","slug":"技能学习/Linux/配置","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Linux/%E9%85%8D%E7%BD%AE/"},{"name":"wsl","slug":"技能学习/Linux/wsl","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/Linux/wsl/"},{"name":"阅读","slug":"生活/阅读","link":"/categories/%E7%94%9F%E6%B4%BB/%E9%98%85%E8%AF%BB/"},{"name":"硬件","slug":"技能学习/硬件","link":"/categories/%E6%8A%80%E8%83%BD%E5%AD%A6%E4%B9%A0/%E7%A1%AC%E4%BB%B6/"},{"name":"留学","slug":"生活/留学","link":"/categories/%E7%94%9F%E6%B4%BB/%E7%95%99%E5%AD%A6/"},{"name":"LLM","slug":"技术学习/深度学习/LLM","link":"/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LLM/"},{"name":"知识科普","slug":"知识科普","link":"/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/"},{"name":"计算机","slug":"知识科普/计算机","link":"/categories/%E7%9F%A5%E8%AF%86%E7%A7%91%E6%99%AE/%E8%AE%A1%E7%AE%97%E6%9C%BA/"}],"pages":[{"title":"About Me","text":"Name Zhou Wentong Location Sichuan, China Education Computer Science, Biomedical Engineering Languages Chinese, English, Japanese; Python, C++, C, HTML,CSS, Java,Javascript Skills Pytorch, Vue, Flask Interests Photography, writing, walking Job Currently pursuing a master’s degree… Favorite Sentences Be kind, stay curious and think deeper.——By me Resent Reading River Town (Peter Hessler) 我与地坛 （史铁生）","link":"/about/index.html"}]}